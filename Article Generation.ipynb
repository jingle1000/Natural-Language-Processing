{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, string, re, csv\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "\n",
    "# set seeds for reproducability\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "\n",
    "#for grammar\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./all-the-news/articles1.csv\n",
      "./all-the-news/articles2.csv\n",
      "./all-the-news/articles3.csv\n"
     ]
    }
   ],
   "source": [
    "path = \"./all-the-news\"\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    if file != \"formatted.csv\":\n",
    "        print(path+\"/\"+file)\n",
    "        dfnew = pd.read_csv(path+\"/\"+file)\n",
    "        df = pd.concat([df, dfnew])\n",
    "articles = df[\"content\"].to_numpy()\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    txt = re.sub(' +',' ', txt)\n",
    "    txt = txt.replace(\"\\t\", \"\").replace(\"\\r\", \"\")\n",
    "    return txt \n",
    "\n",
    "def write_formatted_csv(article_list):\n",
    "    with open(path+\"/formatted.csv\", mode=\"w\", newline=None) as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        for article in article_list:\n",
    "            writer.writerow(article)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_formatted_csv(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = {}\n",
    "# word_frequency_index = {}\n",
    "# counter = 0\n",
    "# for article in corpus:\n",
    "#     try:\n",
    "#         article = article.split(\" \")\n",
    "#         if len(article) > 1:\n",
    "#             for word in article:\n",
    "#                 word = word.lower()\n",
    "#                 word = \"\".join([w for w in word if w not in string.punctuation])\n",
    "#                 if word not in word_index:\n",
    "#                     word_index[word] = counter\n",
    "#                     counter += 1\n",
    "#                 if word not in word_frequency_index:\n",
    "#                     word_frequency_index[word] = 1\n",
    "#                 else:\n",
    "#                     word_frequency_index[word] += 1\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert corpus into one string\n",
    "articles = [clean_text(x) for x in articles if type(x) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in corpus], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON - [51 29 47 36 37 42 35 48 43 42]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{corpus[:10]} - {text_as_int[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(corpus)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jingl\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           23296     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 91)            93275     \n",
      "=================================================================\n",
      "Total params: 5,363,547\n",
      "Trainable params: 5,363,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 91) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 91)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.510748\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 99/100 [============================>.] - ETA: 15:38 - loss: 4.51 - ETA: 11:50 - loss: 4.48 - ETA: 10:23 - loss: 4.33 - ETA: 9:29 - loss: 4.4981 - ETA: 8:52 - loss: 4.271 - ETA: 8:25 - loss: 4.154 - ETA: 8:05 - loss: 4.075 - ETA: 7:51 - loss: 4.009 - ETA: 7:38 - loss: 3.949 - ETA: 7:27 - loss: 3.885 - ETA: 7:16 - loss: 3.823 - ETA: 7:09 - loss: 3.763 - ETA: 7:01 - loss: 3.711 - ETA: 6:53 - loss: 3.666 - ETA: 6:46 - loss: 3.632 - ETA: 6:38 - loss: 3.602 - ETA: 6:31 - loss: 3.573 - ETA: 6:25 - loss: 3.546 - ETA: 6:18 - loss: 3.519 - ETA: 6:12 - loss: 3.497 - ETA: 6:06 - loss: 3.476 - ETA: 6:00 - loss: 3.458 - ETA: 5:54 - loss: 3.440 - ETA: 5:48 - loss: 3.425 - ETA: 5:43 - loss: 3.410 - ETA: 5:37 - loss: 3.396 - ETA: 5:32 - loss: 3.384 - ETA: 5:26 - loss: 3.371 - ETA: 5:20 - loss: 3.359 - ETA: 5:15 - loss: 3.348 - ETA: 5:10 - loss: 3.339 - ETA: 5:05 - loss: 3.329 - ETA: 4:59 - loss: 3.319 - ETA: 4:54 - loss: 3.309 - ETA: 4:49 - loss: 3.300 - ETA: 4:44 - loss: 3.291 - ETA: 4:39 - loss: 3.282 - ETA: 4:34 - loss: 3.275 - ETA: 4:30 - loss: 3.268 - ETA: 4:25 - loss: 3.260 - ETA: 4:20 - loss: 3.253 - ETA: 4:15 - loss: 3.246 - ETA: 4:11 - loss: 3.240 - ETA: 4:06 - loss: 3.234 - ETA: 4:01 - loss: 3.227 - ETA: 3:57 - loss: 3.221 - ETA: 3:52 - loss: 3.215 - ETA: 3:47 - loss: 3.208 - ETA: 3:43 - loss: 3.203 - ETA: 3:38 - loss: 3.198 - ETA: 3:33 - loss: 3.192 - ETA: 3:29 - loss: 3.186 - ETA: 3:24 - loss: 3.180 - ETA: 3:20 - loss: 3.175 - ETA: 3:15 - loss: 3.170 - ETA: 3:11 - loss: 3.165 - ETA: 3:06 - loss: 3.160 - ETA: 3:02 - loss: 3.155 - ETA: 2:57 - loss: 3.150 - ETA: 2:53 - loss: 3.145 - ETA: 2:49 - loss: 3.139 - ETA: 2:44 - loss: 3.134 - ETA: 2:40 - loss: 3.128 - ETA: 2:35 - loss: 3.123 - ETA: 2:31 - loss: 3.118 - ETA: 2:26 - loss: 3.112 - ETA: 2:22 - loss: 3.107 - ETA: 2:18 - loss: 3.102 - ETA: 2:13 - loss: 3.097 - ETA: 2:09 - loss: 3.092 - ETA: 2:04 - loss: 3.087 - ETA: 2:00 - loss: 3.083 - ETA: 1:56 - loss: 3.077 - ETA: 1:52 - loss: 3.072 - ETA: 1:47 - loss: 3.067 - ETA: 1:43 - loss: 3.062 - ETA: 1:38 - loss: 3.057 - ETA: 1:34 - loss: 3.053 - ETA: 1:30 - loss: 3.047 - ETA: 1:25 - loss: 3.043 - ETA: 1:21 - loss: 3.038 - ETA: 1:17 - loss: 3.033 - ETA: 1:12 - loss: 3.029 - ETA: 1:08 - loss: 3.024 - ETA: 1:04 - loss: 3.020 - ETA: 1:00 - loss: 3.015 - ETA: 55s - loss: 3.011 - ETA: 51s - loss: 3.00 - ETA: 47s - loss: 3.00 - ETA: 42s - loss: 2.99 - ETA: 38s - loss: 2.99 - ETA: 34s - loss: 2.98 - ETA: 29s - loss: 2.98 - ETA: 25s - loss: 2.97 - ETA: 21s - loss: 2.97 - ETA: 17s - loss: 2.97 - ETA: 12s - loss: 2.96 - ETA: 8s - loss: 2.9614 - ETA: 4s - loss: 2.9568WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From C:\\Users\\jingl\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "100/100 [==============================] - 428s 4s/step - loss: 2.9525\n",
      "Epoch 2/100\n",
      " 99/100 [============================>.] - ETA: 6:50 - loss: 2.515 - ETA: 6:47 - loss: 2.513 - ETA: 6:42 - loss: 2.519 - ETA: 6:38 - loss: 2.513 - ETA: 6:34 - loss: 2.512 - ETA: 6:30 - loss: 2.515 - ETA: 6:26 - loss: 2.514 - ETA: 6:21 - loss: 2.513 - ETA: 6:17 - loss: 2.512 - ETA: 6:13 - loss: 2.512 - ETA: 6:09 - loss: 2.512 - ETA: 6:05 - loss: 2.510 - ETA: 6:00 - loss: 2.511 - ETA: 5:56 - loss: 2.509 - ETA: 5:52 - loss: 2.508 - ETA: 5:48 - loss: 2.507 - ETA: 5:44 - loss: 2.504 - ETA: 5:40 - loss: 2.505 - ETA: 5:36 - loss: 2.503 - ETA: 5:32 - loss: 2.501 - ETA: 5:28 - loss: 2.502 - ETA: 5:23 - loss: 2.502 - ETA: 5:19 - loss: 2.501 - ETA: 5:15 - loss: 2.500 - ETA: 5:11 - loss: 2.499 - ETA: 5:07 - loss: 2.498 - ETA: 5:03 - loss: 2.496 - ETA: 4:59 - loss: 2.494 - ETA: 4:55 - loss: 2.493 - ETA: 4:50 - loss: 2.490 - ETA: 4:46 - loss: 2.488 - ETA: 4:42 - loss: 2.486 - ETA: 4:38 - loss: 2.484 - ETA: 4:34 - loss: 2.483 - ETA: 4:30 - loss: 2.482 - ETA: 4:26 - loss: 2.480 - ETA: 4:21 - loss: 2.479 - ETA: 4:17 - loss: 2.477 - ETA: 4:13 - loss: 2.476 - ETA: 4:09 - loss: 2.474 - ETA: 4:05 - loss: 2.472 - ETA: 4:01 - loss: 2.470 - ETA: 3:56 - loss: 2.470 - ETA: 3:52 - loss: 2.468 - ETA: 3:48 - loss: 2.466 - ETA: 3:44 - loss: 2.465 - ETA: 3:40 - loss: 2.463 - ETA: 3:36 - loss: 2.462 - ETA: 3:32 - loss: 2.461 - ETA: 3:27 - loss: 2.460 - ETA: 3:23 - loss: 2.459 - ETA: 3:19 - loss: 2.458 - ETA: 3:15 - loss: 2.457 - ETA: 3:11 - loss: 2.455 - ETA: 3:07 - loss: 2.454 - ETA: 3:02 - loss: 2.452 - ETA: 2:58 - loss: 2.450 - ETA: 2:54 - loss: 2.449 - ETA: 2:50 - loss: 2.447 - ETA: 2:46 - loss: 2.446 - ETA: 2:42 - loss: 2.445 - ETA: 2:38 - loss: 2.444 - ETA: 2:33 - loss: 2.442 - ETA: 2:29 - loss: 2.442 - ETA: 2:25 - loss: 2.441 - ETA: 2:21 - loss: 2.439 - ETA: 2:17 - loss: 2.438 - ETA: 2:13 - loss: 2.437 - ETA: 2:08 - loss: 2.435 - ETA: 2:04 - loss: 2.434 - ETA: 2:00 - loss: 2.433 - ETA: 1:56 - loss: 2.432 - ETA: 1:52 - loss: 2.430 - ETA: 1:48 - loss: 2.429 - ETA: 1:44 - loss: 2.427 - ETA: 1:39 - loss: 2.426 - ETA: 1:35 - loss: 2.425 - ETA: 1:31 - loss: 2.424 - ETA: 1:27 - loss: 2.423 - ETA: 1:23 - loss: 2.422 - ETA: 1:19 - loss: 2.420 - ETA: 1:15 - loss: 2.419 - ETA: 1:10 - loss: 2.418 - ETA: 1:06 - loss: 2.417 - ETA: 1:02 - loss: 2.416 - ETA: 58s - loss: 2.414 - ETA: 54s - loss: 2.41 - ETA: 50s - loss: 2.41 - ETA: 45s - loss: 2.41 - ETA: 41s - loss: 2.40 - ETA: 37s - loss: 2.40 - ETA: 33s - loss: 2.40 - ETA: 29s - loss: 2.40 - ETA: 25s - loss: 2.40 - ETA: 20s - loss: 2.40 - ETA: 16s - loss: 2.40 - ETA: 12s - loss: 2.40 - ETA: 8s - loss: 2.4000 - ETA: 4s - loss: 2.3983WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 417s 4s/step - loss: 2.3974\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:51 - loss: 2.276 - ETA: 6:47 - loss: 2.261 - ETA: 6:42 - loss: 2.253 - ETA: 6:38 - loss: 2.259 - ETA: 6:34 - loss: 2.258 - ETA: 6:30 - loss: 2.268 - ETA: 6:26 - loss: 2.266 - ETA: 6:22 - loss: 2.267 - ETA: 6:18 - loss: 2.268 - ETA: 6:14 - loss: 2.265 - ETA: 6:09 - loss: 2.265 - ETA: 6:05 - loss: 2.266 - ETA: 6:01 - loss: 2.263 - ETA: 5:57 - loss: 2.259 - ETA: 5:53 - loss: 2.260 - ETA: 5:49 - loss: 2.258 - ETA: 5:45 - loss: 2.258 - ETA: 5:40 - loss: 2.257 - ETA: 5:36 - loss: 2.255 - ETA: 5:32 - loss: 2.253 - ETA: 5:28 - loss: 2.252 - ETA: 5:24 - loss: 2.251 - ETA: 5:19 - loss: 2.249 - ETA: 5:15 - loss: 2.248 - ETA: 5:11 - loss: 2.246 - ETA: 5:07 - loss: 2.246 - ETA: 5:03 - loss: 2.243 - ETA: 4:59 - loss: 2.242 - ETA: 4:54 - loss: 2.241 - ETA: 4:50 - loss: 2.242 - ETA: 4:46 - loss: 2.240 - ETA: 4:42 - loss: 2.239 - ETA: 4:38 - loss: 2.238 - ETA: 4:33 - loss: 2.237 - ETA: 4:29 - loss: 2.235 - ETA: 4:25 - loss: 2.234 - ETA: 4:21 - loss: 2.233 - ETA: 4:17 - loss: 2.232 - ETA: 4:13 - loss: 2.231 - ETA: 4:09 - loss: 2.231 - ETA: 4:05 - loss: 2.228 - ETA: 4:01 - loss: 2.227 - ETA: 3:56 - loss: 2.227 - ETA: 3:53 - loss: 2.226 - ETA: 3:49 - loss: 2.225 - ETA: 3:45 - loss: 2.224 - ETA: 3:41 - loss: 2.223 - ETA: 3:37 - loss: 2.222 - ETA: 3:33 - loss: 2.221 - ETA: 3:29 - loss: 2.220 - ETA: 3:25 - loss: 2.220 - ETA: 3:21 - loss: 2.219 - ETA: 3:17 - loss: 2.218 - ETA: 3:12 - loss: 2.217 - ETA: 3:08 - loss: 2.216 - ETA: 3:04 - loss: 2.215 - ETA: 3:00 - loss: 2.214 - ETA: 2:55 - loss: 2.213 - ETA: 2:51 - loss: 2.212 - ETA: 2:47 - loss: 2.212 - ETA: 2:43 - loss: 2.211 - ETA: 2:39 - loss: 2.211 - ETA: 2:34 - loss: 2.209 - ETA: 2:30 - loss: 2.209 - ETA: 2:26 - loss: 2.208 - ETA: 2:22 - loss: 2.207 - ETA: 2:18 - loss: 2.205 - ETA: 2:13 - loss: 2.204 - ETA: 2:09 - loss: 2.203 - ETA: 2:05 - loss: 2.202 - ETA: 2:01 - loss: 2.201 - ETA: 1:57 - loss: 2.200 - ETA: 1:52 - loss: 2.198 - ETA: 1:48 - loss: 2.198 - ETA: 1:44 - loss: 2.197 - ETA: 1:40 - loss: 2.196 - ETA: 1:36 - loss: 2.195 - ETA: 1:31 - loss: 2.194 - ETA: 1:27 - loss: 2.194 - ETA: 1:23 - loss: 2.193 - ETA: 1:19 - loss: 2.192 - ETA: 1:15 - loss: 2.191 - ETA: 1:11 - loss: 2.190 - ETA: 1:06 - loss: 2.189 - ETA: 1:02 - loss: 2.188 - ETA: 58s - loss: 2.187 - ETA: 54s - loss: 2.18 - ETA: 50s - loss: 2.18 - ETA: 45s - loss: 2.18 - ETA: 41s - loss: 2.18 - ETA: 37s - loss: 2.18 - ETA: 33s - loss: 2.18 - ETA: 29s - loss: 2.18 - ETA: 25s - loss: 2.18 - ETA: 20s - loss: 2.17 - ETA: 16s - loss: 2.17 - ETA: 12s - loss: 2.17 - ETA: 8s - loss: 2.1767 - ETA: 4s - loss: 2.1758WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 418s 4s/step - loss: 2.1751\n",
      "Epoch 4/100\n",
      " 99/100 [============================>.] - ETA: 6:55 - loss: 2.053 - ETA: 6:53 - loss: 2.063 - ETA: 6:46 - loss: 2.062 - ETA: 6:41 - loss: 2.062 - ETA: 6:36 - loss: 2.068 - ETA: 6:31 - loss: 2.065 - ETA: 6:27 - loss: 2.063 - ETA: 6:22 - loss: 2.061 - ETA: 6:18 - loss: 2.068 - ETA: 6:14 - loss: 2.068 - ETA: 6:10 - loss: 2.068 - ETA: 6:05 - loss: 2.066 - ETA: 6:01 - loss: 2.069 - ETA: 5:57 - loss: 2.068 - ETA: 5:53 - loss: 2.070 - ETA: 5:49 - loss: 2.071 - ETA: 5:44 - loss: 2.070 - ETA: 5:40 - loss: 2.069 - ETA: 5:36 - loss: 2.068 - ETA: 5:32 - loss: 2.067 - ETA: 5:28 - loss: 2.067 - ETA: 5:23 - loss: 2.068 - ETA: 5:19 - loss: 2.067 - ETA: 5:15 - loss: 2.064 - ETA: 5:11 - loss: 2.063 - ETA: 5:07 - loss: 2.063 - ETA: 5:03 - loss: 2.062 - ETA: 4:58 - loss: 2.061 - ETA: 4:54 - loss: 2.060 - ETA: 4:50 - loss: 2.061 - ETA: 4:46 - loss: 2.060 - ETA: 4:42 - loss: 2.060 - ETA: 4:38 - loss: 2.059 - ETA: 4:34 - loss: 2.058 - ETA: 4:29 - loss: 2.058 - ETA: 4:25 - loss: 2.057 - ETA: 4:21 - loss: 2.056 - ETA: 4:17 - loss: 2.055 - ETA: 4:13 - loss: 2.054 - ETA: 4:09 - loss: 2.053 - ETA: 4:04 - loss: 2.053 - ETA: 4:00 - loss: 2.052 - ETA: 3:56 - loss: 2.051 - ETA: 3:52 - loss: 2.050 - ETA: 3:48 - loss: 2.050 - ETA: 3:44 - loss: 2.049 - ETA: 3:40 - loss: 2.048 - ETA: 3:35 - loss: 2.047 - ETA: 3:31 - loss: 2.046 - ETA: 3:27 - loss: 2.046 - ETA: 3:23 - loss: 2.044 - ETA: 3:19 - loss: 2.043 - ETA: 3:15 - loss: 2.043 - ETA: 3:11 - loss: 2.042 - ETA: 3:06 - loss: 2.042 - ETA: 3:02 - loss: 2.041 - ETA: 2:58 - loss: 2.041 - ETA: 2:54 - loss: 2.040 - ETA: 2:50 - loss: 2.040 - ETA: 2:46 - loss: 2.040 - ETA: 2:41 - loss: 2.039 - ETA: 2:37 - loss: 2.039 - ETA: 2:33 - loss: 2.038 - ETA: 2:29 - loss: 2.037 - ETA: 2:25 - loss: 2.037 - ETA: 2:21 - loss: 2.036 - ETA: 2:17 - loss: 2.035 - ETA: 2:12 - loss: 2.034 - ETA: 2:08 - loss: 2.034 - ETA: 2:04 - loss: 2.033 - ETA: 2:00 - loss: 2.032 - ETA: 1:56 - loss: 2.032 - ETA: 1:52 - loss: 2.031 - ETA: 1:48 - loss: 2.030 - ETA: 1:43 - loss: 2.029 - ETA: 1:39 - loss: 2.029 - ETA: 1:35 - loss: 2.028 - ETA: 1:31 - loss: 2.028 - ETA: 1:27 - loss: 2.027 - ETA: 1:23 - loss: 2.027 - ETA: 1:18 - loss: 2.026 - ETA: 1:14 - loss: 2.025 - ETA: 1:10 - loss: 2.024 - ETA: 1:06 - loss: 2.024 - ETA: 1:02 - loss: 2.023 - ETA: 58s - loss: 2.022 - ETA: 54s - loss: 2.02 - ETA: 49s - loss: 2.02 - ETA: 45s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 37s - loss: 2.02 - ETA: 33s - loss: 2.02 - ETA: 29s - loss: 2.01 - ETA: 24s - loss: 2.01 - ETA: 20s - loss: 2.01 - ETA: 16s - loss: 2.01 - ETA: 12s - loss: 2.01 - ETA: 8s - loss: 2.0172 - ETA: 4s - loss: 2.0164WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 416s 4s/step - loss: 2.0158\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.947 - ETA: 6:45 - loss: 1.967 - ETA: 6:41 - loss: 1.952 - ETA: 6:37 - loss: 1.942 - ETA: 6:33 - loss: 1.935 - ETA: 6:28 - loss: 1.938 - ETA: 6:24 - loss: 1.936 - ETA: 6:20 - loss: 1.935 - ETA: 6:17 - loss: 1.935 - ETA: 6:13 - loss: 1.931 - ETA: 6:09 - loss: 1.930 - ETA: 6:04 - loss: 1.932 - ETA: 6:00 - loss: 1.932 - ETA: 5:56 - loss: 1.932 - ETA: 5:52 - loss: 1.930 - ETA: 5:48 - loss: 1.932 - ETA: 5:44 - loss: 1.931 - ETA: 5:40 - loss: 1.929 - ETA: 5:35 - loss: 1.928 - ETA: 5:31 - loss: 1.927 - ETA: 5:27 - loss: 1.927 - ETA: 5:23 - loss: 1.928 - ETA: 5:19 - loss: 1.927 - ETA: 5:14 - loss: 1.926 - ETA: 5:10 - loss: 1.926 - ETA: 5:06 - loss: 1.926 - ETA: 5:02 - loss: 1.925 - ETA: 4:58 - loss: 1.924 - ETA: 4:54 - loss: 1.922 - ETA: 4:50 - loss: 1.921 - ETA: 4:45 - loss: 1.921 - ETA: 4:41 - loss: 1.920 - ETA: 4:37 - loss: 1.919 - ETA: 4:33 - loss: 1.919 - ETA: 4:29 - loss: 1.918 - ETA: 4:25 - loss: 1.917 - ETA: 4:20 - loss: 1.917 - ETA: 4:16 - loss: 1.915 - ETA: 4:12 - loss: 1.914 - ETA: 4:08 - loss: 1.914 - ETA: 4:04 - loss: 1.914 - ETA: 4:00 - loss: 1.913 - ETA: 3:56 - loss: 1.913 - ETA: 3:52 - loss: 1.913 - ETA: 3:48 - loss: 1.912 - ETA: 3:44 - loss: 1.912 - ETA: 3:39 - loss: 1.911 - ETA: 3:35 - loss: 1.911 - ETA: 3:31 - loss: 1.911 - ETA: 3:27 - loss: 1.910 - ETA: 3:23 - loss: 1.909 - ETA: 3:19 - loss: 1.909 - ETA: 3:14 - loss: 1.909 - ETA: 3:10 - loss: 1.908 - ETA: 3:06 - loss: 1.908 - ETA: 3:02 - loss: 1.907 - ETA: 2:58 - loss: 1.907 - ETA: 2:54 - loss: 1.907 - ETA: 2:50 - loss: 1.906 - ETA: 2:45 - loss: 1.906 - ETA: 2:41 - loss: 1.906 - ETA: 2:37 - loss: 1.905 - ETA: 2:33 - loss: 1.904 - ETA: 2:29 - loss: 1.903 - ETA: 2:25 - loss: 1.902 - ETA: 2:21 - loss: 1.901 - ETA: 2:16 - loss: 1.901 - ETA: 2:12 - loss: 1.900 - ETA: 2:08 - loss: 1.899 - ETA: 2:04 - loss: 1.899 - ETA: 2:00 - loss: 1.899 - ETA: 1:56 - loss: 1.898 - ETA: 1:51 - loss: 1.897 - ETA: 1:47 - loss: 1.897 - ETA: 1:43 - loss: 1.897 - ETA: 1:39 - loss: 1.896 - ETA: 1:35 - loss: 1.896 - ETA: 1:31 - loss: 1.895 - ETA: 1:27 - loss: 1.894 - ETA: 1:22 - loss: 1.894 - ETA: 1:18 - loss: 1.893 - ETA: 1:14 - loss: 1.892 - ETA: 1:10 - loss: 1.892 - ETA: 1:06 - loss: 1.891 - ETA: 1:02 - loss: 1.891 - ETA: 58s - loss: 1.890 - ETA: 53s - loss: 1.89 - ETA: 49s - loss: 1.88 - ETA: 45s - loss: 1.88 - ETA: 41s - loss: 1.88 - ETA: 37s - loss: 1.88 - ETA: 33s - loss: 1.88 - ETA: 29s - loss: 1.88 - ETA: 24s - loss: 1.88 - ETA: 20s - loss: 1.88 - ETA: 16s - loss: 1.88 - ETA: 12s - loss: 1.88 - ETA: 8s - loss: 1.8830 - ETA: 4s - loss: 1.8821WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.8823\n",
      "Epoch 6/100\n",
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.831 - ETA: 6:45 - loss: 1.834 - ETA: 6:42 - loss: 1.833 - ETA: 6:38 - loss: 1.828 - ETA: 6:34 - loss: 1.835 - ETA: 6:30 - loss: 1.826 - ETA: 6:26 - loss: 1.831 - ETA: 6:21 - loss: 1.834 - ETA: 6:17 - loss: 1.834 - ETA: 6:13 - loss: 1.833 - ETA: 6:10 - loss: 1.830 - ETA: 6:05 - loss: 1.828 - ETA: 6:01 - loss: 1.828 - ETA: 5:57 - loss: 1.829 - ETA: 5:52 - loss: 1.829 - ETA: 5:48 - loss: 1.832 - ETA: 5:44 - loss: 1.834 - ETA: 5:40 - loss: 1.831 - ETA: 5:36 - loss: 1.829 - ETA: 5:32 - loss: 1.829 - ETA: 5:28 - loss: 1.827 - ETA: 5:23 - loss: 1.828 - ETA: 5:19 - loss: 1.826 - ETA: 5:15 - loss: 1.826 - ETA: 5:11 - loss: 1.826 - ETA: 5:07 - loss: 1.823 - ETA: 5:03 - loss: 1.823 - ETA: 4:58 - loss: 1.822 - ETA: 4:54 - loss: 1.821 - ETA: 4:50 - loss: 1.818 - ETA: 4:46 - loss: 1.817 - ETA: 4:42 - loss: 1.816 - ETA: 4:38 - loss: 1.815 - ETA: 4:34 - loss: 1.814 - ETA: 4:29 - loss: 1.814 - ETA: 4:25 - loss: 1.815 - ETA: 4:21 - loss: 1.814 - ETA: 4:17 - loss: 1.814 - ETA: 4:13 - loss: 1.813 - ETA: 4:09 - loss: 1.812 - ETA: 4:04 - loss: 1.812 - ETA: 4:00 - loss: 1.811 - ETA: 3:56 - loss: 1.811 - ETA: 3:52 - loss: 1.809 - ETA: 3:48 - loss: 1.808 - ETA: 3:44 - loss: 1.807 - ETA: 3:39 - loss: 1.806 - ETA: 3:35 - loss: 1.806 - ETA: 3:31 - loss: 1.806 - ETA: 3:27 - loss: 1.805 - ETA: 3:23 - loss: 1.805 - ETA: 3:19 - loss: 1.804 - ETA: 3:15 - loss: 1.804 - ETA: 3:10 - loss: 1.803 - ETA: 3:06 - loss: 1.803 - ETA: 3:02 - loss: 1.802 - ETA: 2:58 - loss: 1.802 - ETA: 2:54 - loss: 1.801 - ETA: 2:50 - loss: 1.801 - ETA: 2:45 - loss: 1.800 - ETA: 2:41 - loss: 1.799 - ETA: 2:37 - loss: 1.799 - ETA: 2:33 - loss: 1.799 - ETA: 2:29 - loss: 1.799 - ETA: 2:25 - loss: 1.798 - ETA: 2:21 - loss: 1.798 - ETA: 2:16 - loss: 1.797 - ETA: 2:12 - loss: 1.797 - ETA: 2:08 - loss: 1.796 - ETA: 2:04 - loss: 1.795 - ETA: 2:00 - loss: 1.794 - ETA: 1:56 - loss: 1.794 - ETA: 1:52 - loss: 1.793 - ETA: 1:47 - loss: 1.792 - ETA: 1:43 - loss: 1.791 - ETA: 1:39 - loss: 1.791 - ETA: 1:35 - loss: 1.790 - ETA: 1:31 - loss: 1.790 - ETA: 1:27 - loss: 1.789 - ETA: 1:22 - loss: 1.789 - ETA: 1:18 - loss: 1.788 - ETA: 1:14 - loss: 1.788 - ETA: 1:10 - loss: 1.788 - ETA: 1:06 - loss: 1.787 - ETA: 1:02 - loss: 1.787 - ETA: 58s - loss: 1.786 - ETA: 53s - loss: 1.78 - ETA: 49s - loss: 1.78 - ETA: 45s - loss: 1.78 - ETA: 41s - loss: 1.78 - ETA: 37s - loss: 1.78 - ETA: 33s - loss: 1.78 - ETA: 29s - loss: 1.78 - ETA: 24s - loss: 1.78 - ETA: 20s - loss: 1.78 - ETA: 16s - loss: 1.78 - ETA: 12s - loss: 1.78 - ETA: 8s - loss: 1.7791 - ETA: 4s - loss: 1.7782WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.7776\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.704 - ETA: 6:47 - loss: 1.728 - ETA: 6:42 - loss: 1.723 - ETA: 6:38 - loss: 1.713 - ETA: 6:34 - loss: 1.722 - ETA: 6:29 - loss: 1.726 - ETA: 6:25 - loss: 1.723 - ETA: 6:21 - loss: 1.723 - ETA: 6:17 - loss: 1.721 - ETA: 6:13 - loss: 1.721 - ETA: 6:09 - loss: 1.721 - ETA: 6:05 - loss: 1.721 - ETA: 6:00 - loss: 1.720 - ETA: 5:58 - loss: 1.721 - ETA: 5:55 - loss: 1.721 - ETA: 5:50 - loss: 1.720 - ETA: 5:46 - loss: 1.720 - ETA: 5:42 - loss: 1.720 - ETA: 5:38 - loss: 1.719 - ETA: 5:33 - loss: 1.717 - ETA: 5:29 - loss: 1.717 - ETA: 5:25 - loss: 1.717 - ETA: 5:21 - loss: 1.718 - ETA: 5:16 - loss: 1.719 - ETA: 5:12 - loss: 1.718 - ETA: 5:08 - loss: 1.718 - ETA: 5:04 - loss: 1.715 - ETA: 5:00 - loss: 1.716 - ETA: 4:55 - loss: 1.716 - ETA: 4:51 - loss: 1.717 - ETA: 4:47 - loss: 1.717 - ETA: 4:43 - loss: 1.717 - ETA: 4:39 - loss: 1.714 - ETA: 4:34 - loss: 1.712 - ETA: 4:30 - loss: 1.712 - ETA: 4:26 - loss: 1.710 - ETA: 4:22 - loss: 1.710 - ETA: 4:18 - loss: 1.709 - ETA: 4:13 - loss: 1.709 - ETA: 4:09 - loss: 1.709 - ETA: 4:05 - loss: 1.708 - ETA: 4:01 - loss: 1.708 - ETA: 3:57 - loss: 1.707 - ETA: 3:52 - loss: 1.708 - ETA: 3:48 - loss: 1.706 - ETA: 3:44 - loss: 1.707 - ETA: 3:40 - loss: 1.706 - ETA: 3:36 - loss: 1.706 - ETA: 3:32 - loss: 1.705 - ETA: 3:28 - loss: 1.705 - ETA: 3:23 - loss: 1.706 - ETA: 3:19 - loss: 1.706 - ETA: 3:15 - loss: 1.705 - ETA: 3:11 - loss: 1.705 - ETA: 3:07 - loss: 1.705 - ETA: 3:03 - loss: 1.704 - ETA: 2:58 - loss: 1.704 - ETA: 2:54 - loss: 1.704 - ETA: 2:50 - loss: 1.705 - ETA: 2:46 - loss: 1.705 - ETA: 2:42 - loss: 1.705 - ETA: 2:38 - loss: 1.704 - ETA: 2:33 - loss: 1.704 - ETA: 2:29 - loss: 1.704 - ETA: 2:25 - loss: 1.704 - ETA: 2:21 - loss: 1.703 - ETA: 2:17 - loss: 1.703 - ETA: 2:13 - loss: 1.703 - ETA: 2:08 - loss: 1.702 - ETA: 2:04 - loss: 1.702 - ETA: 2:00 - loss: 1.702 - ETA: 1:56 - loss: 1.702 - ETA: 1:52 - loss: 1.701 - ETA: 1:48 - loss: 1.701 - ETA: 1:43 - loss: 1.701 - ETA: 1:39 - loss: 1.700 - ETA: 1:35 - loss: 1.700 - ETA: 1:31 - loss: 1.700 - ETA: 1:27 - loss: 1.699 - ETA: 1:23 - loss: 1.699 - ETA: 1:18 - loss: 1.698 - ETA: 1:14 - loss: 1.698 - ETA: 1:10 - loss: 1.697 - ETA: 1:06 - loss: 1.697 - ETA: 1:02 - loss: 1.696 - ETA: 58s - loss: 1.696 - ETA: 54s - loss: 1.69 - ETA: 49s - loss: 1.69 - ETA: 45s - loss: 1.69 - ETA: 41s - loss: 1.69 - ETA: 37s - loss: 1.69 - ETA: 33s - loss: 1.69 - ETA: 29s - loss: 1.69 - ETA: 24s - loss: 1.69 - ETA: 20s - loss: 1.69 - ETA: 16s - loss: 1.69 - ETA: 12s - loss: 1.69 - ETA: 8s - loss: 1.6910 - ETA: 4s - loss: 1.6910WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 416s 4s/step - loss: 1.6908\n",
      "Epoch 8/100\n",
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.648 - ETA: 6:45 - loss: 1.647 - ETA: 6:41 - loss: 1.653 - ETA: 6:37 - loss: 1.656 - ETA: 6:33 - loss: 1.657 - ETA: 6:30 - loss: 1.663 - ETA: 6:25 - loss: 1.665 - ETA: 6:21 - loss: 1.663 - ETA: 6:16 - loss: 1.661 - ETA: 6:12 - loss: 1.658 - ETA: 6:08 - loss: 1.655 - ETA: 6:04 - loss: 1.655 - ETA: 6:00 - loss: 1.651 - ETA: 5:56 - loss: 1.654 - ETA: 5:52 - loss: 1.653 - ETA: 5:48 - loss: 1.653 - ETA: 5:44 - loss: 1.655 - ETA: 5:40 - loss: 1.656 - ETA: 5:35 - loss: 1.655 - ETA: 5:31 - loss: 1.654 - ETA: 5:27 - loss: 1.652 - ETA: 5:23 - loss: 1.651 - ETA: 5:19 - loss: 1.652 - ETA: 5:15 - loss: 1.651 - ETA: 5:10 - loss: 1.650 - ETA: 5:06 - loss: 1.650 - ETA: 5:02 - loss: 1.649 - ETA: 4:58 - loss: 1.650 - ETA: 4:54 - loss: 1.649 - ETA: 4:50 - loss: 1.648 - ETA: 4:46 - loss: 1.646 - ETA: 4:42 - loss: 1.646 - ETA: 4:37 - loss: 1.644 - ETA: 4:33 - loss: 1.644 - ETA: 4:29 - loss: 1.644 - ETA: 4:25 - loss: 1.643 - ETA: 4:21 - loss: 1.644 - ETA: 4:17 - loss: 1.644 - ETA: 4:13 - loss: 1.643 - ETA: 4:09 - loss: 1.641 - ETA: 4:04 - loss: 1.641 - ETA: 4:00 - loss: 1.640 - ETA: 3:56 - loss: 1.640 - ETA: 3:52 - loss: 1.640 - ETA: 3:48 - loss: 1.639 - ETA: 3:44 - loss: 1.639 - ETA: 3:39 - loss: 1.638 - ETA: 3:35 - loss: 1.638 - ETA: 3:31 - loss: 1.638 - ETA: 3:27 - loss: 1.638 - ETA: 3:23 - loss: 1.639 - ETA: 3:19 - loss: 1.638 - ETA: 3:14 - loss: 1.637 - ETA: 3:10 - loss: 1.637 - ETA: 3:06 - loss: 1.636 - ETA: 3:02 - loss: 1.636 - ETA: 2:58 - loss: 1.635 - ETA: 2:54 - loss: 1.634 - ETA: 2:50 - loss: 1.634 - ETA: 2:45 - loss: 1.633 - ETA: 2:41 - loss: 1.633 - ETA: 2:37 - loss: 1.632 - ETA: 2:33 - loss: 1.633 - ETA: 2:29 - loss: 1.632 - ETA: 2:25 - loss: 1.633 - ETA: 2:21 - loss: 1.633 - ETA: 2:16 - loss: 1.633 - ETA: 2:12 - loss: 1.632 - ETA: 2:08 - loss: 1.632 - ETA: 2:04 - loss: 1.632 - ETA: 2:00 - loss: 1.631 - ETA: 1:56 - loss: 1.632 - ETA: 1:52 - loss: 1.632 - ETA: 1:47 - loss: 1.631 - ETA: 1:43 - loss: 1.631 - ETA: 1:39 - loss: 1.631 - ETA: 1:35 - loss: 1.630 - ETA: 1:31 - loss: 1.630 - ETA: 1:27 - loss: 1.630 - ETA: 1:22 - loss: 1.629 - ETA: 1:18 - loss: 1.629 - ETA: 1:14 - loss: 1.630 - ETA: 1:10 - loss: 1.629 - ETA: 1:06 - loss: 1.628 - ETA: 1:02 - loss: 1.628 - ETA: 58s - loss: 1.628 - ETA: 53s - loss: 1.62 - ETA: 49s - loss: 1.62 - ETA: 45s - loss: 1.62 - ETA: 41s - loss: 1.62 - ETA: 37s - loss: 1.62 - ETA: 33s - loss: 1.62 - ETA: 29s - loss: 1.62 - ETA: 24s - loss: 1.62 - ETA: 20s - loss: 1.62 - ETA: 16s - loss: 1.62 - ETA: 12s - loss: 1.62 - ETA: 8s - loss: 1.6232 - ETA: 4s - loss: 1.6229WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.6227\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.659 - ETA: 6:46 - loss: 1.646 - ETA: 6:41 - loss: 1.642 - ETA: 6:37 - loss: 1.645 - ETA: 6:33 - loss: 1.631 - ETA: 6:29 - loss: 1.622 - ETA: 6:25 - loss: 1.615 - ETA: 6:21 - loss: 1.608 - ETA: 6:17 - loss: 1.612 - ETA: 6:13 - loss: 1.613 - ETA: 6:09 - loss: 1.608 - ETA: 6:05 - loss: 1.611 - ETA: 6:00 - loss: 1.615 - ETA: 5:56 - loss: 1.610 - ETA: 5:52 - loss: 1.608 - ETA: 5:48 - loss: 1.609 - ETA: 5:44 - loss: 1.606 - ETA: 5:40 - loss: 1.607 - ETA: 5:35 - loss: 1.609 - ETA: 5:31 - loss: 1.609 - ETA: 5:27 - loss: 1.608 - ETA: 5:23 - loss: 1.608 - ETA: 5:19 - loss: 1.608 - ETA: 5:15 - loss: 1.608 - ETA: 5:11 - loss: 1.606 - ETA: 5:06 - loss: 1.605 - ETA: 5:02 - loss: 1.606 - ETA: 4:58 - loss: 1.603 - ETA: 4:54 - loss: 1.602 - ETA: 4:50 - loss: 1.602 - ETA: 4:46 - loss: 1.601 - ETA: 4:42 - loss: 1.601 - ETA: 4:38 - loss: 1.601 - ETA: 4:34 - loss: 1.602 - ETA: 4:29 - loss: 1.601 - ETA: 4:25 - loss: 1.601 - ETA: 4:21 - loss: 1.600 - ETA: 4:17 - loss: 1.600 - ETA: 4:13 - loss: 1.600 - ETA: 4:09 - loss: 1.600 - ETA: 4:04 - loss: 1.599 - ETA: 4:00 - loss: 1.598 - ETA: 3:56 - loss: 1.597 - ETA: 3:52 - loss: 1.597 - ETA: 3:48 - loss: 1.597 - ETA: 3:44 - loss: 1.596 - ETA: 3:39 - loss: 1.596 - ETA: 3:35 - loss: 1.596 - ETA: 3:31 - loss: 1.597 - ETA: 3:27 - loss: 1.597 - ETA: 3:23 - loss: 1.597 - ETA: 3:19 - loss: 1.598 - ETA: 3:15 - loss: 1.598 - ETA: 3:10 - loss: 1.597 - ETA: 3:06 - loss: 1.596 - ETA: 3:02 - loss: 1.595 - ETA: 2:58 - loss: 1.595 - ETA: 2:54 - loss: 1.595 - ETA: 2:50 - loss: 1.595 - ETA: 2:46 - loss: 1.595 - ETA: 2:41 - loss: 1.594 - ETA: 2:37 - loss: 1.594 - ETA: 2:33 - loss: 1.593 - ETA: 2:29 - loss: 1.593 - ETA: 2:25 - loss: 1.592 - ETA: 2:21 - loss: 1.591 - ETA: 2:16 - loss: 1.591 - ETA: 2:12 - loss: 1.590 - ETA: 2:08 - loss: 1.589 - ETA: 2:04 - loss: 1.589 - ETA: 2:00 - loss: 1.589 - ETA: 1:56 - loss: 1.588 - ETA: 1:52 - loss: 1.588 - ETA: 1:47 - loss: 1.588 - ETA: 1:43 - loss: 1.587 - ETA: 1:39 - loss: 1.586 - ETA: 1:35 - loss: 1.586 - ETA: 1:31 - loss: 1.586 - ETA: 1:27 - loss: 1.586 - ETA: 1:23 - loss: 1.586 - ETA: 1:18 - loss: 1.585 - ETA: 1:14 - loss: 1.585 - ETA: 1:10 - loss: 1.584 - ETA: 1:06 - loss: 1.584 - ETA: 1:02 - loss: 1.584 - ETA: 58s - loss: 1.583 - ETA: 53s - loss: 1.58 - ETA: 49s - loss: 1.58 - ETA: 45s - loss: 1.58 - ETA: 41s - loss: 1.58 - ETA: 37s - loss: 1.58 - ETA: 33s - loss: 1.58 - ETA: 29s - loss: 1.58 - ETA: 24s - loss: 1.58 - ETA: 20s - loss: 1.58 - ETA: 16s - loss: 1.58 - ETA: 12s - loss: 1.58 - ETA: 8s - loss: 1.5834 - ETA: 4s - loss: 1.5831WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.5823\n",
      "Epoch 10/100\n",
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.574 - ETA: 6:45 - loss: 1.583 - ETA: 6:42 - loss: 1.570 - ETA: 6:38 - loss: 1.578 - ETA: 6:34 - loss: 1.565 - ETA: 6:29 - loss: 1.564 - ETA: 6:25 - loss: 1.561 - ETA: 6:21 - loss: 1.560 - ETA: 6:17 - loss: 1.560 - ETA: 6:13 - loss: 1.558 - ETA: 6:09 - loss: 1.560 - ETA: 6:05 - loss: 1.560 - ETA: 6:01 - loss: 1.562 - ETA: 5:57 - loss: 1.559 - ETA: 5:53 - loss: 1.561 - ETA: 5:48 - loss: 1.559 - ETA: 5:44 - loss: 1.561 - ETA: 5:40 - loss: 1.559 - ETA: 5:36 - loss: 1.560 - ETA: 5:32 - loss: 1.558 - ETA: 5:28 - loss: 1.560 - ETA: 5:23 - loss: 1.560 - ETA: 5:19 - loss: 1.560 - ETA: 5:15 - loss: 1.560 - ETA: 5:11 - loss: 1.560 - ETA: 5:07 - loss: 1.560 - ETA: 5:03 - loss: 1.559 - ETA: 4:58 - loss: 1.560 - ETA: 4:54 - loss: 1.558 - ETA: 4:50 - loss: 1.559 - ETA: 4:46 - loss: 1.559 - ETA: 4:42 - loss: 1.560 - ETA: 4:38 - loss: 1.559 - ETA: 4:34 - loss: 1.559 - ETA: 4:29 - loss: 1.559 - ETA: 4:25 - loss: 1.559 - ETA: 4:21 - loss: 1.559 - ETA: 4:17 - loss: 1.558 - ETA: 4:13 - loss: 1.558 - ETA: 4:09 - loss: 1.559 - ETA: 4:04 - loss: 1.559 - ETA: 4:00 - loss: 1.559 - ETA: 3:56 - loss: 1.558 - ETA: 3:52 - loss: 1.558 - ETA: 3:48 - loss: 1.558 - ETA: 3:44 - loss: 1.557 - ETA: 3:40 - loss: 1.557 - ETA: 3:35 - loss: 1.558 - ETA: 3:31 - loss: 1.557 - ETA: 3:27 - loss: 1.556 - ETA: 3:23 - loss: 1.556 - ETA: 3:19 - loss: 1.556 - ETA: 3:15 - loss: 1.556 - ETA: 3:11 - loss: 1.555 - ETA: 3:06 - loss: 1.555 - ETA: 3:02 - loss: 1.555 - ETA: 2:58 - loss: 1.554 - ETA: 2:54 - loss: 1.553 - ETA: 2:50 - loss: 1.553 - ETA: 2:46 - loss: 1.553 - ETA: 2:41 - loss: 1.553 - ETA: 2:37 - loss: 1.552 - ETA: 2:33 - loss: 1.552 - ETA: 2:29 - loss: 1.551 - ETA: 2:25 - loss: 1.550 - ETA: 2:21 - loss: 1.550 - ETA: 2:17 - loss: 1.550 - ETA: 2:12 - loss: 1.549 - ETA: 2:08 - loss: 1.550 - ETA: 2:04 - loss: 1.550 - ETA: 2:00 - loss: 1.550 - ETA: 1:56 - loss: 1.549 - ETA: 1:52 - loss: 1.549 - ETA: 1:47 - loss: 1.548 - ETA: 1:43 - loss: 1.548 - ETA: 1:39 - loss: 1.548 - ETA: 1:35 - loss: 1.547 - ETA: 1:31 - loss: 1.547 - ETA: 1:27 - loss: 1.546 - ETA: 1:22 - loss: 1.546 - ETA: 1:18 - loss: 1.546 - ETA: 1:14 - loss: 1.546 - ETA: 1:10 - loss: 1.545 - ETA: 1:06 - loss: 1.545 - ETA: 1:02 - loss: 1.545 - ETA: 58s - loss: 1.546 - ETA: 53s - loss: 1.54 - ETA: 49s - loss: 1.54 - ETA: 45s - loss: 1.54 - ETA: 41s - loss: 1.54 - ETA: 37s - loss: 1.54 - ETA: 33s - loss: 1.54 - ETA: 29s - loss: 1.54 - ETA: 24s - loss: 1.54 - ETA: 20s - loss: 1.54 - ETA: 16s - loss: 1.54 - ETA: 12s - loss: 1.54 - ETA: 8s - loss: 1.5447 - ETA: 4s - loss: 1.5441WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.5439\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.531 - ETA: 6:45 - loss: 1.529 - ETA: 6:41 - loss: 1.527 - ETA: 6:37 - loss: 1.526 - ETA: 6:33 - loss: 1.530 - ETA: 6:29 - loss: 1.539 - ETA: 6:25 - loss: 1.538 - ETA: 6:21 - loss: 1.537 - ETA: 6:16 - loss: 1.530 - ETA: 6:12 - loss: 1.526 - ETA: 6:08 - loss: 1.529 - ETA: 6:04 - loss: 1.524 - ETA: 6:00 - loss: 1.523 - ETA: 5:55 - loss: 1.521 - ETA: 5:51 - loss: 1.524 - ETA: 5:47 - loss: 1.523 - ETA: 5:43 - loss: 1.519 - ETA: 5:39 - loss: 1.520 - ETA: 5:35 - loss: 1.519 - ETA: 5:31 - loss: 1.517 - ETA: 5:27 - loss: 1.515 - ETA: 5:22 - loss: 1.518 - ETA: 5:18 - loss: 1.518 - ETA: 5:14 - loss: 1.516 - ETA: 5:10 - loss: 1.517 - ETA: 5:06 - loss: 1.515 - ETA: 5:02 - loss: 1.517 - ETA: 4:58 - loss: 1.518 - ETA: 4:54 - loss: 1.517 - ETA: 4:49 - loss: 1.517 - ETA: 4:45 - loss: 1.517 - ETA: 4:41 - loss: 1.519 - ETA: 4:37 - loss: 1.519 - ETA: 4:33 - loss: 1.520 - ETA: 4:29 - loss: 1.520 - ETA: 4:25 - loss: 1.519 - ETA: 4:21 - loss: 1.520 - ETA: 4:16 - loss: 1.520 - ETA: 4:12 - loss: 1.521 - ETA: 4:08 - loss: 1.520 - ETA: 4:04 - loss: 1.520 - ETA: 4:00 - loss: 1.521 - ETA: 3:56 - loss: 1.520 - ETA: 3:52 - loss: 1.520 - ETA: 3:47 - loss: 1.520 - ETA: 3:43 - loss: 1.519 - ETA: 3:39 - loss: 1.518 - ETA: 3:35 - loss: 1.519 - ETA: 3:31 - loss: 1.518 - ETA: 3:27 - loss: 1.518 - ETA: 3:23 - loss: 1.518 - ETA: 3:19 - loss: 1.518 - ETA: 3:15 - loss: 1.517 - ETA: 3:11 - loss: 1.517 - ETA: 3:06 - loss: 1.517 - ETA: 3:02 - loss: 1.516 - ETA: 2:58 - loss: 1.517 - ETA: 2:54 - loss: 1.517 - ETA: 2:50 - loss: 1.517 - ETA: 2:46 - loss: 1.517 - ETA: 2:41 - loss: 1.517 - ETA: 2:37 - loss: 1.518 - ETA: 2:33 - loss: 1.517 - ETA: 2:29 - loss: 1.517 - ETA: 2:25 - loss: 1.517 - ETA: 2:21 - loss: 1.517 - ETA: 2:17 - loss: 1.517 - ETA: 2:12 - loss: 1.517 - ETA: 2:08 - loss: 1.517 - ETA: 2:04 - loss: 1.517 - ETA: 2:00 - loss: 1.517 - ETA: 1:56 - loss: 1.517 - ETA: 1:52 - loss: 1.516 - ETA: 1:47 - loss: 1.516 - ETA: 1:43 - loss: 1.516 - ETA: 1:39 - loss: 1.515 - ETA: 1:35 - loss: 1.515 - ETA: 1:31 - loss: 1.515 - ETA: 1:27 - loss: 1.514 - ETA: 1:23 - loss: 1.514 - ETA: 1:18 - loss: 1.514 - ETA: 1:14 - loss: 1.513 - ETA: 1:10 - loss: 1.513 - ETA: 1:06 - loss: 1.513 - ETA: 1:02 - loss: 1.512 - ETA: 58s - loss: 1.512 - ETA: 53s - loss: 1.51 - ETA: 49s - loss: 1.51 - ETA: 45s - loss: 1.51 - ETA: 41s - loss: 1.51 - ETA: 37s - loss: 1.51 - ETA: 33s - loss: 1.51 - ETA: 29s - loss: 1.50 - ETA: 24s - loss: 1.50 - ETA: 20s - loss: 1.50 - ETA: 16s - loss: 1.50 - ETA: 12s - loss: 1.50 - ETA: 8s - loss: 1.5084 - ETA: 4s - loss: 1.5081WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.5073\n",
      "Epoch 12/100\n",
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.533 - ETA: 6:46 - loss: 1.507 - ETA: 6:41 - loss: 1.505 - ETA: 6:36 - loss: 1.492 - ETA: 6:32 - loss: 1.492 - ETA: 6:28 - loss: 1.478 - ETA: 6:24 - loss: 1.481 - ETA: 6:20 - loss: 1.486 - ETA: 6:16 - loss: 1.484 - ETA: 6:12 - loss: 1.485 - ETA: 6:08 - loss: 1.486 - ETA: 6:04 - loss: 1.481 - ETA: 6:00 - loss: 1.485 - ETA: 5:56 - loss: 1.486 - ETA: 5:51 - loss: 1.482 - ETA: 5:47 - loss: 1.482 - ETA: 5:43 - loss: 1.485 - ETA: 5:39 - loss: 1.487 - ETA: 5:35 - loss: 1.485 - ETA: 5:31 - loss: 1.483 - ETA: 5:27 - loss: 1.483 - ETA: 5:22 - loss: 1.485 - ETA: 5:18 - loss: 1.484 - ETA: 5:14 - loss: 1.486 - ETA: 5:10 - loss: 1.485 - ETA: 5:06 - loss: 1.486 - ETA: 5:02 - loss: 1.484 - ETA: 4:58 - loss: 1.484 - ETA: 4:54 - loss: 1.483 - ETA: 4:49 - loss: 1.484 - ETA: 4:45 - loss: 1.486 - ETA: 4:41 - loss: 1.484 - ETA: 4:37 - loss: 1.484 - ETA: 4:33 - loss: 1.484 - ETA: 4:29 - loss: 1.486 - ETA: 4:25 - loss: 1.486 - ETA: 4:20 - loss: 1.485 - ETA: 4:16 - loss: 1.484 - ETA: 4:12 - loss: 1.484 - ETA: 4:08 - loss: 1.483 - ETA: 4:04 - loss: 1.482 - ETA: 4:00 - loss: 1.481 - ETA: 3:56 - loss: 1.482 - ETA: 3:51 - loss: 1.483 - ETA: 3:47 - loss: 1.482 - ETA: 3:43 - loss: 1.482 - ETA: 3:39 - loss: 1.481 - ETA: 3:35 - loss: 1.482 - ETA: 3:31 - loss: 1.483 - ETA: 3:27 - loss: 1.482 - ETA: 3:22 - loss: 1.482 - ETA: 3:18 - loss: 1.482 - ETA: 3:14 - loss: 1.481 - ETA: 3:10 - loss: 1.481 - ETA: 3:06 - loss: 1.481 - ETA: 3:02 - loss: 1.481 - ETA: 2:58 - loss: 1.481 - ETA: 2:53 - loss: 1.481 - ETA: 2:49 - loss: 1.479 - ETA: 2:45 - loss: 1.480 - ETA: 2:41 - loss: 1.480 - ETA: 2:37 - loss: 1.481 - ETA: 2:33 - loss: 1.480 - ETA: 2:29 - loss: 1.479 - ETA: 2:24 - loss: 1.480 - ETA: 2:20 - loss: 1.479 - ETA: 2:16 - loss: 1.480 - ETA: 2:12 - loss: 1.480 - ETA: 2:08 - loss: 1.480 - ETA: 2:04 - loss: 1.480 - ETA: 2:00 - loss: 1.481 - ETA: 1:56 - loss: 1.481 - ETA: 1:51 - loss: 1.481 - ETA: 1:47 - loss: 1.482 - ETA: 1:43 - loss: 1.482 - ETA: 1:39 - loss: 1.482 - ETA: 1:35 - loss: 1.481 - ETA: 1:31 - loss: 1.481 - ETA: 1:27 - loss: 1.481 - ETA: 1:22 - loss: 1.480 - ETA: 1:18 - loss: 1.479 - ETA: 1:14 - loss: 1.479 - ETA: 1:10 - loss: 1.478 - ETA: 1:06 - loss: 1.478 - ETA: 1:02 - loss: 1.478 - ETA: 58s - loss: 1.478 - ETA: 53s - loss: 1.47 - ETA: 49s - loss: 1.47 - ETA: 45s - loss: 1.47 - ETA: 41s - loss: 1.47 - ETA: 37s - loss: 1.47 - ETA: 33s - loss: 1.47 - ETA: 29s - loss: 1.47 - ETA: 24s - loss: 1.47 - ETA: 20s - loss: 1.47 - ETA: 16s - loss: 1.47 - ETA: 12s - loss: 1.47 - ETA: 8s - loss: 1.4778 - ETA: 4s - loss: 1.4776WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.4777\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.464 - ETA: 6:45 - loss: 1.490 - ETA: 6:41 - loss: 1.482 - ETA: 6:36 - loss: 1.473 - ETA: 6:33 - loss: 1.463 - ETA: 6:29 - loss: 1.463 - ETA: 6:24 - loss: 1.459 - ETA: 6:20 - loss: 1.463 - ETA: 6:16 - loss: 1.465 - ETA: 6:12 - loss: 1.467 - ETA: 6:08 - loss: 1.467 - ETA: 6:04 - loss: 1.466 - ETA: 6:00 - loss: 1.463 - ETA: 5:56 - loss: 1.460 - ETA: 5:52 - loss: 1.462 - ETA: 5:48 - loss: 1.460 - ETA: 5:44 - loss: 1.459 - ETA: 5:39 - loss: 1.459 - ETA: 5:35 - loss: 1.457 - ETA: 5:31 - loss: 1.459 - ETA: 5:27 - loss: 1.460 - ETA: 5:23 - loss: 1.458 - ETA: 5:19 - loss: 1.458 - ETA: 5:15 - loss: 1.458 - ETA: 5:10 - loss: 1.458 - ETA: 5:06 - loss: 1.458 - ETA: 5:02 - loss: 1.460 - ETA: 4:58 - loss: 1.460 - ETA: 4:54 - loss: 1.460 - ETA: 4:50 - loss: 1.461 - ETA: 4:46 - loss: 1.460 - ETA: 4:41 - loss: 1.460 - ETA: 4:37 - loss: 1.461 - ETA: 4:33 - loss: 1.461 - ETA: 4:29 - loss: 1.460 - ETA: 4:25 - loss: 1.460 - ETA: 4:21 - loss: 1.459 - ETA: 4:16 - loss: 1.460 - ETA: 4:12 - loss: 1.459 - ETA: 4:08 - loss: 1.460 - ETA: 4:04 - loss: 1.460 - ETA: 4:00 - loss: 1.461 - ETA: 3:56 - loss: 1.461 - ETA: 3:52 - loss: 1.461 - ETA: 3:48 - loss: 1.461 - ETA: 3:43 - loss: 1.461 - ETA: 3:39 - loss: 1.461 - ETA: 3:35 - loss: 1.462 - ETA: 3:31 - loss: 1.463 - ETA: 3:27 - loss: 1.463 - ETA: 3:23 - loss: 1.463 - ETA: 3:18 - loss: 1.463 - ETA: 3:14 - loss: 1.463 - ETA: 3:10 - loss: 1.462 - ETA: 3:06 - loss: 1.462 - ETA: 3:02 - loss: 1.463 - ETA: 2:58 - loss: 1.462 - ETA: 2:54 - loss: 1.462 - ETA: 2:50 - loss: 1.462 - ETA: 2:45 - loss: 1.461 - ETA: 2:41 - loss: 1.461 - ETA: 2:37 - loss: 1.462 - ETA: 2:33 - loss: 1.462 - ETA: 2:29 - loss: 1.463 - ETA: 2:25 - loss: 1.463 - ETA: 2:21 - loss: 1.463 - ETA: 2:17 - loss: 1.463 - ETA: 2:12 - loss: 1.463 - ETA: 2:08 - loss: 1.463 - ETA: 2:04 - loss: 1.463 - ETA: 2:00 - loss: 1.463 - ETA: 1:56 - loss: 1.464 - ETA: 1:52 - loss: 1.464 - ETA: 1:47 - loss: 1.464 - ETA: 1:43 - loss: 1.463 - ETA: 1:39 - loss: 1.463 - ETA: 1:35 - loss: 1.463 - ETA: 1:31 - loss: 1.463 - ETA: 1:27 - loss: 1.463 - ETA: 1:22 - loss: 1.463 - ETA: 1:18 - loss: 1.463 - ETA: 1:14 - loss: 1.463 - ETA: 1:10 - loss: 1.462 - ETA: 1:06 - loss: 1.463 - ETA: 1:02 - loss: 1.462 - ETA: 58s - loss: 1.463 - ETA: 53s - loss: 1.46 - ETA: 49s - loss: 1.46 - ETA: 45s - loss: 1.46 - ETA: 41s - loss: 1.46 - ETA: 37s - loss: 1.46 - ETA: 33s - loss: 1.46 - ETA: 29s - loss: 1.46 - ETA: 24s - loss: 1.46 - ETA: 20s - loss: 1.46 - ETA: 16s - loss: 1.46 - ETA: 12s - loss: 1.46 - ETA: 8s - loss: 1.4634 - ETA: 4s - loss: 1.4632WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.4632\n",
      "Epoch 14/100\n",
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.489 - ETA: 6:45 - loss: 1.482 - ETA: 6:40 - loss: 1.472 - ETA: 6:36 - loss: 1.450 - ETA: 6:32 - loss: 1.458 - ETA: 6:28 - loss: 1.463 - ETA: 6:24 - loss: 1.459 - ETA: 6:20 - loss: 1.457 - ETA: 6:16 - loss: 1.460 - ETA: 6:12 - loss: 1.461 - ETA: 6:07 - loss: 1.459 - ETA: 6:03 - loss: 1.458 - ETA: 5:59 - loss: 1.458 - ETA: 5:56 - loss: 1.457 - ETA: 5:52 - loss: 1.458 - ETA: 5:48 - loss: 1.456 - ETA: 5:44 - loss: 1.453 - ETA: 5:39 - loss: 1.452 - ETA: 5:35 - loss: 1.453 - ETA: 5:31 - loss: 1.452 - ETA: 5:27 - loss: 1.452 - ETA: 5:23 - loss: 1.451 - ETA: 5:19 - loss: 1.452 - ETA: 5:15 - loss: 1.450 - ETA: 5:10 - loss: 1.448 - ETA: 5:06 - loss: 1.447 - ETA: 5:02 - loss: 1.447 - ETA: 4:58 - loss: 1.449 - ETA: 4:54 - loss: 1.449 - ETA: 4:50 - loss: 1.449 - ETA: 4:45 - loss: 1.448 - ETA: 4:41 - loss: 1.450 - ETA: 4:37 - loss: 1.447 - ETA: 4:33 - loss: 1.447 - ETA: 4:29 - loss: 1.447 - ETA: 4:25 - loss: 1.449 - ETA: 4:21 - loss: 1.449 - ETA: 4:16 - loss: 1.449 - ETA: 4:12 - loss: 1.448 - ETA: 4:08 - loss: 1.448 - ETA: 4:04 - loss: 1.448 - ETA: 4:00 - loss: 1.448 - ETA: 3:56 - loss: 1.447 - ETA: 3:52 - loss: 1.447 - ETA: 3:47 - loss: 1.447 - ETA: 3:43 - loss: 1.448 - ETA: 3:39 - loss: 1.448 - ETA: 3:35 - loss: 1.447 - ETA: 3:31 - loss: 1.447 - ETA: 3:27 - loss: 1.447 - ETA: 3:23 - loss: 1.447 - ETA: 3:18 - loss: 1.447 - ETA: 3:14 - loss: 1.448 - ETA: 3:10 - loss: 1.448 - ETA: 3:06 - loss: 1.448 - ETA: 3:02 - loss: 1.448 - ETA: 2:58 - loss: 1.450 - ETA: 2:53 - loss: 1.449 - ETA: 2:49 - loss: 1.448 - ETA: 2:45 - loss: 1.448 - ETA: 2:41 - loss: 1.447 - ETA: 2:37 - loss: 1.447 - ETA: 2:33 - loss: 1.447 - ETA: 2:29 - loss: 1.446 - ETA: 2:24 - loss: 1.446 - ETA: 2:20 - loss: 1.446 - ETA: 2:16 - loss: 1.446 - ETA: 2:12 - loss: 1.446 - ETA: 2:08 - loss: 1.447 - ETA: 2:04 - loss: 1.447 - ETA: 2:00 - loss: 1.447 - ETA: 1:55 - loss: 1.447 - ETA: 1:51 - loss: 1.447 - ETA: 1:47 - loss: 1.447 - ETA: 1:43 - loss: 1.447 - ETA: 1:39 - loss: 1.446 - ETA: 1:35 - loss: 1.447 - ETA: 1:31 - loss: 1.447 - ETA: 1:26 - loss: 1.447 - ETA: 1:22 - loss: 1.447 - ETA: 1:18 - loss: 1.446 - ETA: 1:14 - loss: 1.446 - ETA: 1:10 - loss: 1.446 - ETA: 1:06 - loss: 1.446 - ETA: 1:02 - loss: 1.446 - ETA: 57s - loss: 1.445 - ETA: 53s - loss: 1.44 - ETA: 49s - loss: 1.44 - ETA: 45s - loss: 1.44 - ETA: 41s - loss: 1.44 - ETA: 37s - loss: 1.44 - ETA: 33s - loss: 1.44 - ETA: 28s - loss: 1.44 - ETA: 24s - loss: 1.44 - ETA: 20s - loss: 1.44 - ETA: 16s - loss: 1.44 - ETA: 12s - loss: 1.44 - ETA: 8s - loss: 1.4419 - ETA: 4s - loss: 1.4422WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.4421\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.443 - ETA: 6:45 - loss: 1.409 - ETA: 6:42 - loss: 1.405 - ETA: 6:38 - loss: 1.420 - ETA: 6:33 - loss: 1.418 - ETA: 6:29 - loss: 1.418 - ETA: 6:25 - loss: 1.416 - ETA: 6:21 - loss: 1.416 - ETA: 6:17 - loss: 1.414 - ETA: 6:12 - loss: 1.417 - ETA: 6:08 - loss: 1.418 - ETA: 6:04 - loss: 1.417 - ETA: 6:00 - loss: 1.417 - ETA: 5:56 - loss: 1.417 - ETA: 5:52 - loss: 1.416 - ETA: 5:48 - loss: 1.419 - ETA: 5:43 - loss: 1.418 - ETA: 5:39 - loss: 1.418 - ETA: 5:35 - loss: 1.419 - ETA: 5:31 - loss: 1.417 - ETA: 5:27 - loss: 1.415 - ETA: 5:23 - loss: 1.416 - ETA: 5:19 - loss: 1.417 - ETA: 5:15 - loss: 1.418 - ETA: 5:11 - loss: 1.418 - ETA: 5:07 - loss: 1.419 - ETA: 5:02 - loss: 1.421 - ETA: 4:58 - loss: 1.421 - ETA: 4:54 - loss: 1.422 - ETA: 4:50 - loss: 1.421 - ETA: 4:46 - loss: 1.420 - ETA: 4:42 - loss: 1.420 - ETA: 4:38 - loss: 1.420 - ETA: 4:33 - loss: 1.419 - ETA: 4:29 - loss: 1.419 - ETA: 4:25 - loss: 1.418 - ETA: 4:21 - loss: 1.418 - ETA: 4:17 - loss: 1.418 - ETA: 4:13 - loss: 1.417 - ETA: 4:08 - loss: 1.417 - ETA: 4:04 - loss: 1.417 - ETA: 4:00 - loss: 1.418 - ETA: 3:56 - loss: 1.419 - ETA: 3:52 - loss: 1.419 - ETA: 3:48 - loss: 1.418 - ETA: 3:44 - loss: 1.419 - ETA: 3:39 - loss: 1.419 - ETA: 3:35 - loss: 1.419 - ETA: 3:31 - loss: 1.419 - ETA: 3:27 - loss: 1.418 - ETA: 3:23 - loss: 1.418 - ETA: 3:19 - loss: 1.418 - ETA: 3:15 - loss: 1.419 - ETA: 3:10 - loss: 1.419 - ETA: 3:06 - loss: 1.419 - ETA: 3:02 - loss: 1.419 - ETA: 2:58 - loss: 1.419 - ETA: 2:54 - loss: 1.418 - ETA: 2:50 - loss: 1.418 - ETA: 2:46 - loss: 1.418 - ETA: 2:41 - loss: 1.419 - ETA: 2:37 - loss: 1.419 - ETA: 2:33 - loss: 1.419 - ETA: 2:29 - loss: 1.418 - ETA: 2:25 - loss: 1.418 - ETA: 2:21 - loss: 1.418 - ETA: 2:17 - loss: 1.418 - ETA: 2:13 - loss: 1.417 - ETA: 2:09 - loss: 1.417 - ETA: 2:05 - loss: 1.417 - ETA: 2:01 - loss: 1.416 - ETA: 1:56 - loss: 1.415 - ETA: 1:52 - loss: 1.415 - ETA: 1:48 - loss: 1.415 - ETA: 1:44 - loss: 1.414 - ETA: 1:40 - loss: 1.414 - ETA: 1:36 - loss: 1.414 - ETA: 1:32 - loss: 1.414 - ETA: 1:27 - loss: 1.414 - ETA: 1:23 - loss: 1.413 - ETA: 1:19 - loss: 1.413 - ETA: 1:15 - loss: 1.414 - ETA: 1:11 - loss: 1.414 - ETA: 1:07 - loss: 1.414 - ETA: 1:03 - loss: 1.414 - ETA: 58s - loss: 1.413 - ETA: 54s - loss: 1.41 - ETA: 50s - loss: 1.41 - ETA: 46s - loss: 1.41 - ETA: 42s - loss: 1.41 - ETA: 37s - loss: 1.41 - ETA: 33s - loss: 1.41 - ETA: 29s - loss: 1.41 - ETA: 25s - loss: 1.41 - ETA: 21s - loss: 1.41 - ETA: 16s - loss: 1.41 - ETA: 12s - loss: 1.41 - ETA: 8s - loss: 1.4136 - ETA: 4s - loss: 1.4135WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 420s 4s/step - loss: 1.4133\n",
      "Epoch 16/100\n",
      " 99/100 [============================>.] - ETA: 6:52 - loss: 1.411 - ETA: 6:47 - loss: 1.406 - ETA: 6:42 - loss: 1.394 - ETA: 6:38 - loss: 1.399 - ETA: 6:34 - loss: 1.406 - ETA: 6:30 - loss: 1.403 - ETA: 6:26 - loss: 1.399 - ETA: 6:22 - loss: 1.396 - ETA: 6:17 - loss: 1.395 - ETA: 6:13 - loss: 1.394 - ETA: 6:09 - loss: 1.393 - ETA: 6:05 - loss: 1.396 - ETA: 6:00 - loss: 1.396 - ETA: 5:56 - loss: 1.395 - ETA: 5:52 - loss: 1.397 - ETA: 5:49 - loss: 1.396 - ETA: 5:45 - loss: 1.397 - ETA: 5:42 - loss: 1.396 - ETA: 5:38 - loss: 1.400 - ETA: 5:34 - loss: 1.401 - ETA: 5:29 - loss: 1.403 - ETA: 5:25 - loss: 1.404 - ETA: 5:21 - loss: 1.404 - ETA: 5:17 - loss: 1.404 - ETA: 5:12 - loss: 1.404 - ETA: 5:08 - loss: 1.401 - ETA: 5:04 - loss: 1.401 - ETA: 5:00 - loss: 1.399 - ETA: 4:56 - loss: 1.399 - ETA: 4:52 - loss: 1.398 - ETA: 4:48 - loss: 1.397 - ETA: 4:44 - loss: 1.397 - ETA: 4:40 - loss: 1.396 - ETA: 4:36 - loss: 1.397 - ETA: 4:32 - loss: 1.397 - ETA: 4:27 - loss: 1.396 - ETA: 4:23 - loss: 1.397 - ETA: 4:19 - loss: 1.396 - ETA: 4:15 - loss: 1.396 - ETA: 4:11 - loss: 1.396 - ETA: 4:07 - loss: 1.395 - ETA: 4:03 - loss: 1.395 - ETA: 3:59 - loss: 1.395 - ETA: 3:55 - loss: 1.395 - ETA: 3:50 - loss: 1.396 - ETA: 3:46 - loss: 1.396 - ETA: 3:42 - loss: 1.397 - ETA: 3:38 - loss: 1.396 - ETA: 3:33 - loss: 1.397 - ETA: 3:29 - loss: 1.397 - ETA: 3:25 - loss: 1.397 - ETA: 3:21 - loss: 1.397 - ETA: 3:17 - loss: 1.398 - ETA: 3:13 - loss: 1.399 - ETA: 3:09 - loss: 1.398 - ETA: 3:04 - loss: 1.399 - ETA: 3:00 - loss: 1.399 - ETA: 2:56 - loss: 1.399 - ETA: 2:52 - loss: 1.399 - ETA: 2:48 - loss: 1.399 - ETA: 2:44 - loss: 1.399 - ETA: 2:39 - loss: 1.398 - ETA: 2:35 - loss: 1.398 - ETA: 2:31 - loss: 1.397 - ETA: 2:27 - loss: 1.398 - ETA: 2:23 - loss: 1.397 - ETA: 2:19 - loss: 1.398 - ETA: 2:14 - loss: 1.399 - ETA: 2:10 - loss: 1.399 - ETA: 2:06 - loss: 1.399 - ETA: 2:02 - loss: 1.399 - ETA: 1:57 - loss: 1.400 - ETA: 1:53 - loss: 1.399 - ETA: 1:49 - loss: 1.400 - ETA: 1:45 - loss: 1.400 - ETA: 1:41 - loss: 1.400 - ETA: 1:36 - loss: 1.399 - ETA: 1:32 - loss: 1.399 - ETA: 1:28 - loss: 1.399 - ETA: 1:24 - loss: 1.399 - ETA: 1:20 - loss: 1.399 - ETA: 1:15 - loss: 1.399 - ETA: 1:11 - loss: 1.398 - ETA: 1:07 - loss: 1.398 - ETA: 1:03 - loss: 1.398 - ETA: 58s - loss: 1.397 - ETA: 54s - loss: 1.39 - ETA: 50s - loss: 1.39 - ETA: 46s - loss: 1.39 - ETA: 42s - loss: 1.39 - ETA: 37s - loss: 1.39 - ETA: 33s - loss: 1.39 - ETA: 29s - loss: 1.39 - ETA: 25s - loss: 1.39 - ETA: 21s - loss: 1.39 - ETA: 16s - loss: 1.39 - ETA: 12s - loss: 1.39 - ETA: 8s - loss: 1.3994 - ETA: 4s - loss: 1.3994WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 422s 4s/step - loss: 1.3994\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.387 - ETA: 6:46 - loss: 1.409 - ETA: 6:42 - loss: 1.408 - ETA: 6:38 - loss: 1.400 - ETA: 6:34 - loss: 1.393 - ETA: 6:31 - loss: 1.401 - ETA: 6:29 - loss: 1.390 - ETA: 6:26 - loss: 1.389 - ETA: 6:23 - loss: 1.389 - ETA: 6:18 - loss: 1.390 - ETA: 6:14 - loss: 1.389 - ETA: 6:09 - loss: 1.387 - ETA: 6:05 - loss: 1.386 - ETA: 6:00 - loss: 1.391 - ETA: 5:56 - loss: 1.388 - ETA: 5:51 - loss: 1.389 - ETA: 5:47 - loss: 1.390 - ETA: 5:44 - loss: 1.392 - ETA: 5:40 - loss: 1.390 - ETA: 5:36 - loss: 1.389 - ETA: 5:32 - loss: 1.389 - ETA: 5:28 - loss: 1.388 - ETA: 5:24 - loss: 1.387 - ETA: 5:19 - loss: 1.388 - ETA: 5:15 - loss: 1.389 - ETA: 5:10 - loss: 1.388 - ETA: 5:06 - loss: 1.387 - ETA: 5:02 - loss: 1.387 - ETA: 4:58 - loss: 1.389 - ETA: 4:54 - loss: 1.389 - ETA: 4:50 - loss: 1.389 - ETA: 4:46 - loss: 1.389 - ETA: 4:42 - loss: 1.389 - ETA: 4:37 - loss: 1.389 - ETA: 4:33 - loss: 1.390 - ETA: 4:29 - loss: 1.386 - ETA: 4:25 - loss: 1.386 - ETA: 4:20 - loss: 1.386 - ETA: 4:16 - loss: 1.385 - ETA: 4:12 - loss: 1.385 - ETA: 4:08 - loss: 1.386 - ETA: 4:04 - loss: 1.386 - ETA: 4:00 - loss: 1.385 - ETA: 3:56 - loss: 1.384 - ETA: 3:51 - loss: 1.384 - ETA: 3:47 - loss: 1.384 - ETA: 3:43 - loss: 1.384 - ETA: 3:38 - loss: 1.384 - ETA: 3:34 - loss: 1.383 - ETA: 3:30 - loss: 1.383 - ETA: 3:26 - loss: 1.383 - ETA: 3:22 - loss: 1.383 - ETA: 3:18 - loss: 1.384 - ETA: 3:13 - loss: 1.385 - ETA: 3:09 - loss: 1.384 - ETA: 3:05 - loss: 1.383 - ETA: 3:01 - loss: 1.383 - ETA: 2:56 - loss: 1.383 - ETA: 2:52 - loss: 1.383 - ETA: 2:48 - loss: 1.383 - ETA: 2:44 - loss: 1.383 - ETA: 2:40 - loss: 1.384 - ETA: 2:35 - loss: 1.384 - ETA: 2:31 - loss: 1.384 - ETA: 2:27 - loss: 1.385 - ETA: 2:23 - loss: 1.386 - ETA: 2:19 - loss: 1.386 - ETA: 2:14 - loss: 1.385 - ETA: 2:10 - loss: 1.386 - ETA: 2:06 - loss: 1.386 - ETA: 2:02 - loss: 1.386 - ETA: 1:57 - loss: 1.387 - ETA: 1:53 - loss: 1.387 - ETA: 1:49 - loss: 1.387 - ETA: 1:45 - loss: 1.387 - ETA: 1:41 - loss: 1.387 - ETA: 1:37 - loss: 1.387 - ETA: 1:32 - loss: 1.387 - ETA: 1:28 - loss: 1.387 - ETA: 1:24 - loss: 1.387 - ETA: 1:20 - loss: 1.387 - ETA: 1:15 - loss: 1.387 - ETA: 1:11 - loss: 1.387 - ETA: 1:07 - loss: 1.387 - ETA: 1:03 - loss: 1.388 - ETA: 59s - loss: 1.388 - ETA: 54s - loss: 1.38 - ETA: 50s - loss: 1.38 - ETA: 46s - loss: 1.38 - ETA: 42s - loss: 1.38 - ETA: 37s - loss: 1.38 - ETA: 33s - loss: 1.38 - ETA: 29s - loss: 1.38 - ETA: 25s - loss: 1.38 - ETA: 21s - loss: 1.38 - ETA: 16s - loss: 1.38 - ETA: 12s - loss: 1.38 - ETA: 8s - loss: 1.3883 - ETA: 4s - loss: 1.3881WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 422s 4s/step - loss: 1.3885\n",
      "Epoch 18/100\n",
      " 99/100 [============================>.] - ETA: 6:54 - loss: 1.380 - ETA: 6:47 - loss: 1.396 - ETA: 6:42 - loss: 1.401 - ETA: 6:38 - loss: 1.395 - ETA: 6:37 - loss: 1.393 - ETA: 6:34 - loss: 1.395 - ETA: 6:32 - loss: 1.391 - ETA: 6:28 - loss: 1.392 - ETA: 6:24 - loss: 1.391 - ETA: 6:19 - loss: 1.393 - ETA: 6:14 - loss: 1.391 - ETA: 6:09 - loss: 1.389 - ETA: 6:05 - loss: 1.391 - ETA: 6:01 - loss: 1.395 - ETA: 5:56 - loss: 1.395 - ETA: 5:53 - loss: 1.394 - ETA: 5:49 - loss: 1.393 - ETA: 5:45 - loss: 1.394 - ETA: 5:41 - loss: 1.394 - ETA: 5:37 - loss: 1.394 - ETA: 5:33 - loss: 1.393 - ETA: 5:28 - loss: 1.392 - ETA: 5:24 - loss: 1.390 - ETA: 5:19 - loss: 1.388 - ETA: 5:15 - loss: 1.386 - ETA: 5:11 - loss: 1.387 - ETA: 5:07 - loss: 1.386 - ETA: 5:03 - loss: 1.386 - ETA: 4:59 - loss: 1.385 - ETA: 4:55 - loss: 1.385 - ETA: 4:51 - loss: 1.384 - ETA: 4:46 - loss: 1.384 - ETA: 4:42 - loss: 1.383 - ETA: 4:38 - loss: 1.382 - ETA: 4:33 - loss: 1.381 - ETA: 4:29 - loss: 1.381 - ETA: 4:25 - loss: 1.382 - ETA: 4:21 - loss: 1.380 - ETA: 4:17 - loss: 1.380 - ETA: 4:13 - loss: 1.380 - ETA: 4:09 - loss: 1.380 - ETA: 4:04 - loss: 1.379 - ETA: 4:00 - loss: 1.379 - ETA: 3:56 - loss: 1.379 - ETA: 3:51 - loss: 1.379 - ETA: 3:47 - loss: 1.380 - ETA: 3:43 - loss: 1.380 - ETA: 3:39 - loss: 1.379 - ETA: 3:35 - loss: 1.378 - ETA: 3:30 - loss: 1.378 - ETA: 3:26 - loss: 1.377 - ETA: 3:22 - loss: 1.376 - ETA: 3:18 - loss: 1.376 - ETA: 3:13 - loss: 1.377 - ETA: 3:09 - loss: 1.376 - ETA: 3:05 - loss: 1.376 - ETA: 3:01 - loss: 1.376 - ETA: 2:56 - loss: 1.376 - ETA: 2:52 - loss: 1.377 - ETA: 2:48 - loss: 1.377 - ETA: 2:44 - loss: 1.378 - ETA: 2:40 - loss: 1.377 - ETA: 2:35 - loss: 1.377 - ETA: 2:31 - loss: 1.377 - ETA: 2:27 - loss: 1.377 - ETA: 2:23 - loss: 1.377 - ETA: 2:18 - loss: 1.377 - ETA: 2:14 - loss: 1.377 - ETA: 2:10 - loss: 1.378 - ETA: 2:06 - loss: 1.377 - ETA: 2:02 - loss: 1.377 - ETA: 1:57 - loss: 1.377 - ETA: 1:53 - loss: 1.377 - ETA: 1:49 - loss: 1.377 - ETA: 1:45 - loss: 1.378 - ETA: 1:41 - loss: 1.377 - ETA: 1:36 - loss: 1.377 - ETA: 1:32 - loss: 1.377 - ETA: 1:28 - loss: 1.377 - ETA: 1:24 - loss: 1.377 - ETA: 1:20 - loss: 1.377 - ETA: 1:15 - loss: 1.377 - ETA: 1:11 - loss: 1.377 - ETA: 1:07 - loss: 1.377 - ETA: 1:03 - loss: 1.377 - ETA: 58s - loss: 1.377 - ETA: 54s - loss: 1.37 - ETA: 50s - loss: 1.37 - ETA: 46s - loss: 1.37 - ETA: 42s - loss: 1.37 - ETA: 37s - loss: 1.37 - ETA: 33s - loss: 1.37 - ETA: 29s - loss: 1.37 - ETA: 25s - loss: 1.37 - ETA: 21s - loss: 1.37 - ETA: 16s - loss: 1.37 - ETA: 12s - loss: 1.37 - ETA: 8s - loss: 1.3788 - ETA: 4s - loss: 1.3788WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 421s 4s/step - loss: 1.3791\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.398 - ETA: 6:54 - loss: 1.380 - ETA: 6:52 - loss: 1.385 - ETA: 6:49 - loss: 1.378 - ETA: 6:45 - loss: 1.383 - ETA: 6:41 - loss: 1.390 - ETA: 6:35 - loss: 1.400 - ETA: 6:30 - loss: 1.399 - ETA: 6:25 - loss: 1.396 - ETA: 6:20 - loss: 1.395 - ETA: 6:15 - loss: 1.393 - ETA: 6:11 - loss: 1.393 - ETA: 6:07 - loss: 1.393 - ETA: 6:04 - loss: 1.390 - ETA: 6:00 - loss: 1.390 - ETA: 5:57 - loss: 1.392 - ETA: 5:52 - loss: 1.389 - ETA: 5:47 - loss: 1.388 - ETA: 5:42 - loss: 1.387 - ETA: 5:38 - loss: 1.387 - ETA: 5:33 - loss: 1.388 - ETA: 5:29 - loss: 1.389 - ETA: 5:25 - loss: 1.388 - ETA: 5:21 - loss: 1.388 - ETA: 5:17 - loss: 1.387 - ETA: 5:13 - loss: 1.387 - ETA: 5:09 - loss: 1.385 - ETA: 5:04 - loss: 1.385 - ETA: 5:00 - loss: 1.384 - ETA: 4:56 - loss: 1.384 - ETA: 4:51 - loss: 1.384 - ETA: 4:47 - loss: 1.385 - ETA: 4:43 - loss: 1.386 - ETA: 4:39 - loss: 1.387 - ETA: 4:34 - loss: 1.388 - ETA: 4:30 - loss: 1.391 - ETA: 4:26 - loss: 1.391 - ETA: 4:22 - loss: 1.389 - ETA: 4:17 - loss: 1.390 - ETA: 4:13 - loss: 1.390 - ETA: 4:09 - loss: 1.390 - ETA: 4:04 - loss: 1.389 - ETA: 4:00 - loss: 1.389 - ETA: 3:56 - loss: 1.390 - ETA: 3:52 - loss: 1.389 - ETA: 3:48 - loss: 1.389 - ETA: 3:44 - loss: 1.390 - ETA: 3:39 - loss: 1.389 - ETA: 3:35 - loss: 1.389 - ETA: 3:31 - loss: 1.390 - ETA: 3:26 - loss: 1.390 - ETA: 3:22 - loss: 1.390 - ETA: 3:18 - loss: 1.391 - ETA: 3:14 - loss: 1.391 - ETA: 3:09 - loss: 1.390 - ETA: 3:05 - loss: 1.390 - ETA: 3:01 - loss: 1.391 - ETA: 2:57 - loss: 1.391 - ETA: 2:53 - loss: 1.391 - ETA: 2:49 - loss: 1.391 - ETA: 2:44 - loss: 1.391 - ETA: 2:40 - loss: 1.390 - ETA: 2:36 - loss: 1.390 - ETA: 2:31 - loss: 1.389 - ETA: 2:27 - loss: 1.388 - ETA: 2:23 - loss: 1.389 - ETA: 2:19 - loss: 1.389 - ETA: 2:15 - loss: 1.390 - ETA: 2:10 - loss: 1.390 - ETA: 2:06 - loss: 1.390 - ETA: 2:02 - loss: 1.390 - ETA: 1:58 - loss: 1.390 - ETA: 1:53 - loss: 1.391 - ETA: 1:49 - loss: 1.391 - ETA: 1:45 - loss: 1.391 - ETA: 1:41 - loss: 1.391 - ETA: 1:37 - loss: 1.392 - ETA: 1:32 - loss: 1.392 - ETA: 1:28 - loss: 1.392 - ETA: 1:24 - loss: 1.392 - ETA: 1:20 - loss: 1.392 - ETA: 1:15 - loss: 1.391 - ETA: 1:11 - loss: 1.391 - ETA: 1:07 - loss: 1.391 - ETA: 1:03 - loss: 1.391 - ETA: 59s - loss: 1.390 - ETA: 54s - loss: 1.39 - ETA: 50s - loss: 1.39 - ETA: 46s - loss: 1.39 - ETA: 42s - loss: 1.38 - ETA: 37s - loss: 1.38 - ETA: 33s - loss: 1.38 - ETA: 29s - loss: 1.38 - ETA: 25s - loss: 1.38 - ETA: 21s - loss: 1.38 - ETA: 16s - loss: 1.38 - ETA: 12s - loss: 1.38 - ETA: 8s - loss: 1.3878 - ETA: 4s - loss: 1.3876WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 422s 4s/step - loss: 1.3870\n",
      "Epoch 20/100\n",
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.374 - ETA: 6:47 - loss: 1.386 - ETA: 6:42 - loss: 1.393 - ETA: 6:38 - loss: 1.394 - ETA: 6:33 - loss: 1.390 - ETA: 6:29 - loss: 1.384 - ETA: 6:27 - loss: 1.386 - ETA: 6:26 - loss: 1.385 - ETA: 6:24 - loss: 1.383 - ETA: 6:20 - loss: 1.379 - ETA: 6:16 - loss: 1.371 - ETA: 6:13 - loss: 1.373 - ETA: 6:08 - loss: 1.372 - ETA: 6:04 - loss: 1.372 - ETA: 5:59 - loss: 1.371 - ETA: 5:54 - loss: 1.370 - ETA: 5:50 - loss: 1.372 - ETA: 5:45 - loss: 1.375 - ETA: 5:41 - loss: 1.376 - ETA: 5:37 - loss: 1.374 - ETA: 5:34 - loss: 1.374 - ETA: 5:31 - loss: 1.373 - ETA: 5:27 - loss: 1.372 - ETA: 5:22 - loss: 1.371 - ETA: 5:17 - loss: 1.373 - ETA: 5:13 - loss: 1.372 - ETA: 5:09 - loss: 1.371 - ETA: 5:04 - loss: 1.370 - ETA: 5:00 - loss: 1.370 - ETA: 4:56 - loss: 1.370 - ETA: 4:52 - loss: 1.370 - ETA: 4:47 - loss: 1.369 - ETA: 4:43 - loss: 1.369 - ETA: 4:39 - loss: 1.369 - ETA: 4:35 - loss: 1.368 - ETA: 4:30 - loss: 1.368 - ETA: 4:26 - loss: 1.367 - ETA: 4:22 - loss: 1.368 - ETA: 4:17 - loss: 1.368 - ETA: 4:13 - loss: 1.368 - ETA: 4:09 - loss: 1.368 - ETA: 4:05 - loss: 1.368 - ETA: 4:01 - loss: 1.369 - ETA: 3:57 - loss: 1.369 - ETA: 3:52 - loss: 1.369 - ETA: 3:48 - loss: 1.369 - ETA: 3:44 - loss: 1.367 - ETA: 3:39 - loss: 1.368 - ETA: 3:35 - loss: 1.369 - ETA: 3:31 - loss: 1.368 - ETA: 3:26 - loss: 1.369 - ETA: 3:22 - loss: 1.369 - ETA: 3:18 - loss: 1.369 - ETA: 3:14 - loss: 1.370 - ETA: 3:10 - loss: 1.370 - ETA: 3:06 - loss: 1.370 - ETA: 3:01 - loss: 1.369 - ETA: 2:57 - loss: 1.369 - ETA: 2:53 - loss: 1.369 - ETA: 2:48 - loss: 1.369 - ETA: 2:44 - loss: 1.369 - ETA: 2:40 - loss: 1.369 - ETA: 2:36 - loss: 1.369 - ETA: 2:32 - loss: 1.369 - ETA: 2:27 - loss: 1.369 - ETA: 2:23 - loss: 1.369 - ETA: 2:19 - loss: 1.370 - ETA: 2:15 - loss: 1.370 - ETA: 2:10 - loss: 1.369 - ETA: 2:06 - loss: 1.369 - ETA: 2:02 - loss: 1.369 - ETA: 1:58 - loss: 1.370 - ETA: 1:53 - loss: 1.369 - ETA: 1:49 - loss: 1.369 - ETA: 1:45 - loss: 1.369 - ETA: 1:41 - loss: 1.369 - ETA: 1:37 - loss: 1.369 - ETA: 1:32 - loss: 1.369 - ETA: 1:28 - loss: 1.368 - ETA: 1:24 - loss: 1.368 - ETA: 1:20 - loss: 1.368 - ETA: 1:15 - loss: 1.368 - ETA: 1:11 - loss: 1.367 - ETA: 1:07 - loss: 1.367 - ETA: 1:03 - loss: 1.367 - ETA: 59s - loss: 1.366 - ETA: 54s - loss: 1.36 - ETA: 50s - loss: 1.36 - ETA: 46s - loss: 1.36 - ETA: 42s - loss: 1.36 - ETA: 38s - loss: 1.36 - ETA: 33s - loss: 1.36 - ETA: 29s - loss: 1.36 - ETA: 25s - loss: 1.36 - ETA: 21s - loss: 1.36 - ETA: 16s - loss: 1.36 - ETA: 12s - loss: 1.36 - ETA: 8s - loss: 1.3632 - ETA: 4s - loss: 1.3632WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 422s 4s/step - loss: 1.3628\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:46 - loss: 1.395 - ETA: 6:42 - loss: 1.372 - ETA: 6:39 - loss: 1.373 - ETA: 6:35 - loss: 1.350 - ETA: 6:32 - loss: 1.356 - ETA: 6:28 - loss: 1.359 - ETA: 6:24 - loss: 1.363 - ETA: 6:20 - loss: 1.368 - ETA: 6:16 - loss: 1.365 - ETA: 6:13 - loss: 1.362 - ETA: 6:12 - loss: 1.360 - ETA: 6:09 - loss: 1.363 - ETA: 6:06 - loss: 1.365 - ETA: 6:02 - loss: 1.364 - ETA: 5:58 - loss: 1.364 - ETA: 5:55 - loss: 1.359 - ETA: 5:51 - loss: 1.359 - ETA: 5:47 - loss: 1.360 - ETA: 5:43 - loss: 1.359 - ETA: 5:39 - loss: 1.362 - ETA: 5:35 - loss: 1.361 - ETA: 5:31 - loss: 1.361 - ETA: 5:27 - loss: 1.362 - ETA: 5:23 - loss: 1.360 - ETA: 5:19 - loss: 1.359 - ETA: 5:15 - loss: 1.359 - ETA: 5:11 - loss: 1.358 - ETA: 5:07 - loss: 1.359 - ETA: 5:03 - loss: 1.360 - ETA: 4:59 - loss: 1.360 - ETA: 4:54 - loss: 1.360 - ETA: 4:50 - loss: 1.361 - ETA: 4:46 - loss: 1.361 - ETA: 4:42 - loss: 1.360 - ETA: 4:38 - loss: 1.360 - ETA: 4:34 - loss: 1.361 - ETA: 4:29 - loss: 1.362 - ETA: 4:25 - loss: 1.362 - ETA: 4:21 - loss: 1.362 - ETA: 4:17 - loss: 1.362 - ETA: 4:12 - loss: 1.362 - ETA: 4:08 - loss: 1.362 - ETA: 4:04 - loss: 1.361 - ETA: 4:00 - loss: 1.361 - ETA: 3:55 - loss: 1.361 - ETA: 3:51 - loss: 1.361 - ETA: 3:47 - loss: 1.360 - ETA: 3:43 - loss: 1.360 - ETA: 3:38 - loss: 1.359 - ETA: 3:34 - loss: 1.359 - ETA: 3:30 - loss: 1.359 - ETA: 3:25 - loss: 1.359 - ETA: 3:21 - loss: 1.359 - ETA: 3:17 - loss: 1.358 - ETA: 3:13 - loss: 1.358 - ETA: 3:08 - loss: 1.356 - ETA: 3:04 - loss: 1.356 - ETA: 3:00 - loss: 1.356 - ETA: 2:55 - loss: 1.356 - ETA: 2:51 - loss: 1.355 - ETA: 2:47 - loss: 1.355 - ETA: 2:43 - loss: 1.355 - ETA: 2:38 - loss: 1.355 - ETA: 2:34 - loss: 1.354 - ETA: 2:30 - loss: 1.355 - ETA: 2:25 - loss: 1.356 - ETA: 2:21 - loss: 1.356 - ETA: 2:17 - loss: 1.356 - ETA: 2:13 - loss: 1.357 - ETA: 2:08 - loss: 1.356 - ETA: 2:04 - loss: 1.357 - ETA: 2:00 - loss: 1.356 - ETA: 1:55 - loss: 1.356 - ETA: 1:51 - loss: 1.356 - ETA: 1:47 - loss: 1.356 - ETA: 1:43 - loss: 1.357 - ETA: 1:38 - loss: 1.357 - ETA: 1:34 - loss: 1.357 - ETA: 1:30 - loss: 1.356 - ETA: 1:25 - loss: 1.356 - ETA: 1:21 - loss: 1.356 - ETA: 1:17 - loss: 1.356 - ETA: 1:12 - loss: 1.355 - ETA: 1:08 - loss: 1.356 - ETA: 1:04 - loss: 1.356 - ETA: 1:00 - loss: 1.356 - ETA: 55s - loss: 1.356 - ETA: 51s - loss: 1.35 - ETA: 47s - loss: 1.35 - ETA: 42s - loss: 1.35 - ETA: 38s - loss: 1.35 - ETA: 34s - loss: 1.35 - ETA: 30s - loss: 1.35 - ETA: 25s - loss: 1.35 - ETA: 21s - loss: 1.35 - ETA: 17s - loss: 1.35 - ETA: 12s - loss: 1.35 - ETA: 8s - loss: 1.3575 - ETA: 4s - loss: 1.3575WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 430s 4s/step - loss: 1.3579\n",
      "Epoch 22/100\n",
      " 99/100 [============================>.] - ETA: 7:05 - loss: 1.356 - ETA: 7:00 - loss: 1.346 - ETA: 6:57 - loss: 1.365 - ETA: 6:53 - loss: 1.355 - ETA: 6:49 - loss: 1.351 - ETA: 6:44 - loss: 1.354 - ETA: 6:40 - loss: 1.350 - ETA: 6:36 - loss: 1.348 - ETA: 6:32 - loss: 1.346 - ETA: 6:28 - loss: 1.346 - ETA: 6:23 - loss: 1.349 - ETA: 6:19 - loss: 1.349 - ETA: 6:14 - loss: 1.352 - ETA: 6:10 - loss: 1.349 - ETA: 6:06 - loss: 1.349 - ETA: 6:01 - loss: 1.351 - ETA: 5:57 - loss: 1.350 - ETA: 5:54 - loss: 1.350 - ETA: 5:51 - loss: 1.349 - ETA: 5:47 - loss: 1.349 - ETA: 5:44 - loss: 1.346 - ETA: 5:40 - loss: 1.348 - ETA: 5:36 - loss: 1.348 - ETA: 5:32 - loss: 1.347 - ETA: 5:28 - loss: 1.348 - ETA: 5:24 - loss: 1.349 - ETA: 5:20 - loss: 1.348 - ETA: 5:16 - loss: 1.348 - ETA: 5:11 - loss: 1.346 - ETA: 5:07 - loss: 1.347 - ETA: 5:02 - loss: 1.347 - ETA: 4:58 - loss: 1.347 - ETA: 4:54 - loss: 1.347 - ETA: 4:50 - loss: 1.347 - ETA: 4:46 - loss: 1.347 - ETA: 4:42 - loss: 1.346 - ETA: 4:37 - loss: 1.347 - ETA: 4:33 - loss: 1.345 - ETA: 4:29 - loss: 1.344 - ETA: 4:24 - loss: 1.343 - ETA: 4:20 - loss: 1.343 - ETA: 4:16 - loss: 1.343 - ETA: 4:11 - loss: 1.343 - ETA: 4:07 - loss: 1.342 - ETA: 4:03 - loss: 1.341 - ETA: 3:59 - loss: 1.340 - ETA: 3:54 - loss: 1.341 - ETA: 3:50 - loss: 1.339 - ETA: 3:45 - loss: 1.339 - ETA: 3:41 - loss: 1.340 - ETA: 3:37 - loss: 1.340 - ETA: 3:32 - loss: 1.340 - ETA: 3:28 - loss: 1.340 - ETA: 3:23 - loss: 1.340 - ETA: 3:19 - loss: 1.339 - ETA: 3:14 - loss: 1.340 - ETA: 3:10 - loss: 1.339 - ETA: 3:06 - loss: 1.340 - ETA: 3:01 - loss: 1.341 - ETA: 2:57 - loss: 1.340 - ETA: 2:53 - loss: 1.340 - ETA: 2:48 - loss: 1.340 - ETA: 2:44 - loss: 1.340 - ETA: 2:40 - loss: 1.340 - ETA: 2:36 - loss: 1.340 - ETA: 2:32 - loss: 1.341 - ETA: 2:27 - loss: 1.340 - ETA: 2:23 - loss: 1.340 - ETA: 2:18 - loss: 1.339 - ETA: 2:13 - loss: 1.339 - ETA: 2:09 - loss: 1.339 - ETA: 2:04 - loss: 1.339 - ETA: 2:00 - loss: 1.340 - ETA: 1:55 - loss: 1.341 - ETA: 1:51 - loss: 1.341 - ETA: 1:46 - loss: 1.341 - ETA: 1:42 - loss: 1.341 - ETA: 1:37 - loss: 1.341 - ETA: 1:33 - loss: 1.341 - ETA: 1:28 - loss: 1.341 - ETA: 1:24 - loss: 1.342 - ETA: 1:19 - loss: 1.341 - ETA: 1:15 - loss: 1.341 - ETA: 1:10 - loss: 1.341 - ETA: 1:06 - loss: 1.341 - ETA: 1:02 - loss: 1.341 - ETA: 57s - loss: 1.341 - ETA: 53s - loss: 1.34 - ETA: 48s - loss: 1.34 - ETA: 44s - loss: 1.34 - ETA: 39s - loss: 1.34 - ETA: 35s - loss: 1.34 - ETA: 30s - loss: 1.34 - ETA: 26s - loss: 1.34 - ETA: 22s - loss: 1.34 - ETA: 17s - loss: 1.34 - ETA: 13s - loss: 1.34 - ETA: 8s - loss: 1.3424 - ETA: 4s - loss: 1.3425WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 442s 4s/step - loss: 1.3426\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 7:13 - loss: 1.308 - ETA: 7:06 - loss: 1.307 - ETA: 6:59 - loss: 1.316 - ETA: 6:55 - loss: 1.317 - ETA: 6:50 - loss: 1.324 - ETA: 6:45 - loss: 1.316 - ETA: 6:41 - loss: 1.316 - ETA: 6:37 - loss: 1.320 - ETA: 6:32 - loss: 1.323 - ETA: 6:28 - loss: 1.324 - ETA: 6:23 - loss: 1.325 - ETA: 6:19 - loss: 1.330 - ETA: 6:15 - loss: 1.327 - ETA: 6:10 - loss: 1.327 - ETA: 6:06 - loss: 1.327 - ETA: 6:02 - loss: 1.327 - ETA: 5:57 - loss: 1.330 - ETA: 5:53 - loss: 1.330 - ETA: 5:49 - loss: 1.331 - ETA: 5:44 - loss: 1.330 - ETA: 5:40 - loss: 1.329 - ETA: 5:36 - loss: 1.329 - ETA: 5:31 - loss: 1.327 - ETA: 5:27 - loss: 1.327 - ETA: 5:23 - loss: 1.327 - ETA: 5:19 - loss: 1.328 - ETA: 5:14 - loss: 1.328 - ETA: 5:10 - loss: 1.329 - ETA: 5:05 - loss: 1.331 - ETA: 5:01 - loss: 1.330 - ETA: 4:57 - loss: 1.332 - ETA: 4:53 - loss: 1.333 - ETA: 4:48 - loss: 1.333 - ETA: 4:44 - loss: 1.333 - ETA: 4:40 - loss: 1.333 - ETA: 4:35 - loss: 1.333 - ETA: 4:31 - loss: 1.332 - ETA: 4:27 - loss: 1.331 - ETA: 4:22 - loss: 1.330 - ETA: 4:18 - loss: 1.331 - ETA: 4:14 - loss: 1.331 - ETA: 4:09 - loss: 1.330 - ETA: 4:05 - loss: 1.331 - ETA: 4:01 - loss: 1.331 - ETA: 3:56 - loss: 1.332 - ETA: 3:52 - loss: 1.331 - ETA: 3:48 - loss: 1.330 - ETA: 3:44 - loss: 1.330 - ETA: 3:39 - loss: 1.330 - ETA: 3:35 - loss: 1.329 - ETA: 3:31 - loss: 1.329 - ETA: 3:26 - loss: 1.329 - ETA: 3:22 - loss: 1.329 - ETA: 3:18 - loss: 1.329 - ETA: 3:13 - loss: 1.330 - ETA: 3:09 - loss: 1.331 - ETA: 3:05 - loss: 1.331 - ETA: 3:00 - loss: 1.332 - ETA: 2:56 - loss: 1.332 - ETA: 2:52 - loss: 1.332 - ETA: 2:47 - loss: 1.332 - ETA: 2:43 - loss: 1.332 - ETA: 2:39 - loss: 1.331 - ETA: 2:35 - loss: 1.331 - ETA: 2:30 - loss: 1.331 - ETA: 2:26 - loss: 1.331 - ETA: 2:22 - loss: 1.331 - ETA: 2:17 - loss: 1.330 - ETA: 2:13 - loss: 1.329 - ETA: 2:09 - loss: 1.329 - ETA: 2:04 - loss: 1.328 - ETA: 2:00 - loss: 1.328 - ETA: 1:56 - loss: 1.327 - ETA: 1:51 - loss: 1.328 - ETA: 1:47 - loss: 1.328 - ETA: 1:43 - loss: 1.328 - ETA: 1:39 - loss: 1.328 - ETA: 1:34 - loss: 1.328 - ETA: 1:30 - loss: 1.328 - ETA: 1:26 - loss: 1.328 - ETA: 1:21 - loss: 1.328 - ETA: 1:17 - loss: 1.328 - ETA: 1:13 - loss: 1.328 - ETA: 1:08 - loss: 1.328 - ETA: 1:04 - loss: 1.328 - ETA: 1:00 - loss: 1.328 - ETA: 55s - loss: 1.328 - ETA: 51s - loss: 1.32 - ETA: 47s - loss: 1.32 - ETA: 43s - loss: 1.32 - ETA: 38s - loss: 1.32 - ETA: 34s - loss: 1.32 - ETA: 30s - loss: 1.32 - ETA: 25s - loss: 1.32 - ETA: 21s - loss: 1.32 - ETA: 17s - loss: 1.32 - ETA: 12s - loss: 1.32 - ETA: 8s - loss: 1.3284 - ETA: 4s - loss: 1.3280WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 431s 4s/step - loss: 1.3282\n",
      "Epoch 24/100\n",
      " 99/100 [============================>.] - ETA: 7:17 - loss: 1.308 - ETA: 7:11 - loss: 1.299 - ETA: 7:06 - loss: 1.317 - ETA: 7:00 - loss: 1.318 - ETA: 6:54 - loss: 1.317 - ETA: 6:49 - loss: 1.313 - ETA: 6:44 - loss: 1.311 - ETA: 6:39 - loss: 1.312 - ETA: 6:34 - loss: 1.310 - ETA: 6:30 - loss: 1.314 - ETA: 6:25 - loss: 1.312 - ETA: 6:21 - loss: 1.312 - ETA: 6:16 - loss: 1.310 - ETA: 6:12 - loss: 1.314 - ETA: 6:07 - loss: 1.314 - ETA: 6:03 - loss: 1.314 - ETA: 5:58 - loss: 1.313 - ETA: 5:54 - loss: 1.312 - ETA: 5:49 - loss: 1.313 - ETA: 5:45 - loss: 1.312 - ETA: 5:41 - loss: 1.314 - ETA: 5:36 - loss: 1.314 - ETA: 5:32 - loss: 1.314 - ETA: 5:28 - loss: 1.313 - ETA: 5:24 - loss: 1.310 - ETA: 5:20 - loss: 1.311 - ETA: 5:15 - loss: 1.311 - ETA: 5:11 - loss: 1.310 - ETA: 5:07 - loss: 1.310 - ETA: 5:02 - loss: 1.312 - ETA: 4:58 - loss: 1.311 - ETA: 4:53 - loss: 1.311 - ETA: 4:49 - loss: 1.312 - ETA: 4:45 - loss: 1.314 - ETA: 4:40 - loss: 1.316 - ETA: 4:36 - loss: 1.315 - ETA: 4:31 - loss: 1.316 - ETA: 4:27 - loss: 1.316 - ETA: 4:23 - loss: 1.316 - ETA: 4:18 - loss: 1.316 - ETA: 4:14 - loss: 1.316 - ETA: 4:10 - loss: 1.317 - ETA: 4:05 - loss: 1.317 - ETA: 4:01 - loss: 1.316 - ETA: 3:57 - loss: 1.317 - ETA: 3:52 - loss: 1.317 - ETA: 3:48 - loss: 1.317 - ETA: 3:44 - loss: 1.317 - ETA: 3:39 - loss: 1.317 - ETA: 3:35 - loss: 1.317 - ETA: 3:31 - loss: 1.316 - ETA: 3:26 - loss: 1.316 - ETA: 3:22 - loss: 1.317 - ETA: 3:18 - loss: 1.316 - ETA: 3:13 - loss: 1.316 - ETA: 3:09 - loss: 1.316 - ETA: 3:05 - loss: 1.316 - ETA: 3:00 - loss: 1.317 - ETA: 2:56 - loss: 1.317 - ETA: 2:52 - loss: 1.317 - ETA: 2:48 - loss: 1.317 - ETA: 2:43 - loss: 1.317 - ETA: 2:39 - loss: 1.317 - ETA: 2:35 - loss: 1.318 - ETA: 2:30 - loss: 1.318 - ETA: 2:26 - loss: 1.318 - ETA: 2:22 - loss: 1.318 - ETA: 2:17 - loss: 1.318 - ETA: 2:13 - loss: 1.320 - ETA: 2:09 - loss: 1.320 - ETA: 2:04 - loss: 1.321 - ETA: 2:00 - loss: 1.321 - ETA: 1:56 - loss: 1.322 - ETA: 1:52 - loss: 1.322 - ETA: 1:47 - loss: 1.321 - ETA: 1:43 - loss: 1.322 - ETA: 1:39 - loss: 1.323 - ETA: 1:34 - loss: 1.323 - ETA: 1:30 - loss: 1.323 - ETA: 1:26 - loss: 1.323 - ETA: 1:21 - loss: 1.323 - ETA: 1:17 - loss: 1.323 - ETA: 1:13 - loss: 1.323 - ETA: 1:08 - loss: 1.323 - ETA: 1:04 - loss: 1.324 - ETA: 1:00 - loss: 1.323 - ETA: 56s - loss: 1.323 - ETA: 51s - loss: 1.32 - ETA: 47s - loss: 1.32 - ETA: 43s - loss: 1.32 - ETA: 38s - loss: 1.32 - ETA: 34s - loss: 1.32 - ETA: 30s - loss: 1.32 - ETA: 25s - loss: 1.32 - ETA: 21s - loss: 1.32 - ETA: 17s - loss: 1.32 - ETA: 12s - loss: 1.32 - ETA: 8s - loss: 1.3246 - ETA: 4s - loss: 1.3248WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 431s 4s/step - loss: 1.3248\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 7:09 - loss: 1.296 - ETA: 7:02 - loss: 1.297 - ETA: 6:57 - loss: 1.310 - ETA: 6:52 - loss: 1.312 - ETA: 6:48 - loss: 1.311 - ETA: 6:44 - loss: 1.313 - ETA: 6:39 - loss: 1.320 - ETA: 6:35 - loss: 1.320 - ETA: 6:31 - loss: 1.325 - ETA: 6:26 - loss: 1.325 - ETA: 6:22 - loss: 1.331 - ETA: 6:17 - loss: 1.327 - ETA: 6:13 - loss: 1.328 - ETA: 6:09 - loss: 1.327 - ETA: 6:05 - loss: 1.325 - ETA: 6:01 - loss: 1.323 - ETA: 5:56 - loss: 1.323 - ETA: 5:52 - loss: 1.323 - ETA: 5:48 - loss: 1.324 - ETA: 5:43 - loss: 1.327 - ETA: 5:39 - loss: 1.325 - ETA: 5:35 - loss: 1.326 - ETA: 5:31 - loss: 1.327 - ETA: 5:26 - loss: 1.325 - ETA: 5:22 - loss: 1.325 - ETA: 5:18 - loss: 1.324 - ETA: 5:13 - loss: 1.325 - ETA: 5:09 - loss: 1.325 - ETA: 5:05 - loss: 1.324 - ETA: 5:00 - loss: 1.325 - ETA: 4:56 - loss: 1.325 - ETA: 4:52 - loss: 1.325 - ETA: 4:47 - loss: 1.327 - ETA: 4:43 - loss: 1.326 - ETA: 4:39 - loss: 1.326 - ETA: 4:34 - loss: 1.325 - ETA: 4:30 - loss: 1.326 - ETA: 4:26 - loss: 1.326 - ETA: 4:22 - loss: 1.327 - ETA: 4:17 - loss: 1.328 - ETA: 4:13 - loss: 1.329 - ETA: 4:09 - loss: 1.328 - ETA: 4:05 - loss: 1.329 - ETA: 4:00 - loss: 1.329 - ETA: 3:56 - loss: 1.330 - ETA: 3:52 - loss: 1.329 - ETA: 3:47 - loss: 1.329 - ETA: 3:43 - loss: 1.328 - ETA: 3:39 - loss: 1.329 - ETA: 3:34 - loss: 1.329 - ETA: 3:30 - loss: 1.331 - ETA: 3:26 - loss: 1.330 - ETA: 3:22 - loss: 1.330 - ETA: 3:17 - loss: 1.331 - ETA: 3:13 - loss: 1.331 - ETA: 3:09 - loss: 1.332 - ETA: 3:04 - loss: 1.332 - ETA: 3:00 - loss: 1.333 - ETA: 2:56 - loss: 1.334 - ETA: 2:51 - loss: 1.334 - ETA: 2:47 - loss: 1.333 - ETA: 2:43 - loss: 1.333 - ETA: 2:39 - loss: 1.333 - ETA: 2:34 - loss: 1.334 - ETA: 2:30 - loss: 1.334 - ETA: 2:26 - loss: 1.334 - ETA: 2:21 - loss: 1.334 - ETA: 2:17 - loss: 1.334 - ETA: 2:13 - loss: 1.334 - ETA: 2:08 - loss: 1.334 - ETA: 2:04 - loss: 1.334 - ETA: 2:00 - loss: 1.334 - ETA: 1:56 - loss: 1.333 - ETA: 1:51 - loss: 1.334 - ETA: 1:47 - loss: 1.335 - ETA: 1:43 - loss: 1.335 - ETA: 1:38 - loss: 1.335 - ETA: 1:34 - loss: 1.335 - ETA: 1:30 - loss: 1.335 - ETA: 1:25 - loss: 1.335 - ETA: 1:21 - loss: 1.334 - ETA: 1:17 - loss: 1.334 - ETA: 1:13 - loss: 1.334 - ETA: 1:08 - loss: 1.334 - ETA: 1:04 - loss: 1.334 - ETA: 1:00 - loss: 1.333 - ETA: 55s - loss: 1.333 - ETA: 51s - loss: 1.33 - ETA: 47s - loss: 1.33 - ETA: 42s - loss: 1.33 - ETA: 38s - loss: 1.33 - ETA: 34s - loss: 1.33 - ETA: 30s - loss: 1.33 - ETA: 25s - loss: 1.33 - ETA: 21s - loss: 1.33 - ETA: 17s - loss: 1.33 - ETA: 12s - loss: 1.33 - ETA: 8s - loss: 1.3340 - ETA: 4s - loss: 1.3341WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 430s 4s/step - loss: 1.3342\n",
      "Epoch 26/100\n",
      " 99/100 [============================>.] - ETA: 7:11 - loss: 1.326 - ETA: 7:02 - loss: 1.334 - ETA: 6:59 - loss: 1.340 - ETA: 6:53 - loss: 1.341 - ETA: 6:50 - loss: 1.353 - ETA: 6:45 - loss: 1.350 - ETA: 6:40 - loss: 1.348 - ETA: 6:36 - loss: 1.342 - ETA: 6:31 - loss: 1.339 - ETA: 6:27 - loss: 1.340 - ETA: 6:22 - loss: 1.344 - ETA: 6:19 - loss: 1.348 - ETA: 6:14 - loss: 1.348 - ETA: 6:10 - loss: 1.346 - ETA: 6:06 - loss: 1.343 - ETA: 6:01 - loss: 1.343 - ETA: 5:57 - loss: 1.344 - ETA: 5:52 - loss: 1.341 - ETA: 5:48 - loss: 1.341 - ETA: 5:44 - loss: 1.341 - ETA: 5:39 - loss: 1.340 - ETA: 5:35 - loss: 1.339 - ETA: 5:31 - loss: 1.338 - ETA: 5:27 - loss: 1.337 - ETA: 5:22 - loss: 1.337 - ETA: 5:17 - loss: 1.336 - ETA: 5:13 - loss: 1.338 - ETA: 5:09 - loss: 1.338 - ETA: 5:05 - loss: 1.337 - ETA: 5:01 - loss: 1.337 - ETA: 4:56 - loss: 1.339 - ETA: 4:52 - loss: 1.340 - ETA: 4:47 - loss: 1.340 - ETA: 4:43 - loss: 1.340 - ETA: 4:39 - loss: 1.340 - ETA: 4:35 - loss: 1.340 - ETA: 4:31 - loss: 1.340 - ETA: 4:27 - loss: 1.340 - ETA: 4:22 - loss: 1.341 - ETA: 4:18 - loss: 1.340 - ETA: 4:14 - loss: 1.340 - ETA: 4:10 - loss: 1.340 - ETA: 4:06 - loss: 1.340 - ETA: 4:01 - loss: 1.340 - ETA: 3:57 - loss: 1.341 - ETA: 3:52 - loss: 1.341 - ETA: 3:48 - loss: 1.342 - ETA: 3:43 - loss: 1.342 - ETA: 3:39 - loss: 1.342 - ETA: 3:34 - loss: 1.342 - ETA: 3:30 - loss: 1.343 - ETA: 3:25 - loss: 1.342 - ETA: 3:21 - loss: 1.342 - ETA: 3:16 - loss: 1.341 - ETA: 3:12 - loss: 1.341 - ETA: 3:08 - loss: 1.341 - ETA: 3:03 - loss: 1.341 - ETA: 2:59 - loss: 1.341 - ETA: 2:55 - loss: 1.341 - ETA: 2:50 - loss: 1.341 - ETA: 2:46 - loss: 1.340 - ETA: 2:42 - loss: 1.339 - ETA: 2:37 - loss: 1.340 - ETA: 2:33 - loss: 1.340 - ETA: 2:29 - loss: 1.339 - ETA: 2:24 - loss: 1.339 - ETA: 2:20 - loss: 1.339 - ETA: 2:16 - loss: 1.338 - ETA: 2:11 - loss: 1.338 - ETA: 2:07 - loss: 1.338 - ETA: 2:03 - loss: 1.338 - ETA: 1:58 - loss: 1.338 - ETA: 1:54 - loss: 1.337 - ETA: 1:50 - loss: 1.337 - ETA: 1:46 - loss: 1.337 - ETA: 1:41 - loss: 1.337 - ETA: 1:37 - loss: 1.337 - ETA: 1:33 - loss: 1.337 - ETA: 1:29 - loss: 1.337 - ETA: 1:24 - loss: 1.337 - ETA: 1:20 - loss: 1.337 - ETA: 1:16 - loss: 1.337 - ETA: 1:12 - loss: 1.337 - ETA: 1:07 - loss: 1.337 - ETA: 1:03 - loss: 1.337 - ETA: 59s - loss: 1.337 - ETA: 55s - loss: 1.33 - ETA: 50s - loss: 1.33 - ETA: 46s - loss: 1.33 - ETA: 42s - loss: 1.33 - ETA: 38s - loss: 1.33 - ETA: 33s - loss: 1.33 - ETA: 29s - loss: 1.33 - ETA: 25s - loss: 1.33 - ETA: 21s - loss: 1.33 - ETA: 16s - loss: 1.33 - ETA: 12s - loss: 1.33 - ETA: 8s - loss: 1.3368 - ETA: 4s - loss: 1.3370WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 422s 4s/step - loss: 1.3369\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.270 - ETA: 6:46 - loss: 1.298 - ETA: 6:41 - loss: 1.318 - ETA: 6:37 - loss: 1.330 - ETA: 6:32 - loss: 1.323 - ETA: 6:28 - loss: 1.328 - ETA: 6:24 - loss: 1.326 - ETA: 6:19 - loss: 1.326 - ETA: 6:15 - loss: 1.324 - ETA: 6:11 - loss: 1.322 - ETA: 6:08 - loss: 1.322 - ETA: 6:03 - loss: 1.319 - ETA: 5:59 - loss: 1.323 - ETA: 5:55 - loss: 1.324 - ETA: 5:51 - loss: 1.324 - ETA: 5:47 - loss: 1.325 - ETA: 5:43 - loss: 1.323 - ETA: 5:39 - loss: 1.323 - ETA: 5:35 - loss: 1.320 - ETA: 5:30 - loss: 1.321 - ETA: 5:26 - loss: 1.321 - ETA: 5:22 - loss: 1.319 - ETA: 5:18 - loss: 1.320 - ETA: 5:14 - loss: 1.318 - ETA: 5:09 - loss: 1.319 - ETA: 5:05 - loss: 1.320 - ETA: 5:01 - loss: 1.320 - ETA: 4:57 - loss: 1.322 - ETA: 4:53 - loss: 1.322 - ETA: 4:49 - loss: 1.320 - ETA: 4:45 - loss: 1.321 - ETA: 4:40 - loss: 1.321 - ETA: 4:36 - loss: 1.320 - ETA: 4:32 - loss: 1.319 - ETA: 4:28 - loss: 1.320 - ETA: 4:24 - loss: 1.321 - ETA: 4:20 - loss: 1.320 - ETA: 4:16 - loss: 1.321 - ETA: 4:11 - loss: 1.321 - ETA: 4:07 - loss: 1.321 - ETA: 4:03 - loss: 1.322 - ETA: 3:59 - loss: 1.322 - ETA: 3:55 - loss: 1.322 - ETA: 3:51 - loss: 1.321 - ETA: 3:47 - loss: 1.321 - ETA: 3:43 - loss: 1.322 - ETA: 3:39 - loss: 1.322 - ETA: 3:35 - loss: 1.322 - ETA: 3:31 - loss: 1.321 - ETA: 3:26 - loss: 1.321 - ETA: 3:22 - loss: 1.321 - ETA: 3:18 - loss: 1.321 - ETA: 3:14 - loss: 1.321 - ETA: 3:10 - loss: 1.321 - ETA: 3:06 - loss: 1.322 - ETA: 3:02 - loss: 1.322 - ETA: 2:57 - loss: 1.323 - ETA: 2:53 - loss: 1.323 - ETA: 2:49 - loss: 1.324 - ETA: 2:45 - loss: 1.324 - ETA: 2:41 - loss: 1.324 - ETA: 2:37 - loss: 1.324 - ETA: 2:33 - loss: 1.324 - ETA: 2:29 - loss: 1.324 - ETA: 2:24 - loss: 1.324 - ETA: 2:20 - loss: 1.324 - ETA: 2:16 - loss: 1.324 - ETA: 2:12 - loss: 1.324 - ETA: 2:08 - loss: 1.324 - ETA: 2:04 - loss: 1.324 - ETA: 2:00 - loss: 1.324 - ETA: 1:55 - loss: 1.325 - ETA: 1:51 - loss: 1.325 - ETA: 1:47 - loss: 1.325 - ETA: 1:43 - loss: 1.324 - ETA: 1:39 - loss: 1.324 - ETA: 1:35 - loss: 1.324 - ETA: 1:31 - loss: 1.323 - ETA: 1:26 - loss: 1.323 - ETA: 1:22 - loss: 1.323 - ETA: 1:18 - loss: 1.323 - ETA: 1:14 - loss: 1.324 - ETA: 1:10 - loss: 1.324 - ETA: 1:06 - loss: 1.323 - ETA: 1:02 - loss: 1.324 - ETA: 57s - loss: 1.323 - ETA: 53s - loss: 1.32 - ETA: 49s - loss: 1.32 - ETA: 45s - loss: 1.32 - ETA: 41s - loss: 1.32 - ETA: 37s - loss: 1.32 - ETA: 33s - loss: 1.32 - ETA: 28s - loss: 1.32 - ETA: 24s - loss: 1.32 - ETA: 20s - loss: 1.32 - ETA: 16s - loss: 1.32 - ETA: 12s - loss: 1.32 - ETA: 8s - loss: 1.3222 - ETA: 4s - loss: 1.3221WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.3217\n",
      "Epoch 28/100\n",
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.304 - ETA: 6:44 - loss: 1.289 - ETA: 6:40 - loss: 1.291 - ETA: 6:36 - loss: 1.298 - ETA: 6:32 - loss: 1.305 - ETA: 6:28 - loss: 1.300 - ETA: 6:24 - loss: 1.304 - ETA: 6:19 - loss: 1.306 - ETA: 6:15 - loss: 1.310 - ETA: 6:11 - loss: 1.308 - ETA: 6:07 - loss: 1.308 - ETA: 6:03 - loss: 1.308 - ETA: 5:59 - loss: 1.310 - ETA: 5:55 - loss: 1.312 - ETA: 5:50 - loss: 1.312 - ETA: 5:46 - loss: 1.314 - ETA: 5:42 - loss: 1.314 - ETA: 5:38 - loss: 1.313 - ETA: 5:34 - loss: 1.312 - ETA: 5:30 - loss: 1.311 - ETA: 5:26 - loss: 1.311 - ETA: 5:22 - loss: 1.311 - ETA: 5:18 - loss: 1.314 - ETA: 5:13 - loss: 1.313 - ETA: 5:09 - loss: 1.313 - ETA: 5:05 - loss: 1.314 - ETA: 5:01 - loss: 1.315 - ETA: 4:57 - loss: 1.315 - ETA: 4:53 - loss: 1.315 - ETA: 4:49 - loss: 1.318 - ETA: 4:45 - loss: 1.318 - ETA: 4:41 - loss: 1.319 - ETA: 4:37 - loss: 1.319 - ETA: 4:32 - loss: 1.318 - ETA: 4:28 - loss: 1.319 - ETA: 4:24 - loss: 1.318 - ETA: 4:20 - loss: 1.318 - ETA: 4:16 - loss: 1.316 - ETA: 4:12 - loss: 1.316 - ETA: 4:08 - loss: 1.317 - ETA: 4:04 - loss: 1.317 - ETA: 3:59 - loss: 1.317 - ETA: 3:55 - loss: 1.318 - ETA: 3:51 - loss: 1.319 - ETA: 3:47 - loss: 1.320 - ETA: 3:43 - loss: 1.320 - ETA: 3:39 - loss: 1.320 - ETA: 3:35 - loss: 1.320 - ETA: 3:30 - loss: 1.321 - ETA: 3:26 - loss: 1.321 - ETA: 3:22 - loss: 1.321 - ETA: 3:18 - loss: 1.321 - ETA: 3:14 - loss: 1.322 - ETA: 3:10 - loss: 1.323 - ETA: 3:06 - loss: 1.323 - ETA: 3:02 - loss: 1.323 - ETA: 2:57 - loss: 1.324 - ETA: 2:53 - loss: 1.323 - ETA: 2:49 - loss: 1.323 - ETA: 2:45 - loss: 1.323 - ETA: 2:41 - loss: 1.323 - ETA: 2:37 - loss: 1.323 - ETA: 2:33 - loss: 1.324 - ETA: 2:28 - loss: 1.323 - ETA: 2:24 - loss: 1.323 - ETA: 2:20 - loss: 1.323 - ETA: 2:16 - loss: 1.323 - ETA: 2:12 - loss: 1.323 - ETA: 2:08 - loss: 1.323 - ETA: 2:04 - loss: 1.324 - ETA: 1:59 - loss: 1.323 - ETA: 1:55 - loss: 1.323 - ETA: 1:51 - loss: 1.323 - ETA: 1:47 - loss: 1.324 - ETA: 1:43 - loss: 1.324 - ETA: 1:39 - loss: 1.324 - ETA: 1:35 - loss: 1.323 - ETA: 1:30 - loss: 1.323 - ETA: 1:26 - loss: 1.323 - ETA: 1:22 - loss: 1.323 - ETA: 1:18 - loss: 1.323 - ETA: 1:14 - loss: 1.322 - ETA: 1:10 - loss: 1.322 - ETA: 1:06 - loss: 1.323 - ETA: 1:02 - loss: 1.323 - ETA: 57s - loss: 1.323 - ETA: 53s - loss: 1.32 - ETA: 49s - loss: 1.32 - ETA: 45s - loss: 1.32 - ETA: 41s - loss: 1.32 - ETA: 37s - loss: 1.32 - ETA: 33s - loss: 1.32 - ETA: 28s - loss: 1.32 - ETA: 24s - loss: 1.32 - ETA: 20s - loss: 1.32 - ETA: 16s - loss: 1.32 - ETA: 12s - loss: 1.32 - ETA: 8s - loss: 1.3253 - ETA: 4s - loss: 1.3253WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.3256\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.295 - ETA: 6:46 - loss: 1.283 - ETA: 6:41 - loss: 1.290 - ETA: 6:37 - loss: 1.312 - ETA: 6:33 - loss: 1.307 - ETA: 6:29 - loss: 1.311 - ETA: 6:25 - loss: 1.308 - ETA: 6:20 - loss: 1.309 - ETA: 6:16 - loss: 1.311 - ETA: 6:12 - loss: 1.313 - ETA: 6:08 - loss: 1.315 - ETA: 6:04 - loss: 1.315 - ETA: 6:00 - loss: 1.316 - ETA: 5:56 - loss: 1.314 - ETA: 5:52 - loss: 1.316 - ETA: 5:48 - loss: 1.318 - ETA: 5:44 - loss: 1.318 - ETA: 5:40 - loss: 1.318 - ETA: 5:35 - loss: 1.321 - ETA: 5:31 - loss: 1.321 - ETA: 5:27 - loss: 1.322 - ETA: 5:23 - loss: 1.322 - ETA: 5:18 - loss: 1.319 - ETA: 5:14 - loss: 1.320 - ETA: 5:10 - loss: 1.318 - ETA: 5:06 - loss: 1.318 - ETA: 5:02 - loss: 1.321 - ETA: 4:58 - loss: 1.322 - ETA: 4:53 - loss: 1.323 - ETA: 4:49 - loss: 1.324 - ETA: 4:45 - loss: 1.324 - ETA: 4:41 - loss: 1.324 - ETA: 4:37 - loss: 1.324 - ETA: 4:33 - loss: 1.324 - ETA: 4:28 - loss: 1.324 - ETA: 4:24 - loss: 1.323 - ETA: 4:20 - loss: 1.324 - ETA: 4:16 - loss: 1.324 - ETA: 4:12 - loss: 1.324 - ETA: 4:08 - loss: 1.325 - ETA: 4:04 - loss: 1.325 - ETA: 3:59 - loss: 1.325 - ETA: 3:55 - loss: 1.326 - ETA: 3:51 - loss: 1.326 - ETA: 3:47 - loss: 1.326 - ETA: 3:43 - loss: 1.326 - ETA: 3:39 - loss: 1.326 - ETA: 3:35 - loss: 1.326 - ETA: 3:30 - loss: 1.328 - ETA: 3:26 - loss: 1.328 - ETA: 3:22 - loss: 1.328 - ETA: 3:18 - loss: 1.328 - ETA: 3:14 - loss: 1.328 - ETA: 3:10 - loss: 1.329 - ETA: 3:06 - loss: 1.328 - ETA: 3:02 - loss: 1.329 - ETA: 2:57 - loss: 1.328 - ETA: 2:53 - loss: 1.328 - ETA: 2:49 - loss: 1.328 - ETA: 2:45 - loss: 1.327 - ETA: 2:41 - loss: 1.327 - ETA: 2:37 - loss: 1.327 - ETA: 2:33 - loss: 1.327 - ETA: 2:28 - loss: 1.326 - ETA: 2:24 - loss: 1.327 - ETA: 2:20 - loss: 1.327 - ETA: 2:16 - loss: 1.328 - ETA: 2:12 - loss: 1.328 - ETA: 2:08 - loss: 1.328 - ETA: 2:04 - loss: 1.327 - ETA: 1:59 - loss: 1.327 - ETA: 1:55 - loss: 1.327 - ETA: 1:51 - loss: 1.327 - ETA: 1:47 - loss: 1.328 - ETA: 1:43 - loss: 1.327 - ETA: 1:39 - loss: 1.327 - ETA: 1:35 - loss: 1.328 - ETA: 1:31 - loss: 1.327 - ETA: 1:26 - loss: 1.327 - ETA: 1:22 - loss: 1.327 - ETA: 1:18 - loss: 1.327 - ETA: 1:14 - loss: 1.327 - ETA: 1:10 - loss: 1.327 - ETA: 1:06 - loss: 1.327 - ETA: 1:02 - loss: 1.326 - ETA: 57s - loss: 1.326 - ETA: 53s - loss: 1.32 - ETA: 49s - loss: 1.32 - ETA: 45s - loss: 1.32 - ETA: 41s - loss: 1.32 - ETA: 37s - loss: 1.32 - ETA: 33s - loss: 1.32 - ETA: 28s - loss: 1.32 - ETA: 24s - loss: 1.32 - ETA: 20s - loss: 1.32 - ETA: 16s - loss: 1.32 - ETA: 12s - loss: 1.32 - ETA: 8s - loss: 1.3271 - ETA: 4s - loss: 1.3272WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.3268\n",
      "Epoch 30/100\n",
      " 99/100 [============================>.] - ETA: 6:53 - loss: 1.330 - ETA: 6:46 - loss: 1.326 - ETA: 6:41 - loss: 1.315 - ETA: 6:36 - loss: 1.317 - ETA: 6:32 - loss: 1.307 - ETA: 6:27 - loss: 1.315 - ETA: 6:23 - loss: 1.320 - ETA: 6:19 - loss: 1.317 - ETA: 6:15 - loss: 1.322 - ETA: 6:11 - loss: 1.325 - ETA: 6:07 - loss: 1.326 - ETA: 6:03 - loss: 1.329 - ETA: 5:59 - loss: 1.330 - ETA: 5:54 - loss: 1.329 - ETA: 5:50 - loss: 1.330 - ETA: 5:46 - loss: 1.329 - ETA: 5:42 - loss: 1.327 - ETA: 5:38 - loss: 1.326 - ETA: 5:34 - loss: 1.323 - ETA: 5:30 - loss: 1.320 - ETA: 5:25 - loss: 1.319 - ETA: 5:21 - loss: 1.319 - ETA: 5:17 - loss: 1.316 - ETA: 5:13 - loss: 1.315 - ETA: 5:09 - loss: 1.315 - ETA: 5:05 - loss: 1.314 - ETA: 5:01 - loss: 1.314 - ETA: 4:57 - loss: 1.314 - ETA: 4:52 - loss: 1.314 - ETA: 4:48 - loss: 1.313 - ETA: 4:44 - loss: 1.313 - ETA: 4:40 - loss: 1.313 - ETA: 4:36 - loss: 1.313 - ETA: 4:32 - loss: 1.313 - ETA: 4:28 - loss: 1.313 - ETA: 4:24 - loss: 1.312 - ETA: 4:20 - loss: 1.312 - ETA: 4:15 - loss: 1.311 - ETA: 4:11 - loss: 1.311 - ETA: 4:07 - loss: 1.311 - ETA: 4:03 - loss: 1.312 - ETA: 3:59 - loss: 1.312 - ETA: 3:55 - loss: 1.312 - ETA: 3:51 - loss: 1.312 - ETA: 3:47 - loss: 1.311 - ETA: 3:42 - loss: 1.312 - ETA: 3:38 - loss: 1.312 - ETA: 3:34 - loss: 1.313 - ETA: 3:30 - loss: 1.313 - ETA: 3:26 - loss: 1.314 - ETA: 3:22 - loss: 1.315 - ETA: 3:18 - loss: 1.315 - ETA: 3:14 - loss: 1.314 - ETA: 3:09 - loss: 1.314 - ETA: 3:05 - loss: 1.315 - ETA: 3:01 - loss: 1.315 - ETA: 2:57 - loss: 1.315 - ETA: 2:53 - loss: 1.315 - ETA: 2:49 - loss: 1.315 - ETA: 2:45 - loss: 1.315 - ETA: 2:41 - loss: 1.315 - ETA: 2:36 - loss: 1.316 - ETA: 2:32 - loss: 1.316 - ETA: 2:28 - loss: 1.316 - ETA: 2:24 - loss: 1.315 - ETA: 2:20 - loss: 1.315 - ETA: 2:16 - loss: 1.314 - ETA: 2:12 - loss: 1.313 - ETA: 2:08 - loss: 1.313 - ETA: 2:04 - loss: 1.313 - ETA: 2:00 - loss: 1.313 - ETA: 1:55 - loss: 1.313 - ETA: 1:51 - loss: 1.313 - ETA: 1:47 - loss: 1.313 - ETA: 1:43 - loss: 1.313 - ETA: 1:39 - loss: 1.313 - ETA: 1:35 - loss: 1.313 - ETA: 1:31 - loss: 1.313 - ETA: 1:26 - loss: 1.313 - ETA: 1:22 - loss: 1.312 - ETA: 1:18 - loss: 1.312 - ETA: 1:14 - loss: 1.312 - ETA: 1:10 - loss: 1.313 - ETA: 1:06 - loss: 1.312 - ETA: 1:02 - loss: 1.312 - ETA: 57s - loss: 1.313 - ETA: 53s - loss: 1.31 - ETA: 49s - loss: 1.31 - ETA: 45s - loss: 1.31 - ETA: 41s - loss: 1.31 - ETA: 37s - loss: 1.31 - ETA: 33s - loss: 1.31 - ETA: 28s - loss: 1.31 - ETA: 24s - loss: 1.31 - ETA: 20s - loss: 1.31 - ETA: 16s - loss: 1.31 - ETA: 12s - loss: 1.31 - ETA: 8s - loss: 1.3121 - ETA: 4s - loss: 1.3123WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.3124\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.312 - ETA: 6:43 - loss: 1.301 - ETA: 6:39 - loss: 1.291 - ETA: 6:35 - loss: 1.299 - ETA: 6:31 - loss: 1.311 - ETA: 6:27 - loss: 1.314 - ETA: 6:22 - loss: 1.317 - ETA: 6:18 - loss: 1.316 - ETA: 6:14 - loss: 1.315 - ETA: 6:10 - loss: 1.312 - ETA: 6:06 - loss: 1.311 - ETA: 6:02 - loss: 1.312 - ETA: 5:58 - loss: 1.312 - ETA: 5:54 - loss: 1.309 - ETA: 5:50 - loss: 1.306 - ETA: 5:46 - loss: 1.305 - ETA: 5:42 - loss: 1.303 - ETA: 5:38 - loss: 1.304 - ETA: 5:34 - loss: 1.305 - ETA: 5:30 - loss: 1.305 - ETA: 5:26 - loss: 1.305 - ETA: 5:21 - loss: 1.304 - ETA: 5:17 - loss: 1.304 - ETA: 5:13 - loss: 1.302 - ETA: 5:09 - loss: 1.301 - ETA: 5:05 - loss: 1.302 - ETA: 5:01 - loss: 1.303 - ETA: 4:56 - loss: 1.303 - ETA: 4:52 - loss: 1.304 - ETA: 4:48 - loss: 1.304 - ETA: 4:44 - loss: 1.304 - ETA: 4:40 - loss: 1.305 - ETA: 4:36 - loss: 1.304 - ETA: 4:32 - loss: 1.303 - ETA: 4:28 - loss: 1.304 - ETA: 4:24 - loss: 1.305 - ETA: 4:19 - loss: 1.305 - ETA: 4:15 - loss: 1.305 - ETA: 4:11 - loss: 1.305 - ETA: 4:07 - loss: 1.305 - ETA: 4:03 - loss: 1.305 - ETA: 3:59 - loss: 1.305 - ETA: 3:55 - loss: 1.305 - ETA: 3:51 - loss: 1.306 - ETA: 3:46 - loss: 1.304 - ETA: 3:42 - loss: 1.304 - ETA: 3:38 - loss: 1.304 - ETA: 3:34 - loss: 1.303 - ETA: 3:30 - loss: 1.303 - ETA: 3:26 - loss: 1.303 - ETA: 3:22 - loss: 1.304 - ETA: 3:18 - loss: 1.304 - ETA: 3:13 - loss: 1.305 - ETA: 3:09 - loss: 1.304 - ETA: 3:05 - loss: 1.303 - ETA: 3:01 - loss: 1.303 - ETA: 2:57 - loss: 1.304 - ETA: 2:53 - loss: 1.304 - ETA: 2:49 - loss: 1.304 - ETA: 2:45 - loss: 1.303 - ETA: 2:41 - loss: 1.303 - ETA: 2:37 - loss: 1.304 - ETA: 2:32 - loss: 1.304 - ETA: 2:28 - loss: 1.303 - ETA: 2:24 - loss: 1.302 - ETA: 2:20 - loss: 1.302 - ETA: 2:16 - loss: 1.302 - ETA: 2:12 - loss: 1.302 - ETA: 2:08 - loss: 1.302 - ETA: 2:03 - loss: 1.302 - ETA: 1:59 - loss: 1.301 - ETA: 1:55 - loss: 1.302 - ETA: 1:51 - loss: 1.301 - ETA: 1:47 - loss: 1.301 - ETA: 1:43 - loss: 1.302 - ETA: 1:39 - loss: 1.302 - ETA: 1:35 - loss: 1.303 - ETA: 1:30 - loss: 1.302 - ETA: 1:26 - loss: 1.302 - ETA: 1:22 - loss: 1.303 - ETA: 1:18 - loss: 1.303 - ETA: 1:14 - loss: 1.303 - ETA: 1:10 - loss: 1.303 - ETA: 1:06 - loss: 1.303 - ETA: 1:01 - loss: 1.303 - ETA: 57s - loss: 1.303 - ETA: 53s - loss: 1.30 - ETA: 49s - loss: 1.30 - ETA: 45s - loss: 1.30 - ETA: 41s - loss: 1.30 - ETA: 37s - loss: 1.30 - ETA: 33s - loss: 1.30 - ETA: 28s - loss: 1.30 - ETA: 24s - loss: 1.30 - ETA: 20s - loss: 1.30 - ETA: 16s - loss: 1.30 - ETA: 12s - loss: 1.30 - ETA: 8s - loss: 1.3043 - ETA: 4s - loss: 1.3048WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.3047\n",
      "Epoch 32/100\n",
      " 99/100 [============================>.] - ETA: 6:52 - loss: 1.303 - ETA: 6:46 - loss: 1.317 - ETA: 6:41 - loss: 1.316 - ETA: 6:37 - loss: 1.308 - ETA: 6:33 - loss: 1.312 - ETA: 6:28 - loss: 1.306 - ETA: 6:24 - loss: 1.301 - ETA: 6:20 - loss: 1.301 - ETA: 6:15 - loss: 1.298 - ETA: 6:11 - loss: 1.301 - ETA: 6:07 - loss: 1.301 - ETA: 6:03 - loss: 1.298 - ETA: 5:59 - loss: 1.293 - ETA: 5:55 - loss: 1.293 - ETA: 5:51 - loss: 1.295 - ETA: 5:46 - loss: 1.293 - ETA: 5:42 - loss: 1.295 - ETA: 5:38 - loss: 1.297 - ETA: 5:34 - loss: 1.296 - ETA: 5:30 - loss: 1.295 - ETA: 5:26 - loss: 1.294 - ETA: 5:21 - loss: 1.294 - ETA: 5:17 - loss: 1.294 - ETA: 5:13 - loss: 1.292 - ETA: 5:09 - loss: 1.294 - ETA: 5:05 - loss: 1.294 - ETA: 5:01 - loss: 1.295 - ETA: 4:57 - loss: 1.295 - ETA: 4:53 - loss: 1.295 - ETA: 4:48 - loss: 1.295 - ETA: 4:44 - loss: 1.297 - ETA: 4:40 - loss: 1.296 - ETA: 4:36 - loss: 1.298 - ETA: 4:32 - loss: 1.297 - ETA: 4:28 - loss: 1.297 - ETA: 4:24 - loss: 1.297 - ETA: 4:20 - loss: 1.298 - ETA: 4:16 - loss: 1.297 - ETA: 4:11 - loss: 1.297 - ETA: 4:07 - loss: 1.296 - ETA: 4:03 - loss: 1.296 - ETA: 3:59 - loss: 1.297 - ETA: 3:55 - loss: 1.296 - ETA: 3:51 - loss: 1.296 - ETA: 3:47 - loss: 1.296 - ETA: 3:43 - loss: 1.296 - ETA: 3:38 - loss: 1.295 - ETA: 3:34 - loss: 1.295 - ETA: 3:30 - loss: 1.295 - ETA: 3:26 - loss: 1.295 - ETA: 3:22 - loss: 1.295 - ETA: 3:18 - loss: 1.295 - ETA: 3:14 - loss: 1.294 - ETA: 3:10 - loss: 1.295 - ETA: 3:05 - loss: 1.294 - ETA: 3:01 - loss: 1.294 - ETA: 2:57 - loss: 1.294 - ETA: 2:53 - loss: 1.295 - ETA: 2:49 - loss: 1.295 - ETA: 2:45 - loss: 1.295 - ETA: 2:41 - loss: 1.296 - ETA: 2:36 - loss: 1.296 - ETA: 2:32 - loss: 1.296 - ETA: 2:28 - loss: 1.296 - ETA: 2:24 - loss: 1.296 - ETA: 2:20 - loss: 1.297 - ETA: 2:16 - loss: 1.296 - ETA: 2:12 - loss: 1.296 - ETA: 2:08 - loss: 1.296 - ETA: 2:03 - loss: 1.296 - ETA: 1:59 - loss: 1.295 - ETA: 1:55 - loss: 1.296 - ETA: 1:51 - loss: 1.296 - ETA: 1:47 - loss: 1.296 - ETA: 1:43 - loss: 1.296 - ETA: 1:39 - loss: 1.296 - ETA: 1:35 - loss: 1.296 - ETA: 1:30 - loss: 1.295 - ETA: 1:26 - loss: 1.296 - ETA: 1:22 - loss: 1.295 - ETA: 1:18 - loss: 1.295 - ETA: 1:14 - loss: 1.295 - ETA: 1:10 - loss: 1.295 - ETA: 1:06 - loss: 1.295 - ETA: 1:01 - loss: 1.295 - ETA: 57s - loss: 1.295 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2966 - ETA: 4s - loss: 1.2965WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2970\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.311 - ETA: 6:43 - loss: 1.302 - ETA: 6:39 - loss: 1.305 - ETA: 6:35 - loss: 1.305 - ETA: 6:31 - loss: 1.300 - ETA: 6:27 - loss: 1.301 - ETA: 6:22 - loss: 1.298 - ETA: 6:18 - loss: 1.297 - ETA: 6:14 - loss: 1.297 - ETA: 6:10 - loss: 1.294 - ETA: 6:06 - loss: 1.295 - ETA: 6:02 - loss: 1.292 - ETA: 5:58 - loss: 1.291 - ETA: 5:54 - loss: 1.293 - ETA: 5:50 - loss: 1.291 - ETA: 5:46 - loss: 1.290 - ETA: 5:42 - loss: 1.288 - ETA: 5:38 - loss: 1.290 - ETA: 5:33 - loss: 1.290 - ETA: 5:30 - loss: 1.289 - ETA: 5:25 - loss: 1.288 - ETA: 5:21 - loss: 1.288 - ETA: 5:17 - loss: 1.291 - ETA: 5:13 - loss: 1.291 - ETA: 5:09 - loss: 1.290 - ETA: 5:05 - loss: 1.291 - ETA: 5:01 - loss: 1.290 - ETA: 4:56 - loss: 1.290 - ETA: 4:52 - loss: 1.290 - ETA: 4:48 - loss: 1.289 - ETA: 4:44 - loss: 1.290 - ETA: 4:40 - loss: 1.291 - ETA: 4:36 - loss: 1.292 - ETA: 4:32 - loss: 1.292 - ETA: 4:28 - loss: 1.291 - ETA: 4:24 - loss: 1.292 - ETA: 4:19 - loss: 1.292 - ETA: 4:15 - loss: 1.293 - ETA: 4:11 - loss: 1.293 - ETA: 4:07 - loss: 1.292 - ETA: 4:03 - loss: 1.293 - ETA: 3:59 - loss: 1.292 - ETA: 3:55 - loss: 1.292 - ETA: 3:51 - loss: 1.291 - ETA: 3:46 - loss: 1.290 - ETA: 3:42 - loss: 1.289 - ETA: 3:38 - loss: 1.289 - ETA: 3:34 - loss: 1.290 - ETA: 3:30 - loss: 1.290 - ETA: 3:26 - loss: 1.290 - ETA: 3:22 - loss: 1.291 - ETA: 3:18 - loss: 1.290 - ETA: 3:13 - loss: 1.291 - ETA: 3:09 - loss: 1.291 - ETA: 3:05 - loss: 1.290 - ETA: 3:01 - loss: 1.290 - ETA: 2:57 - loss: 1.290 - ETA: 2:53 - loss: 1.290 - ETA: 2:49 - loss: 1.290 - ETA: 2:44 - loss: 1.289 - ETA: 2:40 - loss: 1.290 - ETA: 2:36 - loss: 1.290 - ETA: 2:32 - loss: 1.290 - ETA: 2:28 - loss: 1.290 - ETA: 2:24 - loss: 1.289 - ETA: 2:20 - loss: 1.289 - ETA: 2:16 - loss: 1.290 - ETA: 2:12 - loss: 1.290 - ETA: 2:07 - loss: 1.290 - ETA: 2:03 - loss: 1.291 - ETA: 1:59 - loss: 1.291 - ETA: 1:55 - loss: 1.291 - ETA: 1:51 - loss: 1.292 - ETA: 1:47 - loss: 1.292 - ETA: 1:43 - loss: 1.292 - ETA: 1:38 - loss: 1.292 - ETA: 1:34 - loss: 1.292 - ETA: 1:30 - loss: 1.292 - ETA: 1:26 - loss: 1.292 - ETA: 1:22 - loss: 1.291 - ETA: 1:18 - loss: 1.291 - ETA: 1:14 - loss: 1.291 - ETA: 1:10 - loss: 1.291 - ETA: 1:06 - loss: 1.290 - ETA: 1:01 - loss: 1.290 - ETA: 57s - loss: 1.290 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2930 - ETA: 4s - loss: 1.2931WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2930\n",
      "Epoch 34/100\n",
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.290 - ETA: 6:43 - loss: 1.284 - ETA: 6:39 - loss: 1.303 - ETA: 6:35 - loss: 1.296 - ETA: 6:31 - loss: 1.291 - ETA: 6:27 - loss: 1.286 - ETA: 6:23 - loss: 1.284 - ETA: 6:19 - loss: 1.286 - ETA: 6:15 - loss: 1.285 - ETA: 6:11 - loss: 1.286 - ETA: 6:07 - loss: 1.288 - ETA: 6:03 - loss: 1.290 - ETA: 5:58 - loss: 1.294 - ETA: 5:54 - loss: 1.294 - ETA: 5:50 - loss: 1.294 - ETA: 5:46 - loss: 1.293 - ETA: 5:42 - loss: 1.294 - ETA: 5:38 - loss: 1.291 - ETA: 5:34 - loss: 1.291 - ETA: 5:30 - loss: 1.289 - ETA: 5:26 - loss: 1.289 - ETA: 5:22 - loss: 1.291 - ETA: 5:18 - loss: 1.292 - ETA: 5:14 - loss: 1.290 - ETA: 5:10 - loss: 1.290 - ETA: 5:05 - loss: 1.289 - ETA: 5:01 - loss: 1.290 - ETA: 4:57 - loss: 1.290 - ETA: 4:53 - loss: 1.290 - ETA: 4:49 - loss: 1.290 - ETA: 4:45 - loss: 1.290 - ETA: 4:41 - loss: 1.289 - ETA: 4:36 - loss: 1.289 - ETA: 4:32 - loss: 1.288 - ETA: 4:28 - loss: 1.290 - ETA: 4:24 - loss: 1.290 - ETA: 4:20 - loss: 1.290 - ETA: 4:16 - loss: 1.290 - ETA: 4:12 - loss: 1.291 - ETA: 4:07 - loss: 1.291 - ETA: 4:03 - loss: 1.290 - ETA: 3:59 - loss: 1.289 - ETA: 3:55 - loss: 1.289 - ETA: 3:51 - loss: 1.288 - ETA: 3:47 - loss: 1.289 - ETA: 3:43 - loss: 1.289 - ETA: 3:38 - loss: 1.289 - ETA: 3:34 - loss: 1.290 - ETA: 3:30 - loss: 1.289 - ETA: 3:26 - loss: 1.289 - ETA: 3:22 - loss: 1.289 - ETA: 3:18 - loss: 1.289 - ETA: 3:14 - loss: 1.290 - ETA: 3:10 - loss: 1.290 - ETA: 3:05 - loss: 1.291 - ETA: 3:01 - loss: 1.290 - ETA: 2:57 - loss: 1.290 - ETA: 2:53 - loss: 1.290 - ETA: 2:49 - loss: 1.290 - ETA: 2:45 - loss: 1.291 - ETA: 2:41 - loss: 1.291 - ETA: 2:36 - loss: 1.292 - ETA: 2:32 - loss: 1.292 - ETA: 2:28 - loss: 1.293 - ETA: 2:24 - loss: 1.293 - ETA: 2:20 - loss: 1.293 - ETA: 2:16 - loss: 1.293 - ETA: 2:12 - loss: 1.293 - ETA: 2:07 - loss: 1.294 - ETA: 2:03 - loss: 1.294 - ETA: 1:59 - loss: 1.294 - ETA: 1:55 - loss: 1.294 - ETA: 1:51 - loss: 1.294 - ETA: 1:47 - loss: 1.294 - ETA: 1:43 - loss: 1.294 - ETA: 1:39 - loss: 1.293 - ETA: 1:34 - loss: 1.293 - ETA: 1:30 - loss: 1.293 - ETA: 1:26 - loss: 1.293 - ETA: 1:22 - loss: 1.293 - ETA: 1:18 - loss: 1.292 - ETA: 1:14 - loss: 1.292 - ETA: 1:10 - loss: 1.292 - ETA: 1:06 - loss: 1.292 - ETA: 1:01 - loss: 1.292 - ETA: 57s - loss: 1.292 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2918 - ETA: 4s - loss: 1.2913WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2913\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.267 - ETA: 6:45 - loss: 1.275 - ETA: 6:42 - loss: 1.281 - ETA: 6:46 - loss: 1.265 - ETA: 6:42 - loss: 1.265 - ETA: 6:37 - loss: 1.261 - ETA: 6:32 - loss: 1.262 - ETA: 6:27 - loss: 1.264 - ETA: 6:22 - loss: 1.268 - ETA: 6:17 - loss: 1.273 - ETA: 6:13 - loss: 1.276 - ETA: 6:08 - loss: 1.276 - ETA: 6:04 - loss: 1.274 - ETA: 5:59 - loss: 1.275 - ETA: 5:55 - loss: 1.277 - ETA: 5:51 - loss: 1.278 - ETA: 5:46 - loss: 1.280 - ETA: 5:42 - loss: 1.281 - ETA: 5:38 - loss: 1.281 - ETA: 5:34 - loss: 1.283 - ETA: 5:29 - loss: 1.283 - ETA: 5:25 - loss: 1.283 - ETA: 5:21 - loss: 1.285 - ETA: 5:17 - loss: 1.287 - ETA: 5:13 - loss: 1.286 - ETA: 5:08 - loss: 1.286 - ETA: 5:04 - loss: 1.286 - ETA: 5:00 - loss: 1.286 - ETA: 4:56 - loss: 1.285 - ETA: 4:51 - loss: 1.285 - ETA: 4:47 - loss: 1.286 - ETA: 4:43 - loss: 1.286 - ETA: 4:39 - loss: 1.286 - ETA: 4:34 - loss: 1.285 - ETA: 4:30 - loss: 1.285 - ETA: 4:26 - loss: 1.285 - ETA: 4:22 - loss: 1.285 - ETA: 4:17 - loss: 1.287 - ETA: 4:13 - loss: 1.286 - ETA: 4:09 - loss: 1.285 - ETA: 4:05 - loss: 1.285 - ETA: 4:01 - loss: 1.285 - ETA: 3:56 - loss: 1.285 - ETA: 3:52 - loss: 1.284 - ETA: 3:48 - loss: 1.284 - ETA: 3:44 - loss: 1.284 - ETA: 3:40 - loss: 1.284 - ETA: 3:35 - loss: 1.284 - ETA: 3:31 - loss: 1.285 - ETA: 3:27 - loss: 1.285 - ETA: 3:23 - loss: 1.286 - ETA: 3:19 - loss: 1.286 - ETA: 3:15 - loss: 1.286 - ETA: 3:10 - loss: 1.286 - ETA: 3:06 - loss: 1.286 - ETA: 3:02 - loss: 1.286 - ETA: 2:58 - loss: 1.286 - ETA: 2:54 - loss: 1.286 - ETA: 2:50 - loss: 1.286 - ETA: 2:45 - loss: 1.286 - ETA: 2:41 - loss: 1.287 - ETA: 2:37 - loss: 1.287 - ETA: 2:33 - loss: 1.288 - ETA: 2:29 - loss: 1.288 - ETA: 2:25 - loss: 1.289 - ETA: 2:21 - loss: 1.289 - ETA: 2:16 - loss: 1.289 - ETA: 2:12 - loss: 1.288 - ETA: 2:08 - loss: 1.288 - ETA: 2:04 - loss: 1.288 - ETA: 2:00 - loss: 1.288 - ETA: 1:56 - loss: 1.288 - ETA: 1:51 - loss: 1.288 - ETA: 1:47 - loss: 1.289 - ETA: 1:43 - loss: 1.288 - ETA: 1:39 - loss: 1.288 - ETA: 1:35 - loss: 1.288 - ETA: 1:31 - loss: 1.288 - ETA: 1:27 - loss: 1.288 - ETA: 1:22 - loss: 1.289 - ETA: 1:18 - loss: 1.288 - ETA: 1:14 - loss: 1.288 - ETA: 1:10 - loss: 1.289 - ETA: 1:06 - loss: 1.289 - ETA: 1:02 - loss: 1.289 - ETA: 58s - loss: 1.289 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2910 - ETA: 4s - loss: 1.2907WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2905\n",
      "Epoch 36/100\n",
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.310 - ETA: 6:43 - loss: 1.299 - ETA: 6:39 - loss: 1.304 - ETA: 6:35 - loss: 1.309 - ETA: 6:31 - loss: 1.294 - ETA: 6:27 - loss: 1.302 - ETA: 6:23 - loss: 1.304 - ETA: 6:19 - loss: 1.300 - ETA: 6:14 - loss: 1.299 - ETA: 6:10 - loss: 1.297 - ETA: 6:06 - loss: 1.299 - ETA: 6:02 - loss: 1.296 - ETA: 5:58 - loss: 1.298 - ETA: 5:54 - loss: 1.301 - ETA: 5:49 - loss: 1.299 - ETA: 5:45 - loss: 1.299 - ETA: 5:41 - loss: 1.296 - ETA: 5:37 - loss: 1.293 - ETA: 5:33 - loss: 1.295 - ETA: 5:29 - loss: 1.295 - ETA: 5:25 - loss: 1.296 - ETA: 5:21 - loss: 1.296 - ETA: 5:17 - loss: 1.297 - ETA: 5:13 - loss: 1.296 - ETA: 5:09 - loss: 1.295 - ETA: 5:05 - loss: 1.295 - ETA: 5:01 - loss: 1.294 - ETA: 4:58 - loss: 1.294 - ETA: 4:54 - loss: 1.292 - ETA: 4:50 - loss: 1.292 - ETA: 4:47 - loss: 1.292 - ETA: 4:43 - loss: 1.291 - ETA: 4:39 - loss: 1.290 - ETA: 4:34 - loss: 1.288 - ETA: 4:30 - loss: 1.287 - ETA: 4:26 - loss: 1.288 - ETA: 4:22 - loss: 1.289 - ETA: 4:18 - loss: 1.289 - ETA: 4:13 - loss: 1.290 - ETA: 4:09 - loss: 1.290 - ETA: 4:05 - loss: 1.290 - ETA: 4:01 - loss: 1.289 - ETA: 3:57 - loss: 1.290 - ETA: 3:52 - loss: 1.291 - ETA: 3:48 - loss: 1.291 - ETA: 3:44 - loss: 1.291 - ETA: 3:40 - loss: 1.292 - ETA: 3:36 - loss: 1.292 - ETA: 3:31 - loss: 1.293 - ETA: 3:27 - loss: 1.293 - ETA: 3:23 - loss: 1.293 - ETA: 3:19 - loss: 1.294 - ETA: 3:15 - loss: 1.293 - ETA: 3:10 - loss: 1.293 - ETA: 3:06 - loss: 1.293 - ETA: 3:02 - loss: 1.293 - ETA: 2:58 - loss: 1.293 - ETA: 2:54 - loss: 1.293 - ETA: 2:50 - loss: 1.293 - ETA: 2:45 - loss: 1.293 - ETA: 2:41 - loss: 1.293 - ETA: 2:37 - loss: 1.293 - ETA: 2:33 - loss: 1.292 - ETA: 2:29 - loss: 1.292 - ETA: 2:25 - loss: 1.293 - ETA: 2:20 - loss: 1.293 - ETA: 2:16 - loss: 1.292 - ETA: 2:12 - loss: 1.292 - ETA: 2:08 - loss: 1.292 - ETA: 2:04 - loss: 1.291 - ETA: 2:00 - loss: 1.291 - ETA: 1:56 - loss: 1.291 - ETA: 1:51 - loss: 1.291 - ETA: 1:47 - loss: 1.291 - ETA: 1:43 - loss: 1.291 - ETA: 1:39 - loss: 1.291 - ETA: 1:35 - loss: 1.292 - ETA: 1:31 - loss: 1.292 - ETA: 1:26 - loss: 1.292 - ETA: 1:22 - loss: 1.293 - ETA: 1:18 - loss: 1.293 - ETA: 1:14 - loss: 1.293 - ETA: 1:10 - loss: 1.294 - ETA: 1:06 - loss: 1.293 - ETA: 1:02 - loss: 1.292 - ETA: 57s - loss: 1.293 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2925 - ETA: 4s - loss: 1.2928WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2929\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.310 - ETA: 6:44 - loss: 1.322 - ETA: 6:41 - loss: 1.308 - ETA: 6:36 - loss: 1.299 - ETA: 6:32 - loss: 1.296 - ETA: 6:28 - loss: 1.299 - ETA: 6:24 - loss: 1.291 - ETA: 6:19 - loss: 1.289 - ETA: 6:16 - loss: 1.291 - ETA: 6:12 - loss: 1.289 - ETA: 6:07 - loss: 1.289 - ETA: 6:03 - loss: 1.288 - ETA: 5:59 - loss: 1.290 - ETA: 5:55 - loss: 1.289 - ETA: 5:50 - loss: 1.289 - ETA: 5:46 - loss: 1.292 - ETA: 5:42 - loss: 1.293 - ETA: 5:38 - loss: 1.292 - ETA: 5:34 - loss: 1.289 - ETA: 5:30 - loss: 1.288 - ETA: 5:26 - loss: 1.290 - ETA: 5:22 - loss: 1.290 - ETA: 5:18 - loss: 1.289 - ETA: 5:14 - loss: 1.290 - ETA: 5:10 - loss: 1.290 - ETA: 5:06 - loss: 1.290 - ETA: 5:02 - loss: 1.290 - ETA: 4:57 - loss: 1.290 - ETA: 4:53 - loss: 1.289 - ETA: 4:49 - loss: 1.289 - ETA: 4:45 - loss: 1.291 - ETA: 4:41 - loss: 1.290 - ETA: 4:37 - loss: 1.291 - ETA: 4:33 - loss: 1.291 - ETA: 4:28 - loss: 1.290 - ETA: 4:24 - loss: 1.289 - ETA: 4:20 - loss: 1.291 - ETA: 4:16 - loss: 1.290 - ETA: 4:12 - loss: 1.290 - ETA: 4:08 - loss: 1.291 - ETA: 4:03 - loss: 1.291 - ETA: 3:59 - loss: 1.292 - ETA: 3:55 - loss: 1.292 - ETA: 3:51 - loss: 1.293 - ETA: 3:47 - loss: 1.294 - ETA: 3:43 - loss: 1.293 - ETA: 3:39 - loss: 1.293 - ETA: 3:34 - loss: 1.293 - ETA: 3:30 - loss: 1.293 - ETA: 3:26 - loss: 1.293 - ETA: 3:22 - loss: 1.293 - ETA: 3:18 - loss: 1.294 - ETA: 3:14 - loss: 1.294 - ETA: 3:10 - loss: 1.294 - ETA: 3:05 - loss: 1.293 - ETA: 3:01 - loss: 1.294 - ETA: 2:57 - loss: 1.293 - ETA: 2:53 - loss: 1.294 - ETA: 2:49 - loss: 1.294 - ETA: 2:45 - loss: 1.295 - ETA: 2:41 - loss: 1.295 - ETA: 2:37 - loss: 1.295 - ETA: 2:32 - loss: 1.295 - ETA: 2:28 - loss: 1.294 - ETA: 2:24 - loss: 1.295 - ETA: 2:20 - loss: 1.294 - ETA: 2:16 - loss: 1.295 - ETA: 2:12 - loss: 1.295 - ETA: 2:08 - loss: 1.295 - ETA: 2:03 - loss: 1.295 - ETA: 1:59 - loss: 1.294 - ETA: 1:55 - loss: 1.294 - ETA: 1:51 - loss: 1.294 - ETA: 1:47 - loss: 1.295 - ETA: 1:43 - loss: 1.295 - ETA: 1:39 - loss: 1.295 - ETA: 1:35 - loss: 1.294 - ETA: 1:30 - loss: 1.294 - ETA: 1:26 - loss: 1.294 - ETA: 1:22 - loss: 1.295 - ETA: 1:18 - loss: 1.295 - ETA: 1:14 - loss: 1.294 - ETA: 1:10 - loss: 1.295 - ETA: 1:06 - loss: 1.295 - ETA: 1:01 - loss: 1.295 - ETA: 57s - loss: 1.296 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2953 - ETA: 4s - loss: 1.2952WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2954\n",
      "Epoch 38/100\n",
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.312 - ETA: 6:46 - loss: 1.293 - ETA: 6:42 - loss: 1.293 - ETA: 6:37 - loss: 1.287 - ETA: 6:32 - loss: 1.288 - ETA: 6:28 - loss: 1.284 - ETA: 6:24 - loss: 1.288 - ETA: 6:20 - loss: 1.287 - ETA: 6:16 - loss: 1.287 - ETA: 6:12 - loss: 1.287 - ETA: 6:07 - loss: 1.293 - ETA: 6:03 - loss: 1.295 - ETA: 5:59 - loss: 1.298 - ETA: 5:55 - loss: 1.298 - ETA: 5:51 - loss: 1.297 - ETA: 5:47 - loss: 1.298 - ETA: 5:42 - loss: 1.296 - ETA: 5:38 - loss: 1.293 - ETA: 5:34 - loss: 1.291 - ETA: 5:30 - loss: 1.288 - ETA: 5:26 - loss: 1.287 - ETA: 5:22 - loss: 1.286 - ETA: 5:17 - loss: 1.287 - ETA: 5:13 - loss: 1.288 - ETA: 5:09 - loss: 1.286 - ETA: 5:05 - loss: 1.287 - ETA: 5:01 - loss: 1.287 - ETA: 4:57 - loss: 1.287 - ETA: 4:52 - loss: 1.286 - ETA: 4:48 - loss: 1.286 - ETA: 4:44 - loss: 1.287 - ETA: 4:40 - loss: 1.287 - ETA: 4:36 - loss: 1.287 - ETA: 4:32 - loss: 1.287 - ETA: 4:28 - loss: 1.286 - ETA: 4:24 - loss: 1.287 - ETA: 4:19 - loss: 1.287 - ETA: 4:15 - loss: 1.288 - ETA: 4:11 - loss: 1.288 - ETA: 4:07 - loss: 1.289 - ETA: 4:03 - loss: 1.289 - ETA: 3:59 - loss: 1.290 - ETA: 3:55 - loss: 1.290 - ETA: 3:51 - loss: 1.289 - ETA: 3:47 - loss: 1.289 - ETA: 3:42 - loss: 1.290 - ETA: 3:38 - loss: 1.289 - ETA: 3:34 - loss: 1.291 - ETA: 3:30 - loss: 1.291 - ETA: 3:26 - loss: 1.291 - ETA: 3:22 - loss: 1.291 - ETA: 3:18 - loss: 1.291 - ETA: 3:13 - loss: 1.291 - ETA: 3:09 - loss: 1.290 - ETA: 3:05 - loss: 1.290 - ETA: 3:01 - loss: 1.291 - ETA: 2:57 - loss: 1.291 - ETA: 2:53 - loss: 1.290 - ETA: 2:49 - loss: 1.290 - ETA: 2:45 - loss: 1.290 - ETA: 2:40 - loss: 1.290 - ETA: 2:36 - loss: 1.290 - ETA: 2:32 - loss: 1.290 - ETA: 2:28 - loss: 1.291 - ETA: 2:24 - loss: 1.292 - ETA: 2:20 - loss: 1.291 - ETA: 2:16 - loss: 1.292 - ETA: 2:12 - loss: 1.292 - ETA: 2:07 - loss: 1.292 - ETA: 2:03 - loss: 1.293 - ETA: 1:59 - loss: 1.293 - ETA: 1:55 - loss: 1.293 - ETA: 1:51 - loss: 1.293 - ETA: 1:47 - loss: 1.293 - ETA: 1:43 - loss: 1.293 - ETA: 1:39 - loss: 1.293 - ETA: 1:34 - loss: 1.293 - ETA: 1:30 - loss: 1.293 - ETA: 1:26 - loss: 1.293 - ETA: 1:22 - loss: 1.293 - ETA: 1:18 - loss: 1.293 - ETA: 1:14 - loss: 1.292 - ETA: 1:10 - loss: 1.292 - ETA: 1:06 - loss: 1.292 - ETA: 1:01 - loss: 1.292 - ETA: 57s - loss: 1.292 - ETA: 53s - loss: 1.29 - ETA: 49s - loss: 1.29 - ETA: 45s - loss: 1.29 - ETA: 41s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 20s - loss: 1.29 - ETA: 16s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 8s - loss: 1.2916 - ETA: 4s - loss: 1.2913WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2910\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:51 - loss: 1.266 - ETA: 6:45 - loss: 1.267 - ETA: 6:41 - loss: 1.267 - ETA: 6:36 - loss: 1.267 - ETA: 6:32 - loss: 1.271 - ETA: 6:28 - loss: 1.274 - ETA: 6:23 - loss: 1.274 - ETA: 6:19 - loss: 1.273 - ETA: 6:15 - loss: 1.270 - ETA: 6:11 - loss: 1.269 - ETA: 6:06 - loss: 1.272 - ETA: 6:02 - loss: 1.272 - ETA: 5:58 - loss: 1.276 - ETA: 5:54 - loss: 1.277 - ETA: 5:50 - loss: 1.277 - ETA: 5:46 - loss: 1.281 - ETA: 5:42 - loss: 1.280 - ETA: 5:38 - loss: 1.279 - ETA: 5:34 - loss: 1.281 - ETA: 5:30 - loss: 1.284 - ETA: 5:26 - loss: 1.284 - ETA: 5:21 - loss: 1.286 - ETA: 5:17 - loss: 1.286 - ETA: 5:13 - loss: 1.285 - ETA: 5:09 - loss: 1.287 - ETA: 5:05 - loss: 1.289 - ETA: 5:01 - loss: 1.288 - ETA: 4:57 - loss: 1.288 - ETA: 4:53 - loss: 1.288 - ETA: 4:49 - loss: 1.288 - ETA: 4:44 - loss: 1.289 - ETA: 4:40 - loss: 1.290 - ETA: 4:36 - loss: 1.290 - ETA: 4:32 - loss: 1.290 - ETA: 4:28 - loss: 1.289 - ETA: 4:24 - loss: 1.288 - ETA: 4:19 - loss: 1.288 - ETA: 4:15 - loss: 1.287 - ETA: 4:12 - loss: 1.286 - ETA: 4:08 - loss: 1.287 - ETA: 4:04 - loss: 1.286 - ETA: 4:00 - loss: 1.287 - ETA: 3:56 - loss: 1.287 - ETA: 3:51 - loss: 1.287 - ETA: 3:47 - loss: 1.288 - ETA: 3:43 - loss: 1.288 - ETA: 3:39 - loss: 1.288 - ETA: 3:35 - loss: 1.288 - ETA: 3:31 - loss: 1.288 - ETA: 3:26 - loss: 1.287 - ETA: 3:22 - loss: 1.287 - ETA: 3:18 - loss: 1.288 - ETA: 3:14 - loss: 1.287 - ETA: 3:10 - loss: 1.287 - ETA: 3:06 - loss: 1.287 - ETA: 3:02 - loss: 1.288 - ETA: 2:57 - loss: 1.287 - ETA: 2:53 - loss: 1.287 - ETA: 2:49 - loss: 1.286 - ETA: 2:45 - loss: 1.287 - ETA: 2:41 - loss: 1.287 - ETA: 2:37 - loss: 1.287 - ETA: 2:33 - loss: 1.287 - ETA: 2:28 - loss: 1.287 - ETA: 2:24 - loss: 1.287 - ETA: 2:20 - loss: 1.287 - ETA: 2:16 - loss: 1.287 - ETA: 2:12 - loss: 1.288 - ETA: 2:08 - loss: 1.287 - ETA: 2:04 - loss: 1.287 - ETA: 1:59 - loss: 1.287 - ETA: 1:55 - loss: 1.287 - ETA: 1:51 - loss: 1.287 - ETA: 1:47 - loss: 1.288 - ETA: 1:43 - loss: 1.288 - ETA: 1:39 - loss: 1.287 - ETA: 1:35 - loss: 1.287 - ETA: 1:30 - loss: 1.287 - ETA: 1:26 - loss: 1.287 - ETA: 1:22 - loss: 1.287 - ETA: 1:18 - loss: 1.287 - ETA: 1:14 - loss: 1.287 - ETA: 1:10 - loss: 1.287 - ETA: 1:06 - loss: 1.287 - ETA: 1:01 - loss: 1.286 - ETA: 57s - loss: 1.286 - ETA: 53s - loss: 1.28 - ETA: 49s - loss: 1.28 - ETA: 45s - loss: 1.28 - ETA: 41s - loss: 1.28 - ETA: 37s - loss: 1.28 - ETA: 33s - loss: 1.28 - ETA: 28s - loss: 1.28 - ETA: 24s - loss: 1.28 - ETA: 20s - loss: 1.28 - ETA: 16s - loss: 1.28 - ETA: 12s - loss: 1.28 - ETA: 8s - loss: 1.2862 - ETA: 4s - loss: 1.2861WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2859\n",
      "Epoch 40/100\n",
      " 99/100 [============================>.] - ETA: 6:46 - loss: 1.261 - ETA: 6:43 - loss: 1.280 - ETA: 6:39 - loss: 1.273 - ETA: 6:35 - loss: 1.267 - ETA: 6:31 - loss: 1.269 - ETA: 6:27 - loss: 1.270 - ETA: 6:23 - loss: 1.266 - ETA: 6:19 - loss: 1.266 - ETA: 6:15 - loss: 1.265 - ETA: 6:11 - loss: 1.265 - ETA: 6:07 - loss: 1.264 - ETA: 6:03 - loss: 1.263 - ETA: 5:58 - loss: 1.266 - ETA: 5:54 - loss: 1.268 - ETA: 5:50 - loss: 1.271 - ETA: 5:46 - loss: 1.273 - ETA: 5:42 - loss: 1.270 - ETA: 5:38 - loss: 1.271 - ETA: 5:34 - loss: 1.273 - ETA: 5:30 - loss: 1.272 - ETA: 5:25 - loss: 1.271 - ETA: 5:21 - loss: 1.272 - ETA: 5:17 - loss: 1.271 - ETA: 5:13 - loss: 1.272 - ETA: 5:09 - loss: 1.273 - ETA: 5:05 - loss: 1.273 - ETA: 5:01 - loss: 1.273 - ETA: 4:56 - loss: 1.274 - ETA: 4:52 - loss: 1.275 - ETA: 4:48 - loss: 1.274 - ETA: 4:44 - loss: 1.272 - ETA: 4:40 - loss: 1.273 - ETA: 4:36 - loss: 1.274 - ETA: 4:32 - loss: 1.274 - ETA: 4:28 - loss: 1.274 - ETA: 4:24 - loss: 1.273 - ETA: 4:19 - loss: 1.270 - ETA: 4:15 - loss: 1.270 - ETA: 4:11 - loss: 1.270 - ETA: 4:07 - loss: 1.269 - ETA: 4:03 - loss: 1.269 - ETA: 3:59 - loss: 1.270 - ETA: 3:55 - loss: 1.269 - ETA: 3:50 - loss: 1.270 - ETA: 3:46 - loss: 1.271 - ETA: 3:42 - loss: 1.271 - ETA: 3:38 - loss: 1.271 - ETA: 3:34 - loss: 1.270 - ETA: 3:30 - loss: 1.270 - ETA: 3:26 - loss: 1.270 - ETA: 3:22 - loss: 1.270 - ETA: 3:18 - loss: 1.270 - ETA: 3:13 - loss: 1.269 - ETA: 3:09 - loss: 1.269 - ETA: 3:05 - loss: 1.269 - ETA: 3:01 - loss: 1.269 - ETA: 2:57 - loss: 1.270 - ETA: 2:53 - loss: 1.271 - ETA: 2:49 - loss: 1.271 - ETA: 2:45 - loss: 1.271 - ETA: 2:41 - loss: 1.271 - ETA: 2:36 - loss: 1.271 - ETA: 2:32 - loss: 1.271 - ETA: 2:28 - loss: 1.272 - ETA: 2:24 - loss: 1.271 - ETA: 2:20 - loss: 1.271 - ETA: 2:16 - loss: 1.271 - ETA: 2:12 - loss: 1.270 - ETA: 2:07 - loss: 1.271 - ETA: 2:03 - loss: 1.272 - ETA: 1:59 - loss: 1.272 - ETA: 1:55 - loss: 1.272 - ETA: 1:51 - loss: 1.272 - ETA: 1:47 - loss: 1.272 - ETA: 1:43 - loss: 1.272 - ETA: 1:39 - loss: 1.272 - ETA: 1:34 - loss: 1.272 - ETA: 1:30 - loss: 1.272 - ETA: 1:26 - loss: 1.272 - ETA: 1:22 - loss: 1.273 - ETA: 1:18 - loss: 1.273 - ETA: 1:14 - loss: 1.272 - ETA: 1:10 - loss: 1.273 - ETA: 1:06 - loss: 1.273 - ETA: 1:01 - loss: 1.273 - ETA: 57s - loss: 1.273 - ETA: 53s - loss: 1.27 - ETA: 49s - loss: 1.27 - ETA: 45s - loss: 1.27 - ETA: 41s - loss: 1.27 - ETA: 37s - loss: 1.27 - ETA: 33s - loss: 1.27 - ETA: 28s - loss: 1.27 - ETA: 24s - loss: 1.27 - ETA: 20s - loss: 1.27 - ETA: 16s - loss: 1.27 - ETA: 12s - loss: 1.27 - ETA: 8s - loss: 1.2765 - ETA: 4s - loss: 1.2767WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2767\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.270 - ETA: 6:43 - loss: 1.277 - ETA: 6:39 - loss: 1.274 - ETA: 6:36 - loss: 1.285 - ETA: 6:32 - loss: 1.282 - ETA: 6:28 - loss: 1.276 - ETA: 6:24 - loss: 1.279 - ETA: 6:20 - loss: 1.275 - ETA: 6:15 - loss: 1.273 - ETA: 6:11 - loss: 1.274 - ETA: 6:07 - loss: 1.275 - ETA: 6:03 - loss: 1.275 - ETA: 5:59 - loss: 1.272 - ETA: 5:54 - loss: 1.274 - ETA: 5:51 - loss: 1.278 - ETA: 5:46 - loss: 1.279 - ETA: 5:42 - loss: 1.277 - ETA: 5:38 - loss: 1.276 - ETA: 5:34 - loss: 1.276 - ETA: 5:30 - loss: 1.277 - ETA: 5:26 - loss: 1.277 - ETA: 5:22 - loss: 1.277 - ETA: 5:17 - loss: 1.277 - ETA: 5:13 - loss: 1.278 - ETA: 5:09 - loss: 1.278 - ETA: 5:05 - loss: 1.277 - ETA: 5:01 - loss: 1.277 - ETA: 4:57 - loss: 1.279 - ETA: 4:53 - loss: 1.279 - ETA: 4:48 - loss: 1.278 - ETA: 4:44 - loss: 1.278 - ETA: 4:40 - loss: 1.278 - ETA: 4:36 - loss: 1.279 - ETA: 4:32 - loss: 1.278 - ETA: 4:28 - loss: 1.278 - ETA: 4:24 - loss: 1.278 - ETA: 4:20 - loss: 1.278 - ETA: 4:16 - loss: 1.278 - ETA: 4:11 - loss: 1.278 - ETA: 4:07 - loss: 1.279 - ETA: 4:03 - loss: 1.279 - ETA: 3:59 - loss: 1.278 - ETA: 3:55 - loss: 1.279 - ETA: 3:51 - loss: 1.278 - ETA: 3:47 - loss: 1.278 - ETA: 3:43 - loss: 1.278 - ETA: 3:38 - loss: 1.277 - ETA: 3:34 - loss: 1.277 - ETA: 3:30 - loss: 1.277 - ETA: 3:26 - loss: 1.277 - ETA: 3:22 - loss: 1.277 - ETA: 3:18 - loss: 1.278 - ETA: 3:14 - loss: 1.278 - ETA: 3:10 - loss: 1.277 - ETA: 3:05 - loss: 1.278 - ETA: 3:01 - loss: 1.276 - ETA: 2:57 - loss: 1.276 - ETA: 2:53 - loss: 1.276 - ETA: 2:49 - loss: 1.277 - ETA: 2:45 - loss: 1.277 - ETA: 2:41 - loss: 1.277 - ETA: 2:37 - loss: 1.277 - ETA: 2:33 - loss: 1.277 - ETA: 2:28 - loss: 1.277 - ETA: 2:24 - loss: 1.278 - ETA: 2:20 - loss: 1.278 - ETA: 2:16 - loss: 1.278 - ETA: 2:12 - loss: 1.278 - ETA: 2:08 - loss: 1.279 - ETA: 2:04 - loss: 1.278 - ETA: 1:59 - loss: 1.279 - ETA: 1:55 - loss: 1.278 - ETA: 1:51 - loss: 1.279 - ETA: 1:47 - loss: 1.279 - ETA: 1:43 - loss: 1.278 - ETA: 1:39 - loss: 1.279 - ETA: 1:35 - loss: 1.279 - ETA: 1:30 - loss: 1.279 - ETA: 1:26 - loss: 1.280 - ETA: 1:22 - loss: 1.280 - ETA: 1:18 - loss: 1.279 - ETA: 1:14 - loss: 1.279 - ETA: 1:10 - loss: 1.279 - ETA: 1:06 - loss: 1.279 - ETA: 1:02 - loss: 1.279 - ETA: 57s - loss: 1.279 - ETA: 53s - loss: 1.27 - ETA: 49s - loss: 1.27 - ETA: 45s - loss: 1.27 - ETA: 41s - loss: 1.27 - ETA: 37s - loss: 1.27 - ETA: 33s - loss: 1.27 - ETA: 28s - loss: 1.27 - ETA: 24s - loss: 1.27 - ETA: 20s - loss: 1.27 - ETA: 16s - loss: 1.27 - ETA: 12s - loss: 1.27 - ETA: 8s - loss: 1.2786 - ETA: 4s - loss: 1.2785WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2780\n",
      "Epoch 42/100\n",
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.281 - ETA: 6:43 - loss: 1.260 - ETA: 6:39 - loss: 1.278 - ETA: 6:36 - loss: 1.270 - ETA: 6:32 - loss: 1.260 - ETA: 6:28 - loss: 1.270 - ETA: 6:24 - loss: 1.270 - ETA: 6:20 - loss: 1.274 - ETA: 6:16 - loss: 1.268 - ETA: 6:12 - loss: 1.270 - ETA: 6:07 - loss: 1.267 - ETA: 6:03 - loss: 1.267 - ETA: 5:59 - loss: 1.266 - ETA: 5:55 - loss: 1.263 - ETA: 5:51 - loss: 1.264 - ETA: 5:46 - loss: 1.264 - ETA: 5:42 - loss: 1.263 - ETA: 5:38 - loss: 1.263 - ETA: 5:34 - loss: 1.264 - ETA: 5:30 - loss: 1.265 - ETA: 5:26 - loss: 1.263 - ETA: 5:22 - loss: 1.262 - ETA: 5:18 - loss: 1.262 - ETA: 5:13 - loss: 1.263 - ETA: 5:09 - loss: 1.265 - ETA: 5:05 - loss: 1.264 - ETA: 5:01 - loss: 1.263 - ETA: 4:57 - loss: 1.264 - ETA: 4:53 - loss: 1.264 - ETA: 4:49 - loss: 1.263 - ETA: 4:44 - loss: 1.263 - ETA: 4:40 - loss: 1.263 - ETA: 4:36 - loss: 1.264 - ETA: 4:32 - loss: 1.265 - ETA: 4:28 - loss: 1.267 - ETA: 4:24 - loss: 1.266 - ETA: 4:20 - loss: 1.266 - ETA: 4:15 - loss: 1.267 - ETA: 4:11 - loss: 1.268 - ETA: 4:07 - loss: 1.268 - ETA: 4:03 - loss: 1.268 - ETA: 3:59 - loss: 1.269 - ETA: 3:55 - loss: 1.270 - ETA: 3:51 - loss: 1.270 - ETA: 3:47 - loss: 1.270 - ETA: 3:42 - loss: 1.270 - ETA: 3:38 - loss: 1.270 - ETA: 3:34 - loss: 1.271 - ETA: 3:30 - loss: 1.270 - ETA: 3:26 - loss: 1.269 - ETA: 3:22 - loss: 1.269 - ETA: 3:18 - loss: 1.269 - ETA: 3:14 - loss: 1.269 - ETA: 3:09 - loss: 1.269 - ETA: 3:05 - loss: 1.270 - ETA: 3:01 - loss: 1.270 - ETA: 2:57 - loss: 1.271 - ETA: 2:53 - loss: 1.271 - ETA: 2:49 - loss: 1.271 - ETA: 2:45 - loss: 1.272 - ETA: 2:40 - loss: 1.272 - ETA: 2:36 - loss: 1.273 - ETA: 2:32 - loss: 1.274 - ETA: 2:28 - loss: 1.274 - ETA: 2:24 - loss: 1.274 - ETA: 2:20 - loss: 1.274 - ETA: 2:16 - loss: 1.274 - ETA: 2:12 - loss: 1.275 - ETA: 2:07 - loss: 1.275 - ETA: 2:03 - loss: 1.275 - ETA: 1:59 - loss: 1.275 - ETA: 1:55 - loss: 1.275 - ETA: 1:51 - loss: 1.275 - ETA: 1:47 - loss: 1.274 - ETA: 1:43 - loss: 1.274 - ETA: 1:38 - loss: 1.274 - ETA: 1:34 - loss: 1.274 - ETA: 1:30 - loss: 1.274 - ETA: 1:26 - loss: 1.273 - ETA: 1:22 - loss: 1.273 - ETA: 1:18 - loss: 1.273 - ETA: 1:14 - loss: 1.273 - ETA: 1:10 - loss: 1.273 - ETA: 1:06 - loss: 1.273 - ETA: 1:01 - loss: 1.273 - ETA: 57s - loss: 1.272 - ETA: 53s - loss: 1.27 - ETA: 49s - loss: 1.27 - ETA: 45s - loss: 1.27 - ETA: 41s - loss: 1.27 - ETA: 37s - loss: 1.27 - ETA: 33s - loss: 1.27 - ETA: 28s - loss: 1.27 - ETA: 24s - loss: 1.27 - ETA: 20s - loss: 1.27 - ETA: 16s - loss: 1.27 - ETA: 12s - loss: 1.27 - ETA: 8s - loss: 1.2717 - ETA: 4s - loss: 1.2719WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2720\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.257 - ETA: 6:44 - loss: 1.274 - ETA: 6:39 - loss: 1.273 - ETA: 6:35 - loss: 1.269 - ETA: 6:31 - loss: 1.279 - ETA: 6:27 - loss: 1.277 - ETA: 6:23 - loss: 1.275 - ETA: 6:19 - loss: 1.277 - ETA: 6:15 - loss: 1.276 - ETA: 6:11 - loss: 1.275 - ETA: 6:06 - loss: 1.270 - ETA: 6:02 - loss: 1.270 - ETA: 5:58 - loss: 1.267 - ETA: 5:54 - loss: 1.265 - ETA: 5:50 - loss: 1.267 - ETA: 5:46 - loss: 1.267 - ETA: 5:42 - loss: 1.269 - ETA: 5:38 - loss: 1.272 - ETA: 5:33 - loss: 1.275 - ETA: 5:29 - loss: 1.274 - ETA: 5:25 - loss: 1.274 - ETA: 5:21 - loss: 1.272 - ETA: 5:17 - loss: 1.273 - ETA: 5:13 - loss: 1.272 - ETA: 5:09 - loss: 1.272 - ETA: 5:05 - loss: 1.273 - ETA: 5:01 - loss: 1.273 - ETA: 4:57 - loss: 1.274 - ETA: 4:52 - loss: 1.275 - ETA: 4:48 - loss: 1.275 - ETA: 4:44 - loss: 1.277 - ETA: 4:40 - loss: 1.276 - ETA: 4:36 - loss: 1.276 - ETA: 4:32 - loss: 1.277 - ETA: 4:28 - loss: 1.277 - ETA: 4:24 - loss: 1.276 - ETA: 4:19 - loss: 1.276 - ETA: 4:15 - loss: 1.276 - ETA: 4:11 - loss: 1.275 - ETA: 4:07 - loss: 1.276 - ETA: 4:03 - loss: 1.275 - ETA: 3:59 - loss: 1.274 - ETA: 3:55 - loss: 1.274 - ETA: 3:51 - loss: 1.274 - ETA: 3:46 - loss: 1.274 - ETA: 3:42 - loss: 1.275 - ETA: 3:38 - loss: 1.274 - ETA: 3:34 - loss: 1.274 - ETA: 3:30 - loss: 1.274 - ETA: 3:26 - loss: 1.273 - ETA: 3:22 - loss: 1.274 - ETA: 3:18 - loss: 1.273 - ETA: 3:13 - loss: 1.273 - ETA: 3:09 - loss: 1.272 - ETA: 3:05 - loss: 1.272 - ETA: 3:01 - loss: 1.271 - ETA: 2:57 - loss: 1.271 - ETA: 2:53 - loss: 1.272 - ETA: 2:49 - loss: 1.272 - ETA: 2:45 - loss: 1.271 - ETA: 2:41 - loss: 1.272 - ETA: 2:36 - loss: 1.272 - ETA: 2:32 - loss: 1.272 - ETA: 2:28 - loss: 1.273 - ETA: 2:24 - loss: 1.272 - ETA: 2:20 - loss: 1.273 - ETA: 2:16 - loss: 1.273 - ETA: 2:12 - loss: 1.272 - ETA: 2:08 - loss: 1.272 - ETA: 2:03 - loss: 1.272 - ETA: 1:59 - loss: 1.272 - ETA: 1:55 - loss: 1.272 - ETA: 1:51 - loss: 1.271 - ETA: 1:47 - loss: 1.271 - ETA: 1:43 - loss: 1.271 - ETA: 1:39 - loss: 1.271 - ETA: 1:35 - loss: 1.271 - ETA: 1:30 - loss: 1.271 - ETA: 1:26 - loss: 1.271 - ETA: 1:22 - loss: 1.271 - ETA: 1:18 - loss: 1.271 - ETA: 1:14 - loss: 1.272 - ETA: 1:10 - loss: 1.271 - ETA: 1:06 - loss: 1.271 - ETA: 1:02 - loss: 1.272 - ETA: 57s - loss: 1.272 - ETA: 53s - loss: 1.27 - ETA: 49s - loss: 1.27 - ETA: 45s - loss: 1.27 - ETA: 41s - loss: 1.27 - ETA: 37s - loss: 1.27 - ETA: 33s - loss: 1.27 - ETA: 28s - loss: 1.27 - ETA: 24s - loss: 1.27 - ETA: 20s - loss: 1.27 - ETA: 16s - loss: 1.27 - ETA: 12s - loss: 1.27 - ETA: 8s - loss: 1.2722 - ETA: 4s - loss: 1.2720WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2721\n",
      "Epoch 44/100\n",
      " 99/100 [============================>.] - ETA: 6:46 - loss: 1.224 - ETA: 6:42 - loss: 1.241 - ETA: 6:39 - loss: 1.253 - ETA: 6:35 - loss: 1.259 - ETA: 6:31 - loss: 1.257 - ETA: 6:27 - loss: 1.264 - ETA: 6:23 - loss: 1.272 - ETA: 6:19 - loss: 1.269 - ETA: 6:15 - loss: 1.266 - ETA: 6:11 - loss: 1.271 - ETA: 6:07 - loss: 1.268 - ETA: 6:02 - loss: 1.269 - ETA: 5:58 - loss: 1.267 - ETA: 5:54 - loss: 1.263 - ETA: 5:50 - loss: 1.263 - ETA: 5:46 - loss: 1.268 - ETA: 5:42 - loss: 1.270 - ETA: 5:38 - loss: 1.271 - ETA: 5:34 - loss: 1.271 - ETA: 5:30 - loss: 1.272 - ETA: 5:25 - loss: 1.273 - ETA: 5:21 - loss: 1.272 - ETA: 5:17 - loss: 1.274 - ETA: 5:13 - loss: 1.274 - ETA: 5:09 - loss: 1.276 - ETA: 5:05 - loss: 1.275 - ETA: 5:01 - loss: 1.274 - ETA: 4:57 - loss: 1.273 - ETA: 4:53 - loss: 1.273 - ETA: 4:49 - loss: 1.273 - ETA: 4:44 - loss: 1.273 - ETA: 4:40 - loss: 1.272 - ETA: 4:36 - loss: 1.272 - ETA: 4:32 - loss: 1.271 - ETA: 4:28 - loss: 1.271 - ETA: 4:24 - loss: 1.272 - ETA: 4:20 - loss: 1.272 - ETA: 4:15 - loss: 1.272 - ETA: 4:11 - loss: 1.271 - ETA: 4:07 - loss: 1.271 - ETA: 4:03 - loss: 1.270 - ETA: 3:59 - loss: 1.270 - ETA: 3:55 - loss: 1.270 - ETA: 3:51 - loss: 1.270 - ETA: 3:46 - loss: 1.269 - ETA: 3:42 - loss: 1.269 - ETA: 3:38 - loss: 1.269 - ETA: 3:34 - loss: 1.269 - ETA: 3:30 - loss: 1.269 - ETA: 3:26 - loss: 1.270 - ETA: 3:22 - loss: 1.270 - ETA: 3:18 - loss: 1.269 - ETA: 3:13 - loss: 1.270 - ETA: 3:09 - loss: 1.271 - ETA: 3:05 - loss: 1.271 - ETA: 3:01 - loss: 1.271 - ETA: 2:57 - loss: 1.271 - ETA: 2:53 - loss: 1.270 - ETA: 2:49 - loss: 1.271 - ETA: 2:45 - loss: 1.270 - ETA: 2:40 - loss: 1.271 - ETA: 2:36 - loss: 1.269 - ETA: 2:32 - loss: 1.269 - ETA: 2:28 - loss: 1.269 - ETA: 2:24 - loss: 1.269 - ETA: 2:20 - loss: 1.268 - ETA: 2:16 - loss: 1.268 - ETA: 2:12 - loss: 1.268 - ETA: 2:07 - loss: 1.268 - ETA: 2:03 - loss: 1.268 - ETA: 1:59 - loss: 1.268 - ETA: 1:55 - loss: 1.268 - ETA: 1:51 - loss: 1.269 - ETA: 1:47 - loss: 1.268 - ETA: 1:43 - loss: 1.268 - ETA: 1:39 - loss: 1.268 - ETA: 1:34 - loss: 1.267 - ETA: 1:30 - loss: 1.268 - ETA: 1:26 - loss: 1.267 - ETA: 1:22 - loss: 1.266 - ETA: 1:18 - loss: 1.267 - ETA: 1:14 - loss: 1.267 - ETA: 1:10 - loss: 1.267 - ETA: 1:06 - loss: 1.267 - ETA: 1:01 - loss: 1.267 - ETA: 57s - loss: 1.267 - ETA: 53s - loss: 1.26 - ETA: 49s - loss: 1.26 - ETA: 45s - loss: 1.26 - ETA: 41s - loss: 1.26 - ETA: 37s - loss: 1.26 - ETA: 33s - loss: 1.26 - ETA: 28s - loss: 1.26 - ETA: 24s - loss: 1.26 - ETA: 20s - loss: 1.26 - ETA: 16s - loss: 1.26 - ETA: 12s - loss: 1.26 - ETA: 8s - loss: 1.2668 - ETA: 4s - loss: 1.2664WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2659\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.281 - ETA: 6:44 - loss: 1.292 - ETA: 6:40 - loss: 1.282 - ETA: 6:35 - loss: 1.279 - ETA: 6:32 - loss: 1.266 - ETA: 6:28 - loss: 1.265 - ETA: 6:23 - loss: 1.266 - ETA: 6:19 - loss: 1.267 - ETA: 6:15 - loss: 1.271 - ETA: 6:11 - loss: 1.268 - ETA: 6:07 - loss: 1.270 - ETA: 6:03 - loss: 1.271 - ETA: 5:59 - loss: 1.270 - ETA: 5:55 - loss: 1.269 - ETA: 5:51 - loss: 1.269 - ETA: 5:46 - loss: 1.270 - ETA: 5:42 - loss: 1.270 - ETA: 5:38 - loss: 1.269 - ETA: 5:34 - loss: 1.273 - ETA: 5:30 - loss: 1.271 - ETA: 5:26 - loss: 1.272 - ETA: 5:21 - loss: 1.272 - ETA: 5:17 - loss: 1.271 - ETA: 5:13 - loss: 1.272 - ETA: 5:09 - loss: 1.273 - ETA: 5:05 - loss: 1.273 - ETA: 5:01 - loss: 1.273 - ETA: 4:57 - loss: 1.273 - ETA: 4:52 - loss: 1.273 - ETA: 4:48 - loss: 1.270 - ETA: 4:44 - loss: 1.270 - ETA: 4:40 - loss: 1.269 - ETA: 4:36 - loss: 1.268 - ETA: 4:32 - loss: 1.267 - ETA: 4:28 - loss: 1.267 - ETA: 4:23 - loss: 1.267 - ETA: 4:19 - loss: 1.267 - ETA: 4:15 - loss: 1.267 - ETA: 4:11 - loss: 1.267 - ETA: 4:07 - loss: 1.267 - ETA: 4:03 - loss: 1.267 - ETA: 3:59 - loss: 1.266 - ETA: 3:55 - loss: 1.267 - ETA: 3:50 - loss: 1.267 - ETA: 3:46 - loss: 1.268 - ETA: 3:42 - loss: 1.268 - ETA: 3:38 - loss: 1.268 - ETA: 3:34 - loss: 1.268 - ETA: 3:30 - loss: 1.268 - ETA: 3:26 - loss: 1.268 - ETA: 3:22 - loss: 1.267 - ETA: 3:18 - loss: 1.266 - ETA: 3:13 - loss: 1.266 - ETA: 3:09 - loss: 1.266 - ETA: 3:05 - loss: 1.266 - ETA: 3:01 - loss: 1.266 - ETA: 2:57 - loss: 1.266 - ETA: 2:53 - loss: 1.266 - ETA: 2:49 - loss: 1.266 - ETA: 2:45 - loss: 1.266 - ETA: 2:40 - loss: 1.266 - ETA: 2:36 - loss: 1.266 - ETA: 2:32 - loss: 1.266 - ETA: 2:28 - loss: 1.266 - ETA: 2:24 - loss: 1.266 - ETA: 2:20 - loss: 1.266 - ETA: 2:16 - loss: 1.266 - ETA: 2:12 - loss: 1.266 - ETA: 2:07 - loss: 1.266 - ETA: 2:03 - loss: 1.266 - ETA: 1:59 - loss: 1.265 - ETA: 1:55 - loss: 1.266 - ETA: 1:51 - loss: 1.266 - ETA: 1:47 - loss: 1.266 - ETA: 1:43 - loss: 1.266 - ETA: 1:39 - loss: 1.266 - ETA: 1:34 - loss: 1.267 - ETA: 1:30 - loss: 1.266 - ETA: 1:26 - loss: 1.266 - ETA: 1:22 - loss: 1.266 - ETA: 1:18 - loss: 1.266 - ETA: 1:14 - loss: 1.267 - ETA: 1:10 - loss: 1.266 - ETA: 1:06 - loss: 1.266 - ETA: 1:01 - loss: 1.266 - ETA: 57s - loss: 1.266 - ETA: 53s - loss: 1.26 - ETA: 49s - loss: 1.26 - ETA: 45s - loss: 1.26 - ETA: 41s - loss: 1.26 - ETA: 37s - loss: 1.26 - ETA: 33s - loss: 1.26 - ETA: 28s - loss: 1.26 - ETA: 24s - loss: 1.26 - ETA: 20s - loss: 1.26 - ETA: 16s - loss: 1.26 - ETA: 12s - loss: 1.26 - ETA: 8s - loss: 1.2661 - ETA: 4s - loss: 1.2665WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2667\n",
      "Epoch 46/100\n",
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.290 - ETA: 6:44 - loss: 1.272 - ETA: 6:41 - loss: 1.282 - ETA: 6:36 - loss: 1.283 - ETA: 6:33 - loss: 1.286 - ETA: 6:29 - loss: 1.281 - ETA: 6:25 - loss: 1.287 - ETA: 6:21 - loss: 1.285 - ETA: 6:16 - loss: 1.280 - ETA: 6:12 - loss: 1.278 - ETA: 6:08 - loss: 1.279 - ETA: 6:03 - loss: 1.277 - ETA: 5:59 - loss: 1.276 - ETA: 5:55 - loss: 1.273 - ETA: 5:51 - loss: 1.272 - ETA: 5:47 - loss: 1.271 - ETA: 5:43 - loss: 1.273 - ETA: 5:39 - loss: 1.274 - ETA: 5:35 - loss: 1.274 - ETA: 5:31 - loss: 1.274 - ETA: 5:26 - loss: 1.274 - ETA: 5:22 - loss: 1.275 - ETA: 5:18 - loss: 1.274 - ETA: 5:14 - loss: 1.273 - ETA: 5:10 - loss: 1.272 - ETA: 5:06 - loss: 1.272 - ETA: 5:02 - loss: 1.270 - ETA: 4:58 - loss: 1.271 - ETA: 4:53 - loss: 1.271 - ETA: 4:49 - loss: 1.270 - ETA: 4:45 - loss: 1.269 - ETA: 4:41 - loss: 1.269 - ETA: 4:37 - loss: 1.270 - ETA: 4:33 - loss: 1.270 - ETA: 4:29 - loss: 1.270 - ETA: 4:24 - loss: 1.270 - ETA: 4:20 - loss: 1.270 - ETA: 4:16 - loss: 1.269 - ETA: 4:12 - loss: 1.270 - ETA: 4:08 - loss: 1.270 - ETA: 4:04 - loss: 1.269 - ETA: 4:00 - loss: 1.270 - ETA: 3:56 - loss: 1.269 - ETA: 3:51 - loss: 1.270 - ETA: 3:47 - loss: 1.271 - ETA: 3:43 - loss: 1.271 - ETA: 3:39 - loss: 1.271 - ETA: 3:35 - loss: 1.272 - ETA: 3:31 - loss: 1.272 - ETA: 3:27 - loss: 1.272 - ETA: 3:22 - loss: 1.271 - ETA: 3:18 - loss: 1.271 - ETA: 3:14 - loss: 1.271 - ETA: 3:10 - loss: 1.270 - ETA: 3:06 - loss: 1.269 - ETA: 3:02 - loss: 1.267 - ETA: 2:58 - loss: 1.268 - ETA: 2:53 - loss: 1.268 - ETA: 2:49 - loss: 1.269 - ETA: 2:45 - loss: 1.269 - ETA: 2:41 - loss: 1.269 - ETA: 2:37 - loss: 1.269 - ETA: 2:33 - loss: 1.270 - ETA: 2:28 - loss: 1.270 - ETA: 2:24 - loss: 1.271 - ETA: 2:20 - loss: 1.271 - ETA: 2:16 - loss: 1.271 - ETA: 2:12 - loss: 1.271 - ETA: 2:08 - loss: 1.271 - ETA: 2:04 - loss: 1.271 - ETA: 1:59 - loss: 1.270 - ETA: 1:55 - loss: 1.270 - ETA: 1:51 - loss: 1.270 - ETA: 1:47 - loss: 1.270 - ETA: 1:43 - loss: 1.271 - ETA: 1:39 - loss: 1.270 - ETA: 1:35 - loss: 1.270 - ETA: 1:30 - loss: 1.270 - ETA: 1:26 - loss: 1.270 - ETA: 1:22 - loss: 1.270 - ETA: 1:18 - loss: 1.269 - ETA: 1:14 - loss: 1.269 - ETA: 1:10 - loss: 1.268 - ETA: 1:06 - loss: 1.269 - ETA: 1:02 - loss: 1.269 - ETA: 57s - loss: 1.269 - ETA: 53s - loss: 1.26 - ETA: 49s - loss: 1.26 - ETA: 45s - loss: 1.26 - ETA: 41s - loss: 1.26 - ETA: 37s - loss: 1.26 - ETA: 33s - loss: 1.26 - ETA: 28s - loss: 1.26 - ETA: 24s - loss: 1.26 - ETA: 20s - loss: 1.26 - ETA: 16s - loss: 1.26 - ETA: 12s - loss: 1.26 - ETA: 8s - loss: 1.2681 - ETA: 4s - loss: 1.2681WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2681\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.223 - ETA: 6:42 - loss: 1.241 - ETA: 6:38 - loss: 1.254 - ETA: 6:34 - loss: 1.262 - ETA: 6:31 - loss: 1.261 - ETA: 6:27 - loss: 1.256 - ETA: 6:22 - loss: 1.253 - ETA: 6:18 - loss: 1.254 - ETA: 6:14 - loss: 1.253 - ETA: 6:10 - loss: 1.255 - ETA: 6:06 - loss: 1.256 - ETA: 6:02 - loss: 1.255 - ETA: 5:58 - loss: 1.254 - ETA: 5:54 - loss: 1.256 - ETA: 5:50 - loss: 1.256 - ETA: 5:46 - loss: 1.255 - ETA: 5:42 - loss: 1.254 - ETA: 5:38 - loss: 1.254 - ETA: 5:34 - loss: 1.254 - ETA: 5:30 - loss: 1.253 - ETA: 5:26 - loss: 1.252 - ETA: 5:21 - loss: 1.252 - ETA: 5:17 - loss: 1.253 - ETA: 5:13 - loss: 1.252 - ETA: 5:09 - loss: 1.252 - ETA: 5:05 - loss: 1.253 - ETA: 5:01 - loss: 1.252 - ETA: 4:57 - loss: 1.252 - ETA: 4:53 - loss: 1.252 - ETA: 4:48 - loss: 1.252 - ETA: 4:44 - loss: 1.250 - ETA: 4:40 - loss: 1.251 - ETA: 4:36 - loss: 1.251 - ETA: 4:32 - loss: 1.252 - ETA: 4:28 - loss: 1.252 - ETA: 4:24 - loss: 1.252 - ETA: 4:19 - loss: 1.252 - ETA: 4:15 - loss: 1.253 - ETA: 4:11 - loss: 1.253 - ETA: 4:07 - loss: 1.252 - ETA: 4:03 - loss: 1.253 - ETA: 3:59 - loss: 1.253 - ETA: 3:55 - loss: 1.254 - ETA: 3:51 - loss: 1.254 - ETA: 3:47 - loss: 1.255 - ETA: 3:42 - loss: 1.255 - ETA: 3:38 - loss: 1.256 - ETA: 3:34 - loss: 1.256 - ETA: 3:30 - loss: 1.257 - ETA: 3:26 - loss: 1.256 - ETA: 3:22 - loss: 1.257 - ETA: 3:18 - loss: 1.257 - ETA: 3:13 - loss: 1.257 - ETA: 3:09 - loss: 1.257 - ETA: 3:05 - loss: 1.257 - ETA: 3:01 - loss: 1.258 - ETA: 2:57 - loss: 1.257 - ETA: 2:53 - loss: 1.257 - ETA: 2:49 - loss: 1.257 - ETA: 2:45 - loss: 1.257 - ETA: 2:40 - loss: 1.257 - ETA: 2:36 - loss: 1.257 - ETA: 2:32 - loss: 1.257 - ETA: 2:28 - loss: 1.257 - ETA: 2:24 - loss: 1.257 - ETA: 2:20 - loss: 1.257 - ETA: 2:16 - loss: 1.257 - ETA: 2:12 - loss: 1.257 - ETA: 2:07 - loss: 1.257 - ETA: 2:03 - loss: 1.256 - ETA: 1:59 - loss: 1.256 - ETA: 1:55 - loss: 1.256 - ETA: 1:51 - loss: 1.255 - ETA: 1:47 - loss: 1.256 - ETA: 1:43 - loss: 1.255 - ETA: 1:39 - loss: 1.255 - ETA: 1:34 - loss: 1.255 - ETA: 1:30 - loss: 1.255 - ETA: 1:26 - loss: 1.255 - ETA: 1:22 - loss: 1.255 - ETA: 1:18 - loss: 1.255 - ETA: 1:14 - loss: 1.255 - ETA: 1:10 - loss: 1.255 - ETA: 1:05 - loss: 1.255 - ETA: 1:01 - loss: 1.255 - ETA: 57s - loss: 1.255 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2548 - ETA: 4s - loss: 1.2547WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2547\n",
      "Epoch 48/100\n",
      " 99/100 [============================>.] - ETA: 6:52 - loss: 1.233 - ETA: 6:47 - loss: 1.249 - ETA: 6:42 - loss: 1.251 - ETA: 6:37 - loss: 1.250 - ETA: 6:33 - loss: 1.250 - ETA: 6:28 - loss: 1.253 - ETA: 6:24 - loss: 1.260 - ETA: 6:20 - loss: 1.261 - ETA: 6:16 - loss: 1.264 - ETA: 6:12 - loss: 1.261 - ETA: 6:09 - loss: 1.259 - ETA: 6:06 - loss: 1.261 - ETA: 6:03 - loss: 1.259 - ETA: 5:58 - loss: 1.255 - ETA: 5:54 - loss: 1.256 - ETA: 5:50 - loss: 1.255 - ETA: 5:45 - loss: 1.252 - ETA: 5:41 - loss: 1.251 - ETA: 5:37 - loss: 1.253 - ETA: 5:32 - loss: 1.255 - ETA: 5:28 - loss: 1.254 - ETA: 5:24 - loss: 1.253 - ETA: 5:19 - loss: 1.252 - ETA: 5:15 - loss: 1.254 - ETA: 5:11 - loss: 1.255 - ETA: 5:07 - loss: 1.256 - ETA: 5:03 - loss: 1.258 - ETA: 4:58 - loss: 1.259 - ETA: 4:54 - loss: 1.259 - ETA: 4:50 - loss: 1.260 - ETA: 4:46 - loss: 1.260 - ETA: 4:42 - loss: 1.260 - ETA: 4:37 - loss: 1.260 - ETA: 4:33 - loss: 1.260 - ETA: 4:29 - loss: 1.261 - ETA: 4:25 - loss: 1.261 - ETA: 4:21 - loss: 1.261 - ETA: 4:16 - loss: 1.261 - ETA: 4:12 - loss: 1.262 - ETA: 4:08 - loss: 1.262 - ETA: 4:04 - loss: 1.262 - ETA: 4:00 - loss: 1.262 - ETA: 3:56 - loss: 1.263 - ETA: 3:51 - loss: 1.262 - ETA: 3:47 - loss: 1.262 - ETA: 3:43 - loss: 1.262 - ETA: 3:39 - loss: 1.263 - ETA: 3:35 - loss: 1.262 - ETA: 3:31 - loss: 1.262 - ETA: 3:26 - loss: 1.262 - ETA: 3:22 - loss: 1.261 - ETA: 3:18 - loss: 1.261 - ETA: 3:14 - loss: 1.261 - ETA: 3:10 - loss: 1.261 - ETA: 3:06 - loss: 1.261 - ETA: 3:02 - loss: 1.261 - ETA: 2:57 - loss: 1.261 - ETA: 2:53 - loss: 1.261 - ETA: 2:49 - loss: 1.261 - ETA: 2:45 - loss: 1.260 - ETA: 2:41 - loss: 1.259 - ETA: 2:37 - loss: 1.259 - ETA: 2:33 - loss: 1.259 - ETA: 2:28 - loss: 1.259 - ETA: 2:24 - loss: 1.259 - ETA: 2:20 - loss: 1.259 - ETA: 2:16 - loss: 1.259 - ETA: 2:12 - loss: 1.260 - ETA: 2:08 - loss: 1.259 - ETA: 2:04 - loss: 1.260 - ETA: 1:59 - loss: 1.260 - ETA: 1:55 - loss: 1.260 - ETA: 1:51 - loss: 1.260 - ETA: 1:47 - loss: 1.260 - ETA: 1:43 - loss: 1.259 - ETA: 1:39 - loss: 1.260 - ETA: 1:35 - loss: 1.259 - ETA: 1:31 - loss: 1.259 - ETA: 1:26 - loss: 1.258 - ETA: 1:22 - loss: 1.258 - ETA: 1:18 - loss: 1.258 - ETA: 1:14 - loss: 1.258 - ETA: 1:10 - loss: 1.257 - ETA: 1:06 - loss: 1.258 - ETA: 1:02 - loss: 1.257 - ETA: 57s - loss: 1.257 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2576 - ETA: 4s - loss: 1.2576WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2575\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.266 - ETA: 6:46 - loss: 1.242 - ETA: 6:41 - loss: 1.239 - ETA: 6:35 - loss: 1.249 - ETA: 6:32 - loss: 1.249 - ETA: 6:28 - loss: 1.261 - ETA: 6:24 - loss: 1.268 - ETA: 6:20 - loss: 1.264 - ETA: 6:15 - loss: 1.262 - ETA: 6:11 - loss: 1.267 - ETA: 6:07 - loss: 1.266 - ETA: 6:03 - loss: 1.269 - ETA: 5:59 - loss: 1.268 - ETA: 5:55 - loss: 1.270 - ETA: 5:51 - loss: 1.268 - ETA: 5:47 - loss: 1.268 - ETA: 5:43 - loss: 1.268 - ETA: 5:39 - loss: 1.269 - ETA: 5:35 - loss: 1.269 - ETA: 5:30 - loss: 1.267 - ETA: 5:26 - loss: 1.268 - ETA: 5:22 - loss: 1.269 - ETA: 5:18 - loss: 1.265 - ETA: 5:14 - loss: 1.263 - ETA: 5:10 - loss: 1.261 - ETA: 5:06 - loss: 1.261 - ETA: 5:02 - loss: 1.263 - ETA: 4:58 - loss: 1.263 - ETA: 4:54 - loss: 1.263 - ETA: 4:50 - loss: 1.263 - ETA: 4:45 - loss: 1.260 - ETA: 4:41 - loss: 1.260 - ETA: 4:37 - loss: 1.261 - ETA: 4:33 - loss: 1.261 - ETA: 4:29 - loss: 1.260 - ETA: 4:25 - loss: 1.260 - ETA: 4:21 - loss: 1.259 - ETA: 4:16 - loss: 1.260 - ETA: 4:12 - loss: 1.261 - ETA: 4:08 - loss: 1.261 - ETA: 4:04 - loss: 1.261 - ETA: 4:00 - loss: 1.261 - ETA: 3:56 - loss: 1.261 - ETA: 3:52 - loss: 1.260 - ETA: 3:47 - loss: 1.260 - ETA: 3:43 - loss: 1.259 - ETA: 3:39 - loss: 1.259 - ETA: 3:35 - loss: 1.259 - ETA: 3:31 - loss: 1.258 - ETA: 3:27 - loss: 1.258 - ETA: 3:22 - loss: 1.257 - ETA: 3:18 - loss: 1.256 - ETA: 3:14 - loss: 1.256 - ETA: 3:10 - loss: 1.257 - ETA: 3:06 - loss: 1.257 - ETA: 3:02 - loss: 1.256 - ETA: 2:57 - loss: 1.257 - ETA: 2:53 - loss: 1.257 - ETA: 2:49 - loss: 1.258 - ETA: 2:45 - loss: 1.257 - ETA: 2:41 - loss: 1.256 - ETA: 2:37 - loss: 1.257 - ETA: 2:33 - loss: 1.257 - ETA: 2:28 - loss: 1.257 - ETA: 2:24 - loss: 1.258 - ETA: 2:20 - loss: 1.257 - ETA: 2:16 - loss: 1.257 - ETA: 2:12 - loss: 1.257 - ETA: 2:08 - loss: 1.256 - ETA: 2:04 - loss: 1.257 - ETA: 1:59 - loss: 1.257 - ETA: 1:55 - loss: 1.257 - ETA: 1:51 - loss: 1.257 - ETA: 1:47 - loss: 1.256 - ETA: 1:43 - loss: 1.256 - ETA: 1:39 - loss: 1.255 - ETA: 1:35 - loss: 1.256 - ETA: 1:30 - loss: 1.257 - ETA: 1:26 - loss: 1.256 - ETA: 1:22 - loss: 1.256 - ETA: 1:18 - loss: 1.256 - ETA: 1:14 - loss: 1.256 - ETA: 1:10 - loss: 1.256 - ETA: 1:06 - loss: 1.257 - ETA: 1:02 - loss: 1.257 - ETA: 57s - loss: 1.258 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2571 - ETA: 4s - loss: 1.2570WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2574\n",
      "Epoch 50/100\n",
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.225 - ETA: 6:43 - loss: 1.237 - ETA: 6:39 - loss: 1.249 - ETA: 6:36 - loss: 1.253 - ETA: 6:34 - loss: 1.254 - ETA: 6:29 - loss: 1.252 - ETA: 6:25 - loss: 1.250 - ETA: 6:21 - loss: 1.249 - ETA: 6:17 - loss: 1.251 - ETA: 6:12 - loss: 1.254 - ETA: 6:08 - loss: 1.252 - ETA: 6:03 - loss: 1.253 - ETA: 5:59 - loss: 1.255 - ETA: 5:55 - loss: 1.254 - ETA: 5:51 - loss: 1.257 - ETA: 5:47 - loss: 1.257 - ETA: 5:42 - loss: 1.255 - ETA: 5:38 - loss: 1.255 - ETA: 5:34 - loss: 1.258 - ETA: 5:30 - loss: 1.259 - ETA: 5:26 - loss: 1.258 - ETA: 5:22 - loss: 1.259 - ETA: 5:18 - loss: 1.260 - ETA: 5:13 - loss: 1.261 - ETA: 5:09 - loss: 1.260 - ETA: 5:05 - loss: 1.261 - ETA: 5:01 - loss: 1.260 - ETA: 4:57 - loss: 1.258 - ETA: 4:53 - loss: 1.259 - ETA: 4:49 - loss: 1.258 - ETA: 4:45 - loss: 1.257 - ETA: 4:41 - loss: 1.257 - ETA: 4:37 - loss: 1.257 - ETA: 4:32 - loss: 1.256 - ETA: 4:28 - loss: 1.256 - ETA: 4:24 - loss: 1.256 - ETA: 4:20 - loss: 1.256 - ETA: 4:16 - loss: 1.256 - ETA: 4:12 - loss: 1.255 - ETA: 4:08 - loss: 1.256 - ETA: 4:03 - loss: 1.256 - ETA: 3:59 - loss: 1.255 - ETA: 3:55 - loss: 1.256 - ETA: 3:51 - loss: 1.256 - ETA: 3:47 - loss: 1.256 - ETA: 3:43 - loss: 1.256 - ETA: 3:39 - loss: 1.256 - ETA: 3:34 - loss: 1.256 - ETA: 3:30 - loss: 1.256 - ETA: 3:26 - loss: 1.256 - ETA: 3:22 - loss: 1.256 - ETA: 3:18 - loss: 1.256 - ETA: 3:14 - loss: 1.256 - ETA: 3:10 - loss: 1.256 - ETA: 3:05 - loss: 1.256 - ETA: 3:01 - loss: 1.256 - ETA: 2:57 - loss: 1.255 - ETA: 2:53 - loss: 1.255 - ETA: 2:49 - loss: 1.255 - ETA: 2:45 - loss: 1.255 - ETA: 2:41 - loss: 1.255 - ETA: 2:37 - loss: 1.255 - ETA: 2:32 - loss: 1.255 - ETA: 2:28 - loss: 1.254 - ETA: 2:24 - loss: 1.254 - ETA: 2:20 - loss: 1.255 - ETA: 2:16 - loss: 1.255 - ETA: 2:12 - loss: 1.255 - ETA: 2:08 - loss: 1.254 - ETA: 2:03 - loss: 1.254 - ETA: 1:59 - loss: 1.254 - ETA: 1:55 - loss: 1.254 - ETA: 1:51 - loss: 1.254 - ETA: 1:47 - loss: 1.255 - ETA: 1:43 - loss: 1.254 - ETA: 1:39 - loss: 1.254 - ETA: 1:34 - loss: 1.254 - ETA: 1:30 - loss: 1.254 - ETA: 1:26 - loss: 1.254 - ETA: 1:22 - loss: 1.253 - ETA: 1:18 - loss: 1.253 - ETA: 1:14 - loss: 1.253 - ETA: 1:10 - loss: 1.252 - ETA: 1:06 - loss: 1.253 - ETA: 1:01 - loss: 1.253 - ETA: 57s - loss: 1.253 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2529 - ETA: 4s - loss: 1.2523WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2528\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.279 - ETA: 6:44 - loss: 1.269 - ETA: 6:42 - loss: 1.244 - ETA: 6:40 - loss: 1.242 - ETA: 6:37 - loss: 1.250 - ETA: 6:35 - loss: 1.254 - ETA: 6:30 - loss: 1.255 - ETA: 6:25 - loss: 1.255 - ETA: 6:20 - loss: 1.257 - ETA: 6:15 - loss: 1.255 - ETA: 6:10 - loss: 1.257 - ETA: 6:06 - loss: 1.255 - ETA: 6:02 - loss: 1.251 - ETA: 5:57 - loss: 1.250 - ETA: 5:53 - loss: 1.250 - ETA: 5:49 - loss: 1.253 - ETA: 5:44 - loss: 1.251 - ETA: 5:40 - loss: 1.250 - ETA: 5:36 - loss: 1.251 - ETA: 5:32 - loss: 1.252 - ETA: 5:27 - loss: 1.252 - ETA: 5:23 - loss: 1.254 - ETA: 5:19 - loss: 1.255 - ETA: 5:15 - loss: 1.258 - ETA: 5:10 - loss: 1.257 - ETA: 5:06 - loss: 1.257 - ETA: 5:02 - loss: 1.257 - ETA: 4:58 - loss: 1.256 - ETA: 4:54 - loss: 1.256 - ETA: 4:49 - loss: 1.256 - ETA: 4:45 - loss: 1.256 - ETA: 4:41 - loss: 1.256 - ETA: 4:37 - loss: 1.256 - ETA: 4:33 - loss: 1.254 - ETA: 4:28 - loss: 1.253 - ETA: 4:24 - loss: 1.254 - ETA: 4:20 - loss: 1.255 - ETA: 4:16 - loss: 1.255 - ETA: 4:12 - loss: 1.255 - ETA: 4:08 - loss: 1.254 - ETA: 4:04 - loss: 1.252 - ETA: 3:59 - loss: 1.252 - ETA: 3:55 - loss: 1.253 - ETA: 3:51 - loss: 1.252 - ETA: 3:47 - loss: 1.251 - ETA: 3:43 - loss: 1.251 - ETA: 3:39 - loss: 1.251 - ETA: 3:34 - loss: 1.251 - ETA: 3:30 - loss: 1.252 - ETA: 3:26 - loss: 1.252 - ETA: 3:22 - loss: 1.251 - ETA: 3:18 - loss: 1.251 - ETA: 3:14 - loss: 1.250 - ETA: 3:10 - loss: 1.249 - ETA: 3:06 - loss: 1.250 - ETA: 3:01 - loss: 1.251 - ETA: 2:57 - loss: 1.252 - ETA: 2:53 - loss: 1.251 - ETA: 2:49 - loss: 1.252 - ETA: 2:45 - loss: 1.252 - ETA: 2:41 - loss: 1.252 - ETA: 2:37 - loss: 1.252 - ETA: 2:33 - loss: 1.253 - ETA: 2:28 - loss: 1.252 - ETA: 2:24 - loss: 1.251 - ETA: 2:20 - loss: 1.251 - ETA: 2:16 - loss: 1.252 - ETA: 2:12 - loss: 1.252 - ETA: 2:08 - loss: 1.252 - ETA: 2:04 - loss: 1.252 - ETA: 1:59 - loss: 1.252 - ETA: 1:55 - loss: 1.252 - ETA: 1:51 - loss: 1.252 - ETA: 1:47 - loss: 1.253 - ETA: 1:43 - loss: 1.253 - ETA: 1:39 - loss: 1.254 - ETA: 1:35 - loss: 1.253 - ETA: 1:30 - loss: 1.253 - ETA: 1:26 - loss: 1.253 - ETA: 1:22 - loss: 1.253 - ETA: 1:18 - loss: 1.253 - ETA: 1:14 - loss: 1.254 - ETA: 1:10 - loss: 1.254 - ETA: 1:06 - loss: 1.253 - ETA: 1:02 - loss: 1.253 - ETA: 57s - loss: 1.253 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2527 - ETA: 4s - loss: 1.2530WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2531\n",
      "Epoch 52/100\n",
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.238 - ETA: 6:44 - loss: 1.273 - ETA: 6:40 - loss: 1.269 - ETA: 6:37 - loss: 1.260 - ETA: 6:33 - loss: 1.258 - ETA: 6:29 - loss: 1.258 - ETA: 6:25 - loss: 1.256 - ETA: 6:21 - loss: 1.255 - ETA: 6:17 - loss: 1.252 - ETA: 6:12 - loss: 1.257 - ETA: 6:08 - loss: 1.260 - ETA: 6:04 - loss: 1.257 - ETA: 5:59 - loss: 1.262 - ETA: 5:55 - loss: 1.264 - ETA: 5:51 - loss: 1.265 - ETA: 5:47 - loss: 1.262 - ETA: 5:43 - loss: 1.260 - ETA: 5:38 - loss: 1.259 - ETA: 5:34 - loss: 1.259 - ETA: 5:30 - loss: 1.260 - ETA: 5:26 - loss: 1.260 - ETA: 5:22 - loss: 1.258 - ETA: 5:18 - loss: 1.257 - ETA: 5:14 - loss: 1.259 - ETA: 5:10 - loss: 1.259 - ETA: 5:05 - loss: 1.257 - ETA: 5:01 - loss: 1.256 - ETA: 4:57 - loss: 1.255 - ETA: 4:53 - loss: 1.255 - ETA: 4:49 - loss: 1.256 - ETA: 4:45 - loss: 1.255 - ETA: 4:40 - loss: 1.255 - ETA: 4:36 - loss: 1.255 - ETA: 4:32 - loss: 1.255 - ETA: 4:28 - loss: 1.256 - ETA: 4:24 - loss: 1.255 - ETA: 4:20 - loss: 1.255 - ETA: 4:16 - loss: 1.254 - ETA: 4:12 - loss: 1.254 - ETA: 4:07 - loss: 1.254 - ETA: 4:03 - loss: 1.253 - ETA: 3:59 - loss: 1.254 - ETA: 3:55 - loss: 1.255 - ETA: 3:51 - loss: 1.256 - ETA: 3:47 - loss: 1.255 - ETA: 3:43 - loss: 1.256 - ETA: 3:39 - loss: 1.255 - ETA: 3:35 - loss: 1.254 - ETA: 3:31 - loss: 1.253 - ETA: 3:26 - loss: 1.253 - ETA: 3:22 - loss: 1.253 - ETA: 3:18 - loss: 1.252 - ETA: 3:14 - loss: 1.252 - ETA: 3:10 - loss: 1.252 - ETA: 3:06 - loss: 1.252 - ETA: 3:02 - loss: 1.251 - ETA: 2:57 - loss: 1.251 - ETA: 2:53 - loss: 1.251 - ETA: 2:49 - loss: 1.250 - ETA: 2:45 - loss: 1.250 - ETA: 2:41 - loss: 1.250 - ETA: 2:37 - loss: 1.249 - ETA: 2:33 - loss: 1.249 - ETA: 2:28 - loss: 1.250 - ETA: 2:24 - loss: 1.250 - ETA: 2:20 - loss: 1.250 - ETA: 2:16 - loss: 1.250 - ETA: 2:12 - loss: 1.250 - ETA: 2:08 - loss: 1.250 - ETA: 2:04 - loss: 1.250 - ETA: 1:59 - loss: 1.250 - ETA: 1:55 - loss: 1.250 - ETA: 1:51 - loss: 1.250 - ETA: 1:47 - loss: 1.251 - ETA: 1:43 - loss: 1.251 - ETA: 1:39 - loss: 1.251 - ETA: 1:35 - loss: 1.251 - ETA: 1:30 - loss: 1.251 - ETA: 1:26 - loss: 1.251 - ETA: 1:22 - loss: 1.251 - ETA: 1:18 - loss: 1.251 - ETA: 1:14 - loss: 1.251 - ETA: 1:10 - loss: 1.251 - ETA: 1:06 - loss: 1.251 - ETA: 1:02 - loss: 1.251 - ETA: 57s - loss: 1.251 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2519 - ETA: 4s - loss: 1.2516WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2517\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:46 - loss: 1.250 - ETA: 6:42 - loss: 1.285 - ETA: 6:39 - loss: 1.267 - ETA: 6:35 - loss: 1.274 - ETA: 6:32 - loss: 1.263 - ETA: 6:27 - loss: 1.259 - ETA: 6:24 - loss: 1.254 - ETA: 6:19 - loss: 1.253 - ETA: 6:15 - loss: 1.250 - ETA: 6:11 - loss: 1.251 - ETA: 6:07 - loss: 1.249 - ETA: 6:03 - loss: 1.254 - ETA: 5:59 - loss: 1.249 - ETA: 5:54 - loss: 1.246 - ETA: 5:50 - loss: 1.247 - ETA: 5:46 - loss: 1.250 - ETA: 5:42 - loss: 1.252 - ETA: 5:38 - loss: 1.254 - ETA: 5:34 - loss: 1.256 - ETA: 5:30 - loss: 1.254 - ETA: 5:26 - loss: 1.253 - ETA: 5:21 - loss: 1.252 - ETA: 5:17 - loss: 1.251 - ETA: 5:13 - loss: 1.251 - ETA: 5:09 - loss: 1.250 - ETA: 5:05 - loss: 1.251 - ETA: 5:01 - loss: 1.251 - ETA: 4:57 - loss: 1.251 - ETA: 4:53 - loss: 1.249 - ETA: 4:48 - loss: 1.246 - ETA: 4:44 - loss: 1.246 - ETA: 4:40 - loss: 1.246 - ETA: 4:36 - loss: 1.245 - ETA: 4:32 - loss: 1.245 - ETA: 4:28 - loss: 1.245 - ETA: 4:24 - loss: 1.246 - ETA: 4:19 - loss: 1.246 - ETA: 4:15 - loss: 1.247 - ETA: 4:11 - loss: 1.247 - ETA: 4:07 - loss: 1.248 - ETA: 4:03 - loss: 1.249 - ETA: 3:59 - loss: 1.249 - ETA: 3:55 - loss: 1.249 - ETA: 3:51 - loss: 1.249 - ETA: 3:46 - loss: 1.249 - ETA: 3:42 - loss: 1.249 - ETA: 3:38 - loss: 1.249 - ETA: 3:34 - loss: 1.250 - ETA: 3:30 - loss: 1.250 - ETA: 3:26 - loss: 1.250 - ETA: 3:22 - loss: 1.250 - ETA: 3:18 - loss: 1.251 - ETA: 3:14 - loss: 1.251 - ETA: 3:09 - loss: 1.252 - ETA: 3:05 - loss: 1.252 - ETA: 3:01 - loss: 1.252 - ETA: 2:57 - loss: 1.252 - ETA: 2:53 - loss: 1.251 - ETA: 2:49 - loss: 1.251 - ETA: 2:45 - loss: 1.252 - ETA: 2:40 - loss: 1.251 - ETA: 2:36 - loss: 1.252 - ETA: 2:32 - loss: 1.252 - ETA: 2:28 - loss: 1.252 - ETA: 2:24 - loss: 1.253 - ETA: 2:20 - loss: 1.253 - ETA: 2:16 - loss: 1.254 - ETA: 2:12 - loss: 1.254 - ETA: 2:07 - loss: 1.254 - ETA: 2:03 - loss: 1.254 - ETA: 1:59 - loss: 1.254 - ETA: 1:55 - loss: 1.254 - ETA: 1:51 - loss: 1.254 - ETA: 1:47 - loss: 1.254 - ETA: 1:43 - loss: 1.255 - ETA: 1:39 - loss: 1.255 - ETA: 1:34 - loss: 1.255 - ETA: 1:30 - loss: 1.255 - ETA: 1:26 - loss: 1.255 - ETA: 1:22 - loss: 1.256 - ETA: 1:18 - loss: 1.256 - ETA: 1:14 - loss: 1.256 - ETA: 1:10 - loss: 1.256 - ETA: 1:06 - loss: 1.256 - ETA: 1:01 - loss: 1.256 - ETA: 57s - loss: 1.255 - ETA: 53s - loss: 1.25 - ETA: 49s - loss: 1.25 - ETA: 45s - loss: 1.25 - ETA: 41s - loss: 1.25 - ETA: 37s - loss: 1.25 - ETA: 33s - loss: 1.25 - ETA: 28s - loss: 1.25 - ETA: 24s - loss: 1.25 - ETA: 20s - loss: 1.25 - ETA: 16s - loss: 1.25 - ETA: 12s - loss: 1.25 - ETA: 8s - loss: 1.2548 - ETA: 4s - loss: 1.2550WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2548\n",
      "Epoch 54/100\n",
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.272 - ETA: 6:44 - loss: 1.279 - ETA: 6:39 - loss: 1.264 - ETA: 6:35 - loss: 1.259 - ETA: 6:31 - loss: 1.250 - ETA: 6:28 - loss: 1.242 - ETA: 6:24 - loss: 1.242 - ETA: 6:19 - loss: 1.238 - ETA: 6:15 - loss: 1.238 - ETA: 6:11 - loss: 1.239 - ETA: 6:08 - loss: 1.240 - ETA: 6:03 - loss: 1.240 - ETA: 5:59 - loss: 1.241 - ETA: 5:55 - loss: 1.241 - ETA: 5:51 - loss: 1.241 - ETA: 5:47 - loss: 1.241 - ETA: 5:42 - loss: 1.240 - ETA: 5:38 - loss: 1.240 - ETA: 5:34 - loss: 1.239 - ETA: 5:30 - loss: 1.241 - ETA: 5:26 - loss: 1.242 - ETA: 5:22 - loss: 1.243 - ETA: 5:17 - loss: 1.243 - ETA: 5:13 - loss: 1.244 - ETA: 5:09 - loss: 1.245 - ETA: 5:05 - loss: 1.244 - ETA: 5:01 - loss: 1.245 - ETA: 4:57 - loss: 1.245 - ETA: 4:52 - loss: 1.245 - ETA: 4:48 - loss: 1.244 - ETA: 4:44 - loss: 1.245 - ETA: 4:40 - loss: 1.245 - ETA: 4:36 - loss: 1.244 - ETA: 4:32 - loss: 1.244 - ETA: 4:28 - loss: 1.244 - ETA: 4:24 - loss: 1.244 - ETA: 4:19 - loss: 1.245 - ETA: 4:15 - loss: 1.246 - ETA: 4:11 - loss: 1.246 - ETA: 4:07 - loss: 1.245 - ETA: 4:03 - loss: 1.246 - ETA: 3:59 - loss: 1.246 - ETA: 3:55 - loss: 1.245 - ETA: 3:51 - loss: 1.245 - ETA: 3:47 - loss: 1.245 - ETA: 3:43 - loss: 1.245 - ETA: 3:38 - loss: 1.245 - ETA: 3:34 - loss: 1.246 - ETA: 3:30 - loss: 1.246 - ETA: 3:26 - loss: 1.245 - ETA: 3:22 - loss: 1.246 - ETA: 3:18 - loss: 1.245 - ETA: 3:14 - loss: 1.246 - ETA: 3:09 - loss: 1.247 - ETA: 3:05 - loss: 1.247 - ETA: 3:01 - loss: 1.248 - ETA: 2:57 - loss: 1.248 - ETA: 2:53 - loss: 1.247 - ETA: 2:49 - loss: 1.248 - ETA: 2:45 - loss: 1.248 - ETA: 2:41 - loss: 1.248 - ETA: 2:36 - loss: 1.248 - ETA: 2:32 - loss: 1.247 - ETA: 2:28 - loss: 1.248 - ETA: 2:24 - loss: 1.248 - ETA: 2:20 - loss: 1.247 - ETA: 2:16 - loss: 1.247 - ETA: 2:12 - loss: 1.247 - ETA: 2:08 - loss: 1.247 - ETA: 2:04 - loss: 1.247 - ETA: 1:59 - loss: 1.247 - ETA: 1:55 - loss: 1.247 - ETA: 1:51 - loss: 1.247 - ETA: 1:47 - loss: 1.247 - ETA: 1:43 - loss: 1.248 - ETA: 1:39 - loss: 1.248 - ETA: 1:35 - loss: 1.248 - ETA: 1:30 - loss: 1.248 - ETA: 1:26 - loss: 1.248 - ETA: 1:22 - loss: 1.248 - ETA: 1:18 - loss: 1.247 - ETA: 1:14 - loss: 1.248 - ETA: 1:10 - loss: 1.247 - ETA: 1:06 - loss: 1.247 - ETA: 1:01 - loss: 1.247 - ETA: 57s - loss: 1.247 - ETA: 53s - loss: 1.24 - ETA: 49s - loss: 1.24 - ETA: 45s - loss: 1.24 - ETA: 41s - loss: 1.24 - ETA: 37s - loss: 1.24 - ETA: 33s - loss: 1.24 - ETA: 28s - loss: 1.24 - ETA: 24s - loss: 1.24 - ETA: 20s - loss: 1.24 - ETA: 16s - loss: 1.24 - ETA: 12s - loss: 1.24 - ETA: 8s - loss: 1.2472 - ETA: 4s - loss: 1.2471WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2472\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:49 - loss: 1.250 - ETA: 6:45 - loss: 1.268 - ETA: 6:40 - loss: 1.257 - ETA: 6:36 - loss: 1.266 - ETA: 6:32 - loss: 1.254 - ETA: 6:27 - loss: 1.255 - ETA: 6:23 - loss: 1.256 - ETA: 6:19 - loss: 1.252 - ETA: 6:15 - loss: 1.249 - ETA: 6:11 - loss: 1.249 - ETA: 6:07 - loss: 1.248 - ETA: 6:03 - loss: 1.249 - ETA: 5:59 - loss: 1.247 - ETA: 5:55 - loss: 1.246 - ETA: 5:51 - loss: 1.247 - ETA: 5:47 - loss: 1.246 - ETA: 5:43 - loss: 1.247 - ETA: 5:38 - loss: 1.248 - ETA: 5:34 - loss: 1.248 - ETA: 5:30 - loss: 1.249 - ETA: 5:26 - loss: 1.249 - ETA: 5:22 - loss: 1.247 - ETA: 5:18 - loss: 1.247 - ETA: 5:14 - loss: 1.245 - ETA: 5:09 - loss: 1.246 - ETA: 5:05 - loss: 1.247 - ETA: 5:01 - loss: 1.247 - ETA: 4:57 - loss: 1.246 - ETA: 4:53 - loss: 1.246 - ETA: 4:49 - loss: 1.246 - ETA: 4:45 - loss: 1.247 - ETA: 4:41 - loss: 1.248 - ETA: 4:36 - loss: 1.248 - ETA: 4:32 - loss: 1.248 - ETA: 4:28 - loss: 1.248 - ETA: 4:24 - loss: 1.248 - ETA: 4:20 - loss: 1.248 - ETA: 4:16 - loss: 1.248 - ETA: 4:12 - loss: 1.247 - ETA: 4:08 - loss: 1.247 - ETA: 4:03 - loss: 1.246 - ETA: 3:59 - loss: 1.246 - ETA: 3:55 - loss: 1.247 - ETA: 3:51 - loss: 1.247 - ETA: 3:47 - loss: 1.247 - ETA: 3:43 - loss: 1.247 - ETA: 3:39 - loss: 1.247 - ETA: 3:34 - loss: 1.247 - ETA: 3:30 - loss: 1.247 - ETA: 3:26 - loss: 1.246 - ETA: 3:22 - loss: 1.247 - ETA: 3:18 - loss: 1.246 - ETA: 3:14 - loss: 1.246 - ETA: 3:10 - loss: 1.246 - ETA: 3:05 - loss: 1.246 - ETA: 3:01 - loss: 1.245 - ETA: 2:57 - loss: 1.245 - ETA: 2:53 - loss: 1.245 - ETA: 2:49 - loss: 1.244 - ETA: 2:45 - loss: 1.244 - ETA: 2:41 - loss: 1.244 - ETA: 2:37 - loss: 1.244 - ETA: 2:32 - loss: 1.244 - ETA: 2:28 - loss: 1.243 - ETA: 2:24 - loss: 1.243 - ETA: 2:20 - loss: 1.243 - ETA: 2:16 - loss: 1.243 - ETA: 2:12 - loss: 1.243 - ETA: 2:08 - loss: 1.243 - ETA: 2:03 - loss: 1.244 - ETA: 1:59 - loss: 1.243 - ETA: 1:55 - loss: 1.243 - ETA: 1:51 - loss: 1.243 - ETA: 1:47 - loss: 1.243 - ETA: 1:43 - loss: 1.243 - ETA: 1:39 - loss: 1.244 - ETA: 1:34 - loss: 1.244 - ETA: 1:30 - loss: 1.244 - ETA: 1:26 - loss: 1.244 - ETA: 1:22 - loss: 1.244 - ETA: 1:18 - loss: 1.244 - ETA: 1:14 - loss: 1.244 - ETA: 1:10 - loss: 1.244 - ETA: 1:06 - loss: 1.245 - ETA: 1:01 - loss: 1.245 - ETA: 57s - loss: 1.245 - ETA: 53s - loss: 1.24 - ETA: 49s - loss: 1.24 - ETA: 45s - loss: 1.24 - ETA: 41s - loss: 1.24 - ETA: 37s - loss: 1.24 - ETA: 33s - loss: 1.24 - ETA: 28s - loss: 1.24 - ETA: 24s - loss: 1.24 - ETA: 20s - loss: 1.24 - ETA: 16s - loss: 1.24 - ETA: 12s - loss: 1.24 - ETA: 8s - loss: 1.2442 - ETA: 4s - loss: 1.2443WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2442\n",
      "Epoch 56/100\n",
      " 99/100 [============================>.] - ETA: 6:44 - loss: 1.264 - ETA: 6:41 - loss: 1.244 - ETA: 6:38 - loss: 1.243 - ETA: 6:34 - loss: 1.251 - ETA: 6:30 - loss: 1.244 - ETA: 6:26 - loss: 1.241 - ETA: 6:22 - loss: 1.244 - ETA: 6:18 - loss: 1.239 - ETA: 6:14 - loss: 1.242 - ETA: 6:10 - loss: 1.243 - ETA: 6:06 - loss: 1.243 - ETA: 6:02 - loss: 1.242 - ETA: 5:58 - loss: 1.241 - ETA: 5:54 - loss: 1.239 - ETA: 5:50 - loss: 1.240 - ETA: 5:46 - loss: 1.237 - ETA: 5:42 - loss: 1.238 - ETA: 5:38 - loss: 1.239 - ETA: 5:34 - loss: 1.240 - ETA: 5:29 - loss: 1.237 - ETA: 5:25 - loss: 1.237 - ETA: 5:21 - loss: 1.238 - ETA: 5:17 - loss: 1.238 - ETA: 5:13 - loss: 1.240 - ETA: 5:09 - loss: 1.241 - ETA: 5:05 - loss: 1.241 - ETA: 5:00 - loss: 1.242 - ETA: 4:56 - loss: 1.242 - ETA: 4:52 - loss: 1.241 - ETA: 4:48 - loss: 1.243 - ETA: 4:44 - loss: 1.242 - ETA: 4:40 - loss: 1.242 - ETA: 4:36 - loss: 1.242 - ETA: 4:32 - loss: 1.242 - ETA: 4:27 - loss: 1.241 - ETA: 4:23 - loss: 1.240 - ETA: 4:19 - loss: 1.242 - ETA: 4:15 - loss: 1.241 - ETA: 4:11 - loss: 1.242 - ETA: 4:07 - loss: 1.243 - ETA: 4:03 - loss: 1.244 - ETA: 3:59 - loss: 1.243 - ETA: 3:55 - loss: 1.243 - ETA: 3:50 - loss: 1.242 - ETA: 3:46 - loss: 1.242 - ETA: 3:42 - loss: 1.242 - ETA: 3:38 - loss: 1.242 - ETA: 3:34 - loss: 1.242 - ETA: 3:30 - loss: 1.242 - ETA: 3:26 - loss: 1.243 - ETA: 3:22 - loss: 1.243 - ETA: 3:18 - loss: 1.243 - ETA: 3:13 - loss: 1.243 - ETA: 3:09 - loss: 1.242 - ETA: 3:05 - loss: 1.242 - ETA: 3:01 - loss: 1.242 - ETA: 2:57 - loss: 1.241 - ETA: 2:53 - loss: 1.241 - ETA: 2:49 - loss: 1.241 - ETA: 2:44 - loss: 1.241 - ETA: 2:40 - loss: 1.241 - ETA: 2:36 - loss: 1.241 - ETA: 2:32 - loss: 1.240 - ETA: 2:28 - loss: 1.240 - ETA: 2:24 - loss: 1.240 - ETA: 2:20 - loss: 1.240 - ETA: 2:16 - loss: 1.240 - ETA: 2:12 - loss: 1.239 - ETA: 2:07 - loss: 1.239 - ETA: 2:03 - loss: 1.239 - ETA: 1:59 - loss: 1.238 - ETA: 1:55 - loss: 1.239 - ETA: 1:51 - loss: 1.239 - ETA: 1:47 - loss: 1.238 - ETA: 1:43 - loss: 1.238 - ETA: 1:39 - loss: 1.239 - ETA: 1:34 - loss: 1.239 - ETA: 1:30 - loss: 1.239 - ETA: 1:26 - loss: 1.239 - ETA: 1:22 - loss: 1.240 - ETA: 1:18 - loss: 1.240 - ETA: 1:14 - loss: 1.239 - ETA: 1:10 - loss: 1.240 - ETA: 1:06 - loss: 1.239 - ETA: 1:02 - loss: 1.239 - ETA: 57s - loss: 1.240 - ETA: 53s - loss: 1.23 - ETA: 49s - loss: 1.23 - ETA: 45s - loss: 1.24 - ETA: 41s - loss: 1.24 - ETA: 37s - loss: 1.24 - ETA: 33s - loss: 1.24 - ETA: 28s - loss: 1.24 - ETA: 24s - loss: 1.24 - ETA: 20s - loss: 1.24 - ETA: 16s - loss: 1.24 - ETA: 12s - loss: 1.24 - ETA: 8s - loss: 1.2408 - ETA: 4s - loss: 1.2407WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2408\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:53 - loss: 1.263 - ETA: 6:48 - loss: 1.260 - ETA: 6:42 - loss: 1.259 - ETA: 6:37 - loss: 1.243 - ETA: 6:33 - loss: 1.246 - ETA: 6:29 - loss: 1.246 - ETA: 6:24 - loss: 1.244 - ETA: 6:20 - loss: 1.249 - ETA: 6:16 - loss: 1.244 - ETA: 6:12 - loss: 1.240 - ETA: 6:08 - loss: 1.247 - ETA: 6:03 - loss: 1.245 - ETA: 5:59 - loss: 1.245 - ETA: 5:55 - loss: 1.243 - ETA: 5:51 - loss: 1.239 - ETA: 5:47 - loss: 1.237 - ETA: 5:42 - loss: 1.239 - ETA: 5:38 - loss: 1.238 - ETA: 5:34 - loss: 1.234 - ETA: 5:30 - loss: 1.233 - ETA: 5:26 - loss: 1.231 - ETA: 5:22 - loss: 1.231 - ETA: 5:18 - loss: 1.232 - ETA: 5:13 - loss: 1.233 - ETA: 5:09 - loss: 1.232 - ETA: 5:05 - loss: 1.232 - ETA: 5:01 - loss: 1.232 - ETA: 4:57 - loss: 1.231 - ETA: 4:53 - loss: 1.232 - ETA: 4:49 - loss: 1.234 - ETA: 4:45 - loss: 1.235 - ETA: 4:41 - loss: 1.235 - ETA: 4:36 - loss: 1.235 - ETA: 4:32 - loss: 1.236 - ETA: 4:28 - loss: 1.236 - ETA: 4:24 - loss: 1.236 - ETA: 4:20 - loss: 1.237 - ETA: 4:16 - loss: 1.237 - ETA: 4:12 - loss: 1.237 - ETA: 4:08 - loss: 1.236 - ETA: 4:03 - loss: 1.237 - ETA: 3:59 - loss: 1.236 - ETA: 3:55 - loss: 1.236 - ETA: 3:51 - loss: 1.236 - ETA: 3:47 - loss: 1.235 - ETA: 3:43 - loss: 1.235 - ETA: 3:39 - loss: 1.235 - ETA: 3:34 - loss: 1.235 - ETA: 3:30 - loss: 1.235 - ETA: 3:26 - loss: 1.236 - ETA: 3:22 - loss: 1.236 - ETA: 3:18 - loss: 1.236 - ETA: 3:14 - loss: 1.236 - ETA: 3:10 - loss: 1.236 - ETA: 3:06 - loss: 1.235 - ETA: 3:01 - loss: 1.235 - ETA: 2:57 - loss: 1.235 - ETA: 2:53 - loss: 1.235 - ETA: 2:49 - loss: 1.235 - ETA: 2:45 - loss: 1.235 - ETA: 2:41 - loss: 1.235 - ETA: 2:37 - loss: 1.235 - ETA: 2:32 - loss: 1.235 - ETA: 2:28 - loss: 1.235 - ETA: 2:24 - loss: 1.234 - ETA: 2:20 - loss: 1.235 - ETA: 2:16 - loss: 1.234 - ETA: 2:12 - loss: 1.235 - ETA: 2:08 - loss: 1.234 - ETA: 2:04 - loss: 1.235 - ETA: 1:59 - loss: 1.234 - ETA: 1:55 - loss: 1.235 - ETA: 1:51 - loss: 1.235 - ETA: 1:47 - loss: 1.234 - ETA: 1:43 - loss: 1.234 - ETA: 1:39 - loss: 1.234 - ETA: 1:35 - loss: 1.233 - ETA: 1:30 - loss: 1.233 - ETA: 1:26 - loss: 1.233 - ETA: 1:22 - loss: 1.233 - ETA: 1:18 - loss: 1.233 - ETA: 1:14 - loss: 1.233 - ETA: 1:10 - loss: 1.233 - ETA: 1:06 - loss: 1.232 - ETA: 1:02 - loss: 1.232 - ETA: 57s - loss: 1.232 - ETA: 53s - loss: 1.23 - ETA: 49s - loss: 1.23 - ETA: 45s - loss: 1.23 - ETA: 41s - loss: 1.23 - ETA: 37s - loss: 1.23 - ETA: 33s - loss: 1.23 - ETA: 28s - loss: 1.23 - ETA: 24s - loss: 1.23 - ETA: 20s - loss: 1.23 - ETA: 16s - loss: 1.23 - ETA: 12s - loss: 1.23 - ETA: 8s - loss: 1.2339 - ETA: 4s - loss: 1.2335WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2339\n",
      "Epoch 58/100\n",
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.228 - ETA: 6:43 - loss: 1.229 - ETA: 6:40 - loss: 1.218 - ETA: 6:38 - loss: 1.222 - ETA: 6:33 - loss: 1.226 - ETA: 6:29 - loss: 1.224 - ETA: 6:24 - loss: 1.223 - ETA: 6:20 - loss: 1.224 - ETA: 6:16 - loss: 1.231 - ETA: 6:12 - loss: 1.231 - ETA: 6:08 - loss: 1.231 - ETA: 6:04 - loss: 1.234 - ETA: 6:00 - loss: 1.235 - ETA: 5:55 - loss: 1.235 - ETA: 5:51 - loss: 1.235 - ETA: 5:47 - loss: 1.234 - ETA: 5:43 - loss: 1.233 - ETA: 5:39 - loss: 1.232 - ETA: 5:35 - loss: 1.232 - ETA: 5:31 - loss: 1.232 - ETA: 5:27 - loss: 1.233 - ETA: 5:22 - loss: 1.235 - ETA: 5:18 - loss: 1.235 - ETA: 5:14 - loss: 1.234 - ETA: 5:10 - loss: 1.234 - ETA: 5:06 - loss: 1.234 - ETA: 5:02 - loss: 1.235 - ETA: 4:58 - loss: 1.234 - ETA: 4:54 - loss: 1.234 - ETA: 4:50 - loss: 1.235 - ETA: 4:45 - loss: 1.235 - ETA: 4:41 - loss: 1.235 - ETA: 4:37 - loss: 1.234 - ETA: 4:33 - loss: 1.234 - ETA: 4:29 - loss: 1.233 - ETA: 4:25 - loss: 1.234 - ETA: 4:20 - loss: 1.235 - ETA: 4:16 - loss: 1.235 - ETA: 4:12 - loss: 1.236 - ETA: 4:08 - loss: 1.236 - ETA: 4:04 - loss: 1.236 - ETA: 4:00 - loss: 1.237 - ETA: 3:56 - loss: 1.237 - ETA: 3:51 - loss: 1.238 - ETA: 3:47 - loss: 1.237 - ETA: 3:43 - loss: 1.236 - ETA: 3:39 - loss: 1.236 - ETA: 3:35 - loss: 1.236 - ETA: 3:31 - loss: 1.235 - ETA: 3:27 - loss: 1.236 - ETA: 3:22 - loss: 1.236 - ETA: 3:18 - loss: 1.237 - ETA: 3:14 - loss: 1.237 - ETA: 3:10 - loss: 1.236 - ETA: 3:06 - loss: 1.236 - ETA: 3:02 - loss: 1.237 - ETA: 2:58 - loss: 1.237 - ETA: 2:53 - loss: 1.237 - ETA: 2:49 - loss: 1.237 - ETA: 2:45 - loss: 1.237 - ETA: 2:41 - loss: 1.238 - ETA: 2:37 - loss: 1.238 - ETA: 2:33 - loss: 1.237 - ETA: 2:28 - loss: 1.236 - ETA: 2:24 - loss: 1.237 - ETA: 2:20 - loss: 1.237 - ETA: 2:16 - loss: 1.238 - ETA: 2:12 - loss: 1.237 - ETA: 2:08 - loss: 1.238 - ETA: 2:04 - loss: 1.237 - ETA: 1:59 - loss: 1.237 - ETA: 1:55 - loss: 1.236 - ETA: 1:51 - loss: 1.235 - ETA: 1:47 - loss: 1.235 - ETA: 1:43 - loss: 1.235 - ETA: 1:39 - loss: 1.236 - ETA: 1:35 - loss: 1.236 - ETA: 1:31 - loss: 1.236 - ETA: 1:26 - loss: 1.236 - ETA: 1:22 - loss: 1.235 - ETA: 1:18 - loss: 1.235 - ETA: 1:14 - loss: 1.235 - ETA: 1:10 - loss: 1.235 - ETA: 1:06 - loss: 1.235 - ETA: 1:02 - loss: 1.235 - ETA: 57s - loss: 1.234 - ETA: 53s - loss: 1.23 - ETA: 49s - loss: 1.23 - ETA: 45s - loss: 1.23 - ETA: 41s - loss: 1.23 - ETA: 37s - loss: 1.23 - ETA: 33s - loss: 1.23 - ETA: 28s - loss: 1.23 - ETA: 24s - loss: 1.23 - ETA: 20s - loss: 1.23 - ETA: 16s - loss: 1.23 - ETA: 12s - loss: 1.23 - ETA: 8s - loss: 1.2343 - ETA: 4s - loss: 1.2344WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2346\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:46 - loss: 1.212 - ETA: 6:43 - loss: 1.233 - ETA: 6:39 - loss: 1.230 - ETA: 6:36 - loss: 1.217 - ETA: 6:32 - loss: 1.220 - ETA: 6:28 - loss: 1.214 - ETA: 6:24 - loss: 1.217 - ETA: 6:20 - loss: 1.219 - ETA: 6:16 - loss: 1.219 - ETA: 6:12 - loss: 1.221 - ETA: 6:07 - loss: 1.217 - ETA: 6:03 - loss: 1.215 - ETA: 5:59 - loss: 1.216 - ETA: 5:55 - loss: 1.215 - ETA: 5:51 - loss: 1.214 - ETA: 5:47 - loss: 1.219 - ETA: 5:42 - loss: 1.223 - ETA: 5:38 - loss: 1.223 - ETA: 5:34 - loss: 1.223 - ETA: 5:30 - loss: 1.222 - ETA: 5:26 - loss: 1.222 - ETA: 5:22 - loss: 1.222 - ETA: 5:17 - loss: 1.223 - ETA: 5:13 - loss: 1.223 - ETA: 5:09 - loss: 1.223 - ETA: 5:05 - loss: 1.222 - ETA: 5:01 - loss: 1.222 - ETA: 4:57 - loss: 1.224 - ETA: 4:52 - loss: 1.224 - ETA: 4:48 - loss: 1.225 - ETA: 4:44 - loss: 1.225 - ETA: 4:40 - loss: 1.225 - ETA: 4:36 - loss: 1.225 - ETA: 4:32 - loss: 1.226 - ETA: 4:28 - loss: 1.226 - ETA: 4:24 - loss: 1.225 - ETA: 4:20 - loss: 1.226 - ETA: 4:15 - loss: 1.227 - ETA: 4:11 - loss: 1.226 - ETA: 4:07 - loss: 1.226 - ETA: 4:03 - loss: 1.226 - ETA: 3:59 - loss: 1.227 - ETA: 3:55 - loss: 1.226 - ETA: 3:51 - loss: 1.227 - ETA: 3:47 - loss: 1.228 - ETA: 3:42 - loss: 1.229 - ETA: 3:38 - loss: 1.230 - ETA: 3:34 - loss: 1.229 - ETA: 3:30 - loss: 1.230 - ETA: 3:26 - loss: 1.230 - ETA: 3:22 - loss: 1.230 - ETA: 3:18 - loss: 1.231 - ETA: 3:14 - loss: 1.231 - ETA: 3:09 - loss: 1.232 - ETA: 3:05 - loss: 1.232 - ETA: 3:01 - loss: 1.233 - ETA: 2:57 - loss: 1.234 - ETA: 2:53 - loss: 1.233 - ETA: 2:49 - loss: 1.233 - ETA: 2:45 - loss: 1.233 - ETA: 2:41 - loss: 1.233 - ETA: 2:36 - loss: 1.233 - ETA: 2:32 - loss: 1.234 - ETA: 2:28 - loss: 1.234 - ETA: 2:24 - loss: 1.235 - ETA: 2:20 - loss: 1.235 - ETA: 2:16 - loss: 1.235 - ETA: 2:12 - loss: 1.236 - ETA: 2:08 - loss: 1.235 - ETA: 2:03 - loss: 1.235 - ETA: 1:59 - loss: 1.236 - ETA: 1:55 - loss: 1.236 - ETA: 1:51 - loss: 1.237 - ETA: 1:47 - loss: 1.237 - ETA: 1:43 - loss: 1.238 - ETA: 1:39 - loss: 1.238 - ETA: 1:35 - loss: 1.237 - ETA: 1:30 - loss: 1.238 - ETA: 1:26 - loss: 1.238 - ETA: 1:22 - loss: 1.238 - ETA: 1:18 - loss: 1.238 - ETA: 1:14 - loss: 1.238 - ETA: 1:10 - loss: 1.238 - ETA: 1:06 - loss: 1.238 - ETA: 1:01 - loss: 1.237 - ETA: 57s - loss: 1.238 - ETA: 53s - loss: 1.23 - ETA: 49s - loss: 1.23 - ETA: 45s - loss: 1.23 - ETA: 41s - loss: 1.23 - ETA: 37s - loss: 1.23 - ETA: 33s - loss: 1.23 - ETA: 28s - loss: 1.23 - ETA: 24s - loss: 1.23 - ETA: 20s - loss: 1.23 - ETA: 16s - loss: 1.23 - ETA: 12s - loss: 1.23 - ETA: 8s - loss: 1.2393 - ETA: 4s - loss: 1.2396WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2396\n",
      "Epoch 60/100\n",
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.226 - ETA: 6:43 - loss: 1.243 - ETA: 6:39 - loss: 1.251 - ETA: 6:35 - loss: 1.243 - ETA: 6:31 - loss: 1.243 - ETA: 6:27 - loss: 1.244 - ETA: 6:23 - loss: 1.245 - ETA: 6:19 - loss: 1.251 - ETA: 6:15 - loss: 1.248 - ETA: 6:11 - loss: 1.245 - ETA: 6:07 - loss: 1.244 - ETA: 6:03 - loss: 1.244 - ETA: 5:58 - loss: 1.245 - ETA: 5:54 - loss: 1.245 - ETA: 5:50 - loss: 1.244 - ETA: 5:46 - loss: 1.243 - ETA: 5:42 - loss: 1.245 - ETA: 5:38 - loss: 1.248 - ETA: 5:34 - loss: 1.250 - ETA: 5:30 - loss: 1.250 - ETA: 5:26 - loss: 1.250 - ETA: 5:22 - loss: 1.249 - ETA: 5:18 - loss: 1.248 - ETA: 5:14 - loss: 1.248 - ETA: 5:09 - loss: 1.247 - ETA: 5:05 - loss: 1.247 - ETA: 5:01 - loss: 1.246 - ETA: 4:57 - loss: 1.247 - ETA: 4:53 - loss: 1.247 - ETA: 4:49 - loss: 1.247 - ETA: 4:45 - loss: 1.247 - ETA: 4:41 - loss: 1.245 - ETA: 4:36 - loss: 1.246 - ETA: 4:32 - loss: 1.246 - ETA: 4:28 - loss: 1.246 - ETA: 4:24 - loss: 1.247 - ETA: 4:20 - loss: 1.245 - ETA: 4:16 - loss: 1.246 - ETA: 4:12 - loss: 1.246 - ETA: 4:07 - loss: 1.246 - ETA: 4:03 - loss: 1.247 - ETA: 3:59 - loss: 1.247 - ETA: 3:55 - loss: 1.247 - ETA: 3:51 - loss: 1.246 - ETA: 3:47 - loss: 1.247 - ETA: 3:43 - loss: 1.247 - ETA: 3:39 - loss: 1.248 - ETA: 3:34 - loss: 1.248 - ETA: 3:30 - loss: 1.249 - ETA: 3:26 - loss: 1.249 - ETA: 3:22 - loss: 1.248 - ETA: 3:18 - loss: 1.247 - ETA: 3:14 - loss: 1.248 - ETA: 3:10 - loss: 1.248 - ETA: 3:06 - loss: 1.248 - ETA: 3:02 - loss: 1.248 - ETA: 2:57 - loss: 1.248 - ETA: 2:53 - loss: 1.248 - ETA: 2:49 - loss: 1.247 - ETA: 2:45 - loss: 1.247 - ETA: 2:41 - loss: 1.247 - ETA: 2:37 - loss: 1.247 - ETA: 2:33 - loss: 1.247 - ETA: 2:28 - loss: 1.247 - ETA: 2:24 - loss: 1.247 - ETA: 2:20 - loss: 1.247 - ETA: 2:16 - loss: 1.246 - ETA: 2:12 - loss: 1.246 - ETA: 2:08 - loss: 1.246 - ETA: 2:04 - loss: 1.245 - ETA: 1:59 - loss: 1.245 - ETA: 1:55 - loss: 1.245 - ETA: 1:51 - loss: 1.245 - ETA: 1:47 - loss: 1.246 - ETA: 1:43 - loss: 1.245 - ETA: 1:39 - loss: 1.245 - ETA: 1:35 - loss: 1.245 - ETA: 1:30 - loss: 1.245 - ETA: 1:26 - loss: 1.246 - ETA: 1:22 - loss: 1.246 - ETA: 1:18 - loss: 1.246 - ETA: 1:14 - loss: 1.246 - ETA: 1:10 - loss: 1.246 - ETA: 1:06 - loss: 1.246 - ETA: 1:02 - loss: 1.246 - ETA: 57s - loss: 1.246 - ETA: 53s - loss: 1.24 - ETA: 49s - loss: 1.24 - ETA: 45s - loss: 1.24 - ETA: 41s - loss: 1.24 - ETA: 37s - loss: 1.24 - ETA: 33s - loss: 1.24 - ETA: 28s - loss: 1.24 - ETA: 24s - loss: 1.24 - ETA: 20s - loss: 1.24 - ETA: 16s - loss: 1.24 - ETA: 12s - loss: 1.24 - ETA: 8s - loss: 1.2458 - ETA: 4s - loss: 1.2457WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2458\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:50 - loss: 1.223 - ETA: 6:45 - loss: 1.228 - ETA: 6:40 - loss: 1.238 - ETA: 6:36 - loss: 1.232 - ETA: 6:33 - loss: 1.235 - ETA: 6:28 - loss: 1.229 - ETA: 6:25 - loss: 1.228 - ETA: 6:21 - loss: 1.226 - ETA: 6:17 - loss: 1.229 - ETA: 6:12 - loss: 1.232 - ETA: 6:08 - loss: 1.234 - ETA: 6:04 - loss: 1.235 - ETA: 6:00 - loss: 1.235 - ETA: 5:56 - loss: 1.237 - ETA: 5:51 - loss: 1.238 - ETA: 5:48 - loss: 1.237 - ETA: 5:45 - loss: 1.236 - ETA: 5:41 - loss: 1.237 - ETA: 5:37 - loss: 1.236 - ETA: 5:33 - loss: 1.237 - ETA: 5:28 - loss: 1.236 - ETA: 5:24 - loss: 1.237 - ETA: 5:20 - loss: 1.237 - ETA: 5:16 - loss: 1.237 - ETA: 5:11 - loss: 1.239 - ETA: 5:07 - loss: 1.239 - ETA: 5:03 - loss: 1.240 - ETA: 4:59 - loss: 1.239 - ETA: 4:54 - loss: 1.239 - ETA: 4:50 - loss: 1.239 - ETA: 4:46 - loss: 1.238 - ETA: 4:42 - loss: 1.239 - ETA: 4:38 - loss: 1.238 - ETA: 4:33 - loss: 1.238 - ETA: 4:29 - loss: 1.238 - ETA: 4:25 - loss: 1.239 - ETA: 4:21 - loss: 1.239 - ETA: 4:17 - loss: 1.239 - ETA: 4:13 - loss: 1.238 - ETA: 4:08 - loss: 1.238 - ETA: 4:04 - loss: 1.239 - ETA: 4:00 - loss: 1.239 - ETA: 3:56 - loss: 1.239 - ETA: 3:52 - loss: 1.238 - ETA: 3:48 - loss: 1.238 - ETA: 3:43 - loss: 1.237 - ETA: 3:39 - loss: 1.238 - ETA: 3:35 - loss: 1.238 - ETA: 3:31 - loss: 1.238 - ETA: 3:27 - loss: 1.238 - ETA: 3:23 - loss: 1.237 - ETA: 3:18 - loss: 1.236 - ETA: 3:14 - loss: 1.235 - ETA: 3:10 - loss: 1.235 - ETA: 3:06 - loss: 1.235 - ETA: 3:02 - loss: 1.234 - ETA: 2:58 - loss: 1.233 - ETA: 2:53 - loss: 1.234 - ETA: 2:49 - loss: 1.234 - ETA: 2:45 - loss: 1.235 - ETA: 2:41 - loss: 1.236 - ETA: 2:37 - loss: 1.235 - ETA: 2:33 - loss: 1.236 - ETA: 2:29 - loss: 1.237 - ETA: 2:24 - loss: 1.237 - ETA: 2:20 - loss: 1.238 - ETA: 2:16 - loss: 1.238 - ETA: 2:12 - loss: 1.238 - ETA: 2:08 - loss: 1.238 - ETA: 2:04 - loss: 1.238 - ETA: 2:00 - loss: 1.238 - ETA: 1:55 - loss: 1.237 - ETA: 1:51 - loss: 1.237 - ETA: 1:47 - loss: 1.237 - ETA: 1:43 - loss: 1.238 - ETA: 1:39 - loss: 1.239 - ETA: 1:35 - loss: 1.239 - ETA: 1:31 - loss: 1.239 - ETA: 1:26 - loss: 1.239 - ETA: 1:22 - loss: 1.239 - ETA: 1:18 - loss: 1.239 - ETA: 1:14 - loss: 1.239 - ETA: 1:10 - loss: 1.239 - ETA: 1:06 - loss: 1.239 - ETA: 1:02 - loss: 1.239 - ETA: 57s - loss: 1.239 - ETA: 53s - loss: 1.24 - ETA: 49s - loss: 1.24 - ETA: 45s - loss: 1.24 - ETA: 41s - loss: 1.24 - ETA: 37s - loss: 1.24 - ETA: 33s - loss: 1.24 - ETA: 28s - loss: 1.24 - ETA: 24s - loss: 1.23 - ETA: 20s - loss: 1.24 - ETA: 16s - loss: 1.24 - ETA: 12s - loss: 1.24 - ETA: 8s - loss: 1.2397 - ETA: 4s - loss: 1.2396WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2395\n",
      "Epoch 62/100\n",
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.228 - ETA: 6:43 - loss: 1.230 - ETA: 6:40 - loss: 1.231 - ETA: 6:36 - loss: 1.239 - ETA: 6:32 - loss: 1.241 - ETA: 6:27 - loss: 1.236 - ETA: 6:23 - loss: 1.235 - ETA: 6:19 - loss: 1.234 - ETA: 6:15 - loss: 1.238 - ETA: 6:11 - loss: 1.238 - ETA: 6:07 - loss: 1.238 - ETA: 6:02 - loss: 1.237 - ETA: 5:58 - loss: 1.237 - ETA: 5:54 - loss: 1.239 - ETA: 5:50 - loss: 1.240 - ETA: 5:46 - loss: 1.245 - ETA: 5:42 - loss: 1.243 - ETA: 5:38 - loss: 1.245 - ETA: 5:34 - loss: 1.245 - ETA: 5:30 - loss: 1.243 - ETA: 5:25 - loss: 1.241 - ETA: 5:21 - loss: 1.242 - ETA: 5:17 - loss: 1.242 - ETA: 5:13 - loss: 1.241 - ETA: 5:09 - loss: 1.242 - ETA: 5:05 - loss: 1.241 - ETA: 5:01 - loss: 1.239 - ETA: 4:57 - loss: 1.241 - ETA: 4:53 - loss: 1.241 - ETA: 4:48 - loss: 1.239 - ETA: 4:44 - loss: 1.237 - ETA: 4:40 - loss: 1.237 - ETA: 4:36 - loss: 1.237 - ETA: 4:32 - loss: 1.237 - ETA: 4:28 - loss: 1.236 - ETA: 4:24 - loss: 1.235 - ETA: 4:20 - loss: 1.235 - ETA: 4:16 - loss: 1.234 - ETA: 4:12 - loss: 1.235 - ETA: 4:07 - loss: 1.234 - ETA: 4:03 - loss: 1.233 - ETA: 3:59 - loss: 1.233 - ETA: 3:55 - loss: 1.233 - ETA: 3:51 - loss: 1.233 - ETA: 3:47 - loss: 1.234 - ETA: 3:43 - loss: 1.233 - ETA: 3:38 - loss: 1.234 - ETA: 3:34 - loss: 1.233 - ETA: 3:30 - loss: 1.232 - ETA: 3:26 - loss: 1.233 - ETA: 3:22 - loss: 1.233 - ETA: 3:18 - loss: 1.233 - ETA: 3:14 - loss: 1.233 - ETA: 3:10 - loss: 1.233 - ETA: 3:05 - loss: 1.232 - ETA: 3:01 - loss: 1.233 - ETA: 2:57 - loss: 1.232 - ETA: 2:53 - loss: 1.233 - ETA: 2:49 - loss: 1.233 - ETA: 2:45 - loss: 1.233 - ETA: 2:41 - loss: 1.233 - ETA: 2:36 - loss: 1.233 - ETA: 2:32 - loss: 1.233 - ETA: 2:28 - loss: 1.233 - ETA: 2:24 - loss: 1.233 - ETA: 2:20 - loss: 1.233 - ETA: 2:16 - loss: 1.233 - ETA: 2:12 - loss: 1.233 - ETA: 2:08 - loss: 1.233 - ETA: 2:03 - loss: 1.233 - ETA: 1:59 - loss: 1.233 - ETA: 1:55 - loss: 1.233 - ETA: 1:51 - loss: 1.233 - ETA: 1:47 - loss: 1.233 - ETA: 1:43 - loss: 1.233 - ETA: 1:39 - loss: 1.233 - ETA: 1:34 - loss: 1.233 - ETA: 1:30 - loss: 1.233 - ETA: 1:26 - loss: 1.233 - ETA: 1:22 - loss: 1.234 - ETA: 1:18 - loss: 1.234 - ETA: 1:14 - loss: 1.235 - ETA: 1:10 - loss: 1.235 - ETA: 1:06 - loss: 1.234 - ETA: 1:01 - loss: 1.234 - ETA: 57s - loss: 1.235 - ETA: 53s - loss: 1.23 - ETA: 49s - loss: 1.23 - ETA: 45s - loss: 1.23 - ETA: 41s - loss: 1.23 - ETA: 37s - loss: 1.23 - ETA: 33s - loss: 1.23 - ETA: 28s - loss: 1.23 - ETA: 24s - loss: 1.23 - ETA: 20s - loss: 1.23 - ETA: 16s - loss: 1.23 - ETA: 12s - loss: 1.23 - ETA: 8s - loss: 1.2344 - ETA: 4s - loss: 1.2345WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2343\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.185 - ETA: 6:44 - loss: 1.209 - ETA: 6:39 - loss: 1.223 - ETA: 6:35 - loss: 1.222 - ETA: 6:31 - loss: 1.214 - ETA: 6:27 - loss: 1.216 - ETA: 6:23 - loss: 1.222 - ETA: 6:19 - loss: 1.222 - ETA: 6:14 - loss: 1.220 - ETA: 6:10 - loss: 1.218 - ETA: 6:07 - loss: 1.217 - ETA: 6:03 - loss: 1.217 - ETA: 5:59 - loss: 1.220 - ETA: 5:55 - loss: 1.220 - ETA: 5:50 - loss: 1.224 - ETA: 5:46 - loss: 1.223 - ETA: 5:42 - loss: 1.224 - ETA: 5:38 - loss: 1.226 - ETA: 5:34 - loss: 1.225 - ETA: 5:30 - loss: 1.227 - ETA: 5:26 - loss: 1.229 - ETA: 5:22 - loss: 1.227 - ETA: 5:18 - loss: 1.228 - ETA: 5:14 - loss: 1.227 - ETA: 5:09 - loss: 1.228 - ETA: 5:05 - loss: 1.228 - ETA: 5:01 - loss: 1.229 - ETA: 4:57 - loss: 1.229 - ETA: 4:53 - loss: 1.230 - ETA: 4:49 - loss: 1.230 - ETA: 4:45 - loss: 1.230 - ETA: 4:41 - loss: 1.228 - ETA: 4:37 - loss: 1.228 - ETA: 4:33 - loss: 1.228 - ETA: 4:29 - loss: 1.229 - ETA: 4:25 - loss: 1.228 - ETA: 4:20 - loss: 1.229 - ETA: 4:16 - loss: 1.229 - ETA: 4:12 - loss: 1.229 - ETA: 4:08 - loss: 1.229 - ETA: 4:04 - loss: 1.229 - ETA: 4:00 - loss: 1.229 - ETA: 3:56 - loss: 1.230 - ETA: 3:51 - loss: 1.229 - ETA: 3:47 - loss: 1.229 - ETA: 3:43 - loss: 1.229 - ETA: 3:39 - loss: 1.229 - ETA: 3:35 - loss: 1.228 - ETA: 3:31 - loss: 1.229 - ETA: 3:27 - loss: 1.229 - ETA: 3:22 - loss: 1.228 - ETA: 3:18 - loss: 1.228 - ETA: 3:14 - loss: 1.228 - ETA: 3:10 - loss: 1.227 - ETA: 3:06 - loss: 1.227 - ETA: 3:02 - loss: 1.227 - ETA: 2:57 - loss: 1.227 - ETA: 2:53 - loss: 1.227 - ETA: 2:49 - loss: 1.227 - ETA: 2:45 - loss: 1.227 - ETA: 2:41 - loss: 1.228 - ETA: 2:37 - loss: 1.227 - ETA: 2:33 - loss: 1.227 - ETA: 2:28 - loss: 1.227 - ETA: 2:24 - loss: 1.227 - ETA: 2:20 - loss: 1.227 - ETA: 2:16 - loss: 1.227 - ETA: 2:12 - loss: 1.227 - ETA: 2:08 - loss: 1.228 - ETA: 2:04 - loss: 1.227 - ETA: 1:59 - loss: 1.227 - ETA: 1:55 - loss: 1.227 - ETA: 1:51 - loss: 1.226 - ETA: 1:47 - loss: 1.226 - ETA: 1:43 - loss: 1.227 - ETA: 1:39 - loss: 1.227 - ETA: 1:35 - loss: 1.227 - ETA: 1:31 - loss: 1.227 - ETA: 1:26 - loss: 1.228 - ETA: 1:22 - loss: 1.228 - ETA: 1:18 - loss: 1.228 - ETA: 1:14 - loss: 1.228 - ETA: 1:10 - loss: 1.229 - ETA: 1:06 - loss: 1.229 - ETA: 1:02 - loss: 1.229 - ETA: 57s - loss: 1.228 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 28s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2288 - ETA: 4s - loss: 1.2291WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2291\n",
      "Epoch 64/100\n",
      " 99/100 [============================>.] - ETA: 6:45 - loss: 1.216 - ETA: 6:43 - loss: 1.226 - ETA: 6:39 - loss: 1.230 - ETA: 6:35 - loss: 1.230 - ETA: 6:31 - loss: 1.228 - ETA: 6:27 - loss: 1.234 - ETA: 6:22 - loss: 1.226 - ETA: 6:18 - loss: 1.227 - ETA: 6:14 - loss: 1.225 - ETA: 6:10 - loss: 1.225 - ETA: 6:06 - loss: 1.228 - ETA: 6:02 - loss: 1.228 - ETA: 5:58 - loss: 1.226 - ETA: 5:54 - loss: 1.227 - ETA: 5:49 - loss: 1.229 - ETA: 5:45 - loss: 1.228 - ETA: 5:41 - loss: 1.228 - ETA: 5:37 - loss: 1.227 - ETA: 5:33 - loss: 1.225 - ETA: 5:29 - loss: 1.225 - ETA: 5:25 - loss: 1.226 - ETA: 5:21 - loss: 1.224 - ETA: 5:17 - loss: 1.223 - ETA: 5:12 - loss: 1.223 - ETA: 5:08 - loss: 1.222 - ETA: 5:04 - loss: 1.222 - ETA: 5:00 - loss: 1.222 - ETA: 4:56 - loss: 1.222 - ETA: 4:52 - loss: 1.221 - ETA: 4:48 - loss: 1.221 - ETA: 4:44 - loss: 1.221 - ETA: 4:40 - loss: 1.223 - ETA: 4:36 - loss: 1.223 - ETA: 4:31 - loss: 1.222 - ETA: 4:27 - loss: 1.222 - ETA: 4:23 - loss: 1.222 - ETA: 4:19 - loss: 1.222 - ETA: 4:15 - loss: 1.224 - ETA: 4:11 - loss: 1.224 - ETA: 4:07 - loss: 1.225 - ETA: 4:03 - loss: 1.225 - ETA: 3:59 - loss: 1.225 - ETA: 3:54 - loss: 1.225 - ETA: 3:50 - loss: 1.227 - ETA: 3:46 - loss: 1.226 - ETA: 3:42 - loss: 1.225 - ETA: 3:38 - loss: 1.225 - ETA: 3:34 - loss: 1.225 - ETA: 3:30 - loss: 1.225 - ETA: 3:26 - loss: 1.225 - ETA: 3:21 - loss: 1.225 - ETA: 3:17 - loss: 1.226 - ETA: 3:13 - loss: 1.226 - ETA: 3:09 - loss: 1.225 - ETA: 3:05 - loss: 1.225 - ETA: 3:01 - loss: 1.224 - ETA: 2:57 - loss: 1.224 - ETA: 2:53 - loss: 1.223 - ETA: 2:49 - loss: 1.223 - ETA: 2:45 - loss: 1.223 - ETA: 2:40 - loss: 1.224 - ETA: 2:36 - loss: 1.224 - ETA: 2:32 - loss: 1.224 - ETA: 2:28 - loss: 1.224 - ETA: 2:24 - loss: 1.224 - ETA: 2:20 - loss: 1.224 - ETA: 2:16 - loss: 1.224 - ETA: 2:12 - loss: 1.225 - ETA: 2:07 - loss: 1.224 - ETA: 2:03 - loss: 1.224 - ETA: 1:59 - loss: 1.224 - ETA: 1:55 - loss: 1.223 - ETA: 1:51 - loss: 1.223 - ETA: 1:47 - loss: 1.224 - ETA: 1:43 - loss: 1.224 - ETA: 1:39 - loss: 1.224 - ETA: 1:34 - loss: 1.224 - ETA: 1:30 - loss: 1.224 - ETA: 1:26 - loss: 1.224 - ETA: 1:22 - loss: 1.225 - ETA: 1:18 - loss: 1.225 - ETA: 1:14 - loss: 1.225 - ETA: 1:10 - loss: 1.224 - ETA: 1:06 - loss: 1.224 - ETA: 1:01 - loss: 1.224 - ETA: 57s - loss: 1.224 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 28s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2246 - ETA: 4s - loss: 1.2247WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2243\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:47 - loss: 1.238 - ETA: 6:43 - loss: 1.252 - ETA: 6:39 - loss: 1.236 - ETA: 6:35 - loss: 1.242 - ETA: 6:31 - loss: 1.233 - ETA: 6:27 - loss: 1.240 - ETA: 6:23 - loss: 1.239 - ETA: 6:19 - loss: 1.241 - ETA: 6:15 - loss: 1.240 - ETA: 6:11 - loss: 1.236 - ETA: 6:07 - loss: 1.233 - ETA: 6:03 - loss: 1.237 - ETA: 5:59 - loss: 1.240 - ETA: 5:55 - loss: 1.239 - ETA: 5:51 - loss: 1.237 - ETA: 5:46 - loss: 1.234 - ETA: 5:42 - loss: 1.236 - ETA: 5:38 - loss: 1.235 - ETA: 5:34 - loss: 1.235 - ETA: 5:30 - loss: 1.235 - ETA: 5:26 - loss: 1.234 - ETA: 5:22 - loss: 1.233 - ETA: 5:17 - loss: 1.234 - ETA: 5:13 - loss: 1.232 - ETA: 5:09 - loss: 1.231 - ETA: 5:05 - loss: 1.230 - ETA: 5:01 - loss: 1.229 - ETA: 4:57 - loss: 1.228 - ETA: 4:53 - loss: 1.227 - ETA: 4:49 - loss: 1.226 - ETA: 4:45 - loss: 1.227 - ETA: 4:40 - loss: 1.227 - ETA: 4:36 - loss: 1.227 - ETA: 4:32 - loss: 1.227 - ETA: 4:28 - loss: 1.227 - ETA: 4:24 - loss: 1.227 - ETA: 4:20 - loss: 1.226 - ETA: 4:16 - loss: 1.226 - ETA: 4:11 - loss: 1.226 - ETA: 4:07 - loss: 1.226 - ETA: 4:03 - loss: 1.226 - ETA: 3:59 - loss: 1.226 - ETA: 3:55 - loss: 1.226 - ETA: 3:51 - loss: 1.227 - ETA: 3:47 - loss: 1.227 - ETA: 3:43 - loss: 1.227 - ETA: 3:39 - loss: 1.226 - ETA: 3:34 - loss: 1.226 - ETA: 3:30 - loss: 1.226 - ETA: 3:26 - loss: 1.225 - ETA: 3:22 - loss: 1.226 - ETA: 3:18 - loss: 1.226 - ETA: 3:14 - loss: 1.226 - ETA: 3:10 - loss: 1.227 - ETA: 3:06 - loss: 1.227 - ETA: 3:02 - loss: 1.226 - ETA: 2:58 - loss: 1.226 - ETA: 2:54 - loss: 1.227 - ETA: 2:49 - loss: 1.227 - ETA: 2:45 - loss: 1.227 - ETA: 2:41 - loss: 1.227 - ETA: 2:37 - loss: 1.228 - ETA: 2:33 - loss: 1.227 - ETA: 2:29 - loss: 1.227 - ETA: 2:24 - loss: 1.228 - ETA: 2:20 - loss: 1.228 - ETA: 2:16 - loss: 1.228 - ETA: 2:12 - loss: 1.227 - ETA: 2:08 - loss: 1.228 - ETA: 2:04 - loss: 1.228 - ETA: 2:00 - loss: 1.228 - ETA: 1:55 - loss: 1.228 - ETA: 1:51 - loss: 1.228 - ETA: 1:47 - loss: 1.228 - ETA: 1:43 - loss: 1.228 - ETA: 1:39 - loss: 1.227 - ETA: 1:35 - loss: 1.227 - ETA: 1:31 - loss: 1.227 - ETA: 1:26 - loss: 1.226 - ETA: 1:22 - loss: 1.226 - ETA: 1:18 - loss: 1.226 - ETA: 1:14 - loss: 1.225 - ETA: 1:10 - loss: 1.225 - ETA: 1:06 - loss: 1.225 - ETA: 1:02 - loss: 1.225 - ETA: 57s - loss: 1.225 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 28s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2246 - ETA: 4s - loss: 1.2244WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2243\n",
      "Epoch 66/100\n",
      " 99/100 [============================>.] - ETA: 6:54 - loss: 1.231 - ETA: 6:46 - loss: 1.245 - ETA: 6:41 - loss: 1.234 - ETA: 6:36 - loss: 1.248 - ETA: 6:32 - loss: 1.239 - ETA: 6:28 - loss: 1.226 - ETA: 6:24 - loss: 1.223 - ETA: 6:20 - loss: 1.220 - ETA: 6:16 - loss: 1.220 - ETA: 6:12 - loss: 1.223 - ETA: 6:08 - loss: 1.220 - ETA: 6:04 - loss: 1.219 - ETA: 5:59 - loss: 1.223 - ETA: 5:55 - loss: 1.221 - ETA: 5:51 - loss: 1.221 - ETA: 5:47 - loss: 1.222 - ETA: 5:43 - loss: 1.222 - ETA: 5:39 - loss: 1.220 - ETA: 5:35 - loss: 1.219 - ETA: 5:31 - loss: 1.219 - ETA: 5:27 - loss: 1.222 - ETA: 5:22 - loss: 1.223 - ETA: 5:18 - loss: 1.223 - ETA: 5:14 - loss: 1.223 - ETA: 5:10 - loss: 1.222 - ETA: 5:06 - loss: 1.223 - ETA: 5:02 - loss: 1.224 - ETA: 4:57 - loss: 1.223 - ETA: 4:53 - loss: 1.223 - ETA: 4:49 - loss: 1.223 - ETA: 4:45 - loss: 1.223 - ETA: 4:41 - loss: 1.224 - ETA: 4:37 - loss: 1.225 - ETA: 4:32 - loss: 1.226 - ETA: 4:28 - loss: 1.226 - ETA: 4:24 - loss: 1.227 - ETA: 4:20 - loss: 1.227 - ETA: 4:16 - loss: 1.227 - ETA: 4:12 - loss: 1.227 - ETA: 4:07 - loss: 1.228 - ETA: 4:03 - loss: 1.228 - ETA: 3:59 - loss: 1.227 - ETA: 3:55 - loss: 1.227 - ETA: 3:51 - loss: 1.228 - ETA: 3:47 - loss: 1.228 - ETA: 3:43 - loss: 1.228 - ETA: 3:39 - loss: 1.226 - ETA: 3:34 - loss: 1.226 - ETA: 3:30 - loss: 1.226 - ETA: 3:26 - loss: 1.225 - ETA: 3:22 - loss: 1.225 - ETA: 3:18 - loss: 1.225 - ETA: 3:14 - loss: 1.225 - ETA: 3:10 - loss: 1.226 - ETA: 3:05 - loss: 1.226 - ETA: 3:01 - loss: 1.226 - ETA: 2:57 - loss: 1.226 - ETA: 2:53 - loss: 1.226 - ETA: 2:49 - loss: 1.226 - ETA: 2:45 - loss: 1.225 - ETA: 2:41 - loss: 1.225 - ETA: 2:37 - loss: 1.225 - ETA: 2:32 - loss: 1.225 - ETA: 2:28 - loss: 1.226 - ETA: 2:24 - loss: 1.226 - ETA: 2:20 - loss: 1.226 - ETA: 2:16 - loss: 1.226 - ETA: 2:12 - loss: 1.226 - ETA: 2:08 - loss: 1.226 - ETA: 2:03 - loss: 1.226 - ETA: 1:59 - loss: 1.226 - ETA: 1:55 - loss: 1.226 - ETA: 1:51 - loss: 1.226 - ETA: 1:47 - loss: 1.226 - ETA: 1:43 - loss: 1.226 - ETA: 1:39 - loss: 1.226 - ETA: 1:35 - loss: 1.225 - ETA: 1:30 - loss: 1.226 - ETA: 1:26 - loss: 1.225 - ETA: 1:22 - loss: 1.225 - ETA: 1:18 - loss: 1.225 - ETA: 1:14 - loss: 1.225 - ETA: 1:10 - loss: 1.225 - ETA: 1:06 - loss: 1.226 - ETA: 1:01 - loss: 1.226 - ETA: 57s - loss: 1.226 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 28s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2258 - ETA: 4s - loss: 1.2259WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2262\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.219 - ETA: 6:43 - loss: 1.211 - ETA: 6:39 - loss: 1.209 - ETA: 6:34 - loss: 1.215 - ETA: 6:30 - loss: 1.223 - ETA: 6:26 - loss: 1.218 - ETA: 6:22 - loss: 1.215 - ETA: 6:18 - loss: 1.216 - ETA: 6:14 - loss: 1.216 - ETA: 6:10 - loss: 1.215 - ETA: 6:06 - loss: 1.215 - ETA: 6:02 - loss: 1.212 - ETA: 5:58 - loss: 1.210 - ETA: 5:54 - loss: 1.209 - ETA: 5:50 - loss: 1.211 - ETA: 5:46 - loss: 1.214 - ETA: 5:42 - loss: 1.216 - ETA: 5:38 - loss: 1.216 - ETA: 5:34 - loss: 1.217 - ETA: 5:29 - loss: 1.219 - ETA: 5:25 - loss: 1.220 - ETA: 5:21 - loss: 1.221 - ETA: 5:17 - loss: 1.221 - ETA: 5:13 - loss: 1.222 - ETA: 5:09 - loss: 1.222 - ETA: 5:06 - loss: 1.222 - ETA: 5:03 - loss: 1.223 - ETA: 4:59 - loss: 1.222 - ETA: 4:56 - loss: 1.223 - ETA: 4:52 - loss: 1.223 - ETA: 4:48 - loss: 1.222 - ETA: 4:44 - loss: 1.221 - ETA: 4:39 - loss: 1.222 - ETA: 4:35 - loss: 1.222 - ETA: 4:31 - loss: 1.222 - ETA: 4:27 - loss: 1.221 - ETA: 4:22 - loss: 1.221 - ETA: 4:18 - loss: 1.221 - ETA: 4:14 - loss: 1.221 - ETA: 4:10 - loss: 1.223 - ETA: 4:05 - loss: 1.223 - ETA: 4:01 - loss: 1.223 - ETA: 3:57 - loss: 1.223 - ETA: 3:53 - loss: 1.223 - ETA: 3:49 - loss: 1.224 - ETA: 3:44 - loss: 1.223 - ETA: 3:40 - loss: 1.223 - ETA: 3:36 - loss: 1.223 - ETA: 3:32 - loss: 1.224 - ETA: 3:28 - loss: 1.224 - ETA: 3:23 - loss: 1.225 - ETA: 3:19 - loss: 1.225 - ETA: 3:15 - loss: 1.225 - ETA: 3:11 - loss: 1.225 - ETA: 3:07 - loss: 1.225 - ETA: 3:02 - loss: 1.225 - ETA: 2:58 - loss: 1.224 - ETA: 2:54 - loss: 1.224 - ETA: 2:50 - loss: 1.224 - ETA: 2:46 - loss: 1.223 - ETA: 2:41 - loss: 1.223 - ETA: 2:37 - loss: 1.222 - ETA: 2:33 - loss: 1.223 - ETA: 2:29 - loss: 1.222 - ETA: 2:25 - loss: 1.222 - ETA: 2:21 - loss: 1.222 - ETA: 2:16 - loss: 1.222 - ETA: 2:12 - loss: 1.223 - ETA: 2:08 - loss: 1.223 - ETA: 2:04 - loss: 1.223 - ETA: 2:00 - loss: 1.223 - ETA: 1:56 - loss: 1.223 - ETA: 1:52 - loss: 1.223 - ETA: 1:47 - loss: 1.222 - ETA: 1:43 - loss: 1.223 - ETA: 1:39 - loss: 1.223 - ETA: 1:35 - loss: 1.223 - ETA: 1:31 - loss: 1.223 - ETA: 1:27 - loss: 1.223 - ETA: 1:23 - loss: 1.223 - ETA: 1:18 - loss: 1.223 - ETA: 1:14 - loss: 1.223 - ETA: 1:10 - loss: 1.223 - ETA: 1:06 - loss: 1.223 - ETA: 1:02 - loss: 1.223 - ETA: 58s - loss: 1.223 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 29s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2237 - ETA: 4s - loss: 1.2238WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 415s 4s/step - loss: 1.2236\n",
      "Epoch 68/100\n",
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.237 - ETA: 6:44 - loss: 1.251 - ETA: 6:39 - loss: 1.248 - ETA: 6:37 - loss: 1.244 - ETA: 6:33 - loss: 1.233 - ETA: 6:29 - loss: 1.227 - ETA: 6:24 - loss: 1.227 - ETA: 6:20 - loss: 1.229 - ETA: 6:16 - loss: 1.227 - ETA: 6:12 - loss: 1.231 - ETA: 6:07 - loss: 1.231 - ETA: 6:03 - loss: 1.227 - ETA: 5:59 - loss: 1.227 - ETA: 5:55 - loss: 1.230 - ETA: 5:50 - loss: 1.225 - ETA: 5:46 - loss: 1.226 - ETA: 5:42 - loss: 1.225 - ETA: 5:38 - loss: 1.224 - ETA: 5:34 - loss: 1.225 - ETA: 5:30 - loss: 1.225 - ETA: 5:26 - loss: 1.227 - ETA: 5:22 - loss: 1.226 - ETA: 5:18 - loss: 1.227 - ETA: 5:13 - loss: 1.225 - ETA: 5:09 - loss: 1.225 - ETA: 5:05 - loss: 1.225 - ETA: 5:01 - loss: 1.225 - ETA: 4:57 - loss: 1.226 - ETA: 4:53 - loss: 1.226 - ETA: 4:49 - loss: 1.225 - ETA: 4:44 - loss: 1.225 - ETA: 4:40 - loss: 1.226 - ETA: 4:36 - loss: 1.227 - ETA: 4:32 - loss: 1.226 - ETA: 4:28 - loss: 1.228 - ETA: 4:24 - loss: 1.227 - ETA: 4:20 - loss: 1.227 - ETA: 4:16 - loss: 1.226 - ETA: 4:11 - loss: 1.225 - ETA: 4:07 - loss: 1.226 - ETA: 4:03 - loss: 1.227 - ETA: 3:59 - loss: 1.228 - ETA: 3:55 - loss: 1.228 - ETA: 3:51 - loss: 1.228 - ETA: 3:47 - loss: 1.228 - ETA: 3:42 - loss: 1.227 - ETA: 3:38 - loss: 1.228 - ETA: 3:34 - loss: 1.228 - ETA: 3:30 - loss: 1.228 - ETA: 3:26 - loss: 1.228 - ETA: 3:22 - loss: 1.227 - ETA: 3:18 - loss: 1.227 - ETA: 3:14 - loss: 1.227 - ETA: 3:09 - loss: 1.227 - ETA: 3:05 - loss: 1.227 - ETA: 3:01 - loss: 1.227 - ETA: 2:57 - loss: 1.227 - ETA: 2:53 - loss: 1.226 - ETA: 2:49 - loss: 1.226 - ETA: 2:45 - loss: 1.226 - ETA: 2:41 - loss: 1.226 - ETA: 2:36 - loss: 1.227 - ETA: 2:32 - loss: 1.227 - ETA: 2:28 - loss: 1.227 - ETA: 2:24 - loss: 1.226 - ETA: 2:20 - loss: 1.226 - ETA: 2:16 - loss: 1.226 - ETA: 2:12 - loss: 1.225 - ETA: 2:07 - loss: 1.225 - ETA: 2:03 - loss: 1.225 - ETA: 1:59 - loss: 1.225 - ETA: 1:55 - loss: 1.225 - ETA: 1:51 - loss: 1.225 - ETA: 1:47 - loss: 1.224 - ETA: 1:43 - loss: 1.225 - ETA: 1:39 - loss: 1.225 - ETA: 1:34 - loss: 1.224 - ETA: 1:30 - loss: 1.224 - ETA: 1:26 - loss: 1.224 - ETA: 1:22 - loss: 1.225 - ETA: 1:18 - loss: 1.225 - ETA: 1:14 - loss: 1.225 - ETA: 1:10 - loss: 1.225 - ETA: 1:06 - loss: 1.225 - ETA: 1:01 - loss: 1.225 - ETA: 57s - loss: 1.225 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 28s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2230 - ETA: 4s - loss: 1.2232WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2231\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.208 - ETA: 6:44 - loss: 1.209 - ETA: 6:42 - loss: 1.199 - ETA: 6:37 - loss: 1.199 - ETA: 6:33 - loss: 1.201 - ETA: 6:28 - loss: 1.204 - ETA: 6:24 - loss: 1.206 - ETA: 6:20 - loss: 1.209 - ETA: 6:16 - loss: 1.210 - ETA: 6:11 - loss: 1.212 - ETA: 6:07 - loss: 1.215 - ETA: 6:03 - loss: 1.214 - ETA: 5:59 - loss: 1.214 - ETA: 5:55 - loss: 1.212 - ETA: 5:51 - loss: 1.211 - ETA: 5:47 - loss: 1.213 - ETA: 5:43 - loss: 1.213 - ETA: 5:38 - loss: 1.214 - ETA: 5:34 - loss: 1.214 - ETA: 5:30 - loss: 1.213 - ETA: 5:26 - loss: 1.214 - ETA: 5:22 - loss: 1.212 - ETA: 5:18 - loss: 1.210 - ETA: 5:14 - loss: 1.212 - ETA: 5:09 - loss: 1.213 - ETA: 5:05 - loss: 1.212 - ETA: 5:01 - loss: 1.212 - ETA: 4:57 - loss: 1.211 - ETA: 4:53 - loss: 1.210 - ETA: 4:49 - loss: 1.211 - ETA: 4:45 - loss: 1.210 - ETA: 4:40 - loss: 1.210 - ETA: 4:36 - loss: 1.209 - ETA: 4:32 - loss: 1.208 - ETA: 4:28 - loss: 1.209 - ETA: 4:24 - loss: 1.209 - ETA: 4:20 - loss: 1.207 - ETA: 4:16 - loss: 1.206 - ETA: 4:11 - loss: 1.205 - ETA: 4:07 - loss: 1.206 - ETA: 4:03 - loss: 1.205 - ETA: 3:59 - loss: 1.205 - ETA: 3:55 - loss: 1.206 - ETA: 3:51 - loss: 1.205 - ETA: 3:47 - loss: 1.205 - ETA: 3:43 - loss: 1.204 - ETA: 3:38 - loss: 1.205 - ETA: 3:34 - loss: 1.205 - ETA: 3:30 - loss: 1.205 - ETA: 3:26 - loss: 1.204 - ETA: 3:22 - loss: 1.204 - ETA: 3:18 - loss: 1.205 - ETA: 3:14 - loss: 1.204 - ETA: 3:10 - loss: 1.204 - ETA: 3:05 - loss: 1.205 - ETA: 3:01 - loss: 1.205 - ETA: 2:57 - loss: 1.206 - ETA: 2:53 - loss: 1.206 - ETA: 2:49 - loss: 1.206 - ETA: 2:45 - loss: 1.207 - ETA: 2:41 - loss: 1.207 - ETA: 2:36 - loss: 1.207 - ETA: 2:32 - loss: 1.207 - ETA: 2:28 - loss: 1.207 - ETA: 2:24 - loss: 1.207 - ETA: 2:20 - loss: 1.207 - ETA: 2:16 - loss: 1.207 - ETA: 2:12 - loss: 1.207 - ETA: 2:08 - loss: 1.207 - ETA: 2:03 - loss: 1.208 - ETA: 1:59 - loss: 1.209 - ETA: 1:55 - loss: 1.209 - ETA: 1:51 - loss: 1.209 - ETA: 1:47 - loss: 1.209 - ETA: 1:43 - loss: 1.210 - ETA: 1:39 - loss: 1.210 - ETA: 1:35 - loss: 1.210 - ETA: 1:30 - loss: 1.211 - ETA: 1:26 - loss: 1.210 - ETA: 1:22 - loss: 1.210 - ETA: 1:18 - loss: 1.210 - ETA: 1:14 - loss: 1.210 - ETA: 1:10 - loss: 1.210 - ETA: 1:06 - loss: 1.210 - ETA: 1:01 - loss: 1.210 - ETA: 57s - loss: 1.210 - ETA: 53s - loss: 1.21 - ETA: 49s - loss: 1.21 - ETA: 45s - loss: 1.21 - ETA: 41s - loss: 1.21 - ETA: 37s - loss: 1.21 - ETA: 33s - loss: 1.21 - ETA: 28s - loss: 1.21 - ETA: 24s - loss: 1.21 - ETA: 20s - loss: 1.21 - ETA: 16s - loss: 1.21 - ETA: 12s - loss: 1.21 - ETA: 8s - loss: 1.2119 - ETA: 4s - loss: 1.2119WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 414s 4s/step - loss: 1.2120\n",
      "Epoch 70/100\n",
      " 99/100 [============================>.] - ETA: 6:48 - loss: 1.176 - ETA: 6:44 - loss: 1.189 - ETA: 6:41 - loss: 1.189 - ETA: 6:37 - loss: 1.201 - ETA: 6:33 - loss: 1.207 - ETA: 6:28 - loss: 1.211 - ETA: 6:25 - loss: 1.206 - ETA: 6:20 - loss: 1.209 - ETA: 6:16 - loss: 1.209 - ETA: 6:12 - loss: 1.209 - ETA: 6:08 - loss: 1.207 - ETA: 6:03 - loss: 1.205 - ETA: 5:59 - loss: 1.207 - ETA: 5:55 - loss: 1.211 - ETA: 5:51 - loss: 1.212 - ETA: 5:47 - loss: 1.213 - ETA: 5:43 - loss: 1.213 - ETA: 5:39 - loss: 1.215 - ETA: 5:35 - loss: 1.215 - ETA: 5:30 - loss: 1.215 - ETA: 5:26 - loss: 1.216 - ETA: 5:22 - loss: 1.215 - ETA: 5:18 - loss: 1.216 - ETA: 5:14 - loss: 1.216 - ETA: 5:10 - loss: 1.217 - ETA: 5:06 - loss: 1.217 - ETA: 5:01 - loss: 1.218 - ETA: 4:57 - loss: 1.219 - ETA: 4:53 - loss: 1.219 - ETA: 4:49 - loss: 1.219 - ETA: 4:45 - loss: 1.219 - ETA: 4:41 - loss: 1.218 - ETA: 4:36 - loss: 1.218 - ETA: 4:32 - loss: 1.218 - ETA: 4:28 - loss: 1.218 - ETA: 4:24 - loss: 1.219 - ETA: 4:20 - loss: 1.221 - ETA: 4:16 - loss: 1.222 - ETA: 4:12 - loss: 1.221 - ETA: 4:08 - loss: 1.221 - ETA: 4:04 - loss: 1.221 - ETA: 3:59 - loss: 1.221 - ETA: 3:55 - loss: 1.220 - ETA: 3:51 - loss: 1.221 - ETA: 3:47 - loss: 1.221 - ETA: 3:43 - loss: 1.221 - ETA: 3:39 - loss: 1.221 - ETA: 3:35 - loss: 1.221 - ETA: 3:31 - loss: 1.221 - ETA: 3:26 - loss: 1.222 - ETA: 3:22 - loss: 1.222 - ETA: 3:18 - loss: 1.222 - ETA: 3:14 - loss: 1.221 - ETA: 3:10 - loss: 1.222 - ETA: 3:06 - loss: 1.222 - ETA: 3:01 - loss: 1.221 - ETA: 2:57 - loss: 1.221 - ETA: 2:53 - loss: 1.221 - ETA: 2:49 - loss: 1.221 - ETA: 2:45 - loss: 1.221 - ETA: 2:41 - loss: 1.221 - ETA: 2:37 - loss: 1.222 - ETA: 2:32 - loss: 1.222 - ETA: 2:28 - loss: 1.222 - ETA: 2:24 - loss: 1.222 - ETA: 2:20 - loss: 1.222 - ETA: 2:16 - loss: 1.222 - ETA: 2:12 - loss: 1.222 - ETA: 2:08 - loss: 1.222 - ETA: 2:04 - loss: 1.222 - ETA: 1:59 - loss: 1.222 - ETA: 1:55 - loss: 1.222 - ETA: 1:51 - loss: 1.221 - ETA: 1:47 - loss: 1.221 - ETA: 1:43 - loss: 1.221 - ETA: 1:39 - loss: 1.222 - ETA: 1:35 - loss: 1.222 - ETA: 1:30 - loss: 1.222 - ETA: 1:26 - loss: 1.222 - ETA: 1:22 - loss: 1.222 - ETA: 1:18 - loss: 1.222 - ETA: 1:14 - loss: 1.222 - ETA: 1:10 - loss: 1.222 - ETA: 1:06 - loss: 1.222 - ETA: 1:01 - loss: 1.222 - ETA: 57s - loss: 1.222 - ETA: 53s - loss: 1.22 - ETA: 49s - loss: 1.22 - ETA: 45s - loss: 1.22 - ETA: 41s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 28s - loss: 1.22 - ETA: 24s - loss: 1.22 - ETA: 20s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2230 - ETA: 4s - loss: 1.2229WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 413s 4s/step - loss: 1.2229\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 6:53 - loss: 1.218 - ETA: 6:47 - loss: 1.207 - ETA: 6:42 - loss: 1.215 - ETA: 6:37 - loss: 1.212 - ETA: 6:33 - loss: 1.211 - ETA: 6:28 - loss: 1.215 - ETA: 6:24 - loss: 1.213 - ETA: 6:19 - loss: 1.220 - ETA: 6:15 - loss: 1.218 - ETA: 6:11 - loss: 1.218 - ETA: 6:07 - loss: 1.219 - ETA: 6:03 - loss: 1.221 - ETA: 5:59 - loss: 1.220 - ETA: 5:55 - loss: 1.220 - ETA: 5:50 - loss: 1.219 - ETA: 5:46 - loss: 1.220 - ETA: 5:42 - loss: 1.222 - ETA: 5:38 - loss: 1.222 - ETA: 5:34 - loss: 1.221 - ETA: 5:30 - loss: 1.223 - ETA: 5:26 - loss: 1.223 - ETA: 5:22 - loss: 1.223 - ETA: 5:18 - loss: 1.223 - ETA: 5:14 - loss: 1.224 - ETA: 5:10 - loss: 1.224 - ETA: 5:06 - loss: 1.224 - ETA: 5:01 - loss: 1.224 - ETA: 4:57 - loss: 1.226 - ETA: 4:53 - loss: 1.224 - ETA: 4:49 - loss: 1.224 - ETA: 4:45 - loss: 1.224 - ETA: 4:41 - loss: 1.223 - ETA: 4:36 - loss: 1.225 - ETA: 4:32 - loss: 1.224 - ETA: 4:28 - loss: 1.225 - ETA: 4:24 - loss: 1.224 - ETA: 4:20 - loss: 1.224 - ETA: 4:16 - loss: 1.224 - ETA: 4:12 - loss: 1.224 - ETA: 4:07 - loss: 1.223 - ETA: 4:03 - loss: 1.224 - ETA: 3:59 - loss: 1.224 - ETA: 3:55 - loss: 1.224 - ETA: 3:51 - loss: 1.224 - ETA: 3:47 - loss: 1.224 - ETA: 3:43 - loss: 1.224 - ETA: 3:38 - loss: 1.223 - ETA: 3:34 - loss: 1.224 - ETA: 3:30 - loss: 1.223 - ETA: 3:26 - loss: 1.224 - ETA: 3:22 - loss: 1.223 - ETA: 3:18 - loss: 1.224 - ETA: 3:14 - loss: 1.223 - ETA: 3:10 - loss: 1.223 - ETA: 3:05 - loss: 1.224 - ETA: 3:01 - loss: 1.224 - ETA: 2:57 - loss: 1.224 - ETA: 2:53 - loss: 1.225 - ETA: 2:49 - loss: 1.225 - ETA: 2:45 - loss: 1.224 - ETA: 2:41 - loss: 1.224 - ETA: 2:37 - loss: 1.225 - ETA: 2:32 - loss: 1.225 - ETA: 2:28 - loss: 1.224 - ETA: 2:24 - loss: 1.224 - ETA: 2:21 - loss: 1.225 - ETA: 2:17 - loss: 1.225 - ETA: 2:13 - loss: 1.225 - ETA: 2:09 - loss: 1.225 - ETA: 2:04 - loss: 1.225 - ETA: 2:01 - loss: 1.225 - ETA: 1:57 - loss: 1.225 - ETA: 1:53 - loss: 1.225 - ETA: 1:49 - loss: 1.225 - ETA: 1:44 - loss: 1.225 - ETA: 1:40 - loss: 1.225 - ETA: 1:36 - loss: 1.225 - ETA: 1:32 - loss: 1.225 - ETA: 1:28 - loss: 1.225 - ETA: 1:24 - loss: 1.225 - ETA: 1:19 - loss: 1.225 - ETA: 1:15 - loss: 1.225 - ETA: 1:11 - loss: 1.226 - ETA: 1:07 - loss: 1.226 - ETA: 1:03 - loss: 1.226 - ETA: 58s - loss: 1.225 - ETA: 54s - loss: 1.22 - ETA: 50s - loss: 1.22 - ETA: 46s - loss: 1.22 - ETA: 42s - loss: 1.22 - ETA: 37s - loss: 1.22 - ETA: 33s - loss: 1.22 - ETA: 29s - loss: 1.22 - ETA: 25s - loss: 1.22 - ETA: 21s - loss: 1.22 - ETA: 16s - loss: 1.22 - ETA: 12s - loss: 1.22 - ETA: 8s - loss: 1.2237 - ETA: 4s - loss: 1.2239WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019E111AB400>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "100/100 [==============================] - 422s 4s/step - loss: 1.2236\n",
      "Epoch 72/100\n",
      "  2/100 [..............................] - ETA: 7:03 - loss: 1.204 - ETA: 7:08 - loss: 1.2103"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-effc8d65967c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    852\u001b[0m     elif distributed_training_utils.is_tpu_strategy(\n\u001b[0;32m    853\u001b[0m         self._distribution_strategy):\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3164\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3165\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3166\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3167\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m   3168\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m           \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Got two values for keyword '{}'.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munused_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Keyword arguments {} unknown.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gradient_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    267\u001b[0m           \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction_call_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_proto_serialized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m           executor_type=function_call_options.executor_type)\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[1;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[0;32m   1081\u001b[0m       outputs = gen_functional_ops.stateful_partitioned_call(\n\u001b[0;32m   1082\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m           executor_type=executor_type)\n\u001b[0m\u001b[0;32m   1084\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m       outputs = gen_functional_ops.partitioned_call(\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\gen_functional_ops.py\u001b[0m in \u001b[0;36mstateful_partitioned_call\u001b[1;34m(args, Tout, f, config, config_proto, executor_type, name)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[1;34m\"StatefulPartitionedCall\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;34m\"Tout\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \"executor_type\", executor_type)\n\u001b[0m\u001b[0;32m    483\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=100, steps_per_epoch=100, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            23296     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 91)             93275     \n",
      "=================================================================\n",
      "Total params: 5,363,547\n",
      "Trainable params: 5,363,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "   # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellon haunts several polls with their crime, she ability to be about: the current choices had tried to evaluate freedom, but also because the time I think it seems like it, You get themselves in this approva. A New York city filed by Pene Pand, said with O. C. The two good walls in secondbody, at a mission to prison for canapartic bis and promotes a wall for a moment campaign, has never been frustrations, ard others are talking for in order to support him expected to speak together.) As together, We were wedding on beyond North Carolina. Ordered the truth your it as stumbling almost one on that corone on top loans. Tesls before you arrested. Its 90 mune dashed to have offered possible rights and waits so offendes may never have everybody next morning was the only in others it was as if smart, Find have just dont work. Cerform the caused fah of clerians to be a resilient, the scientist s have struggled with ve their overtaskpect. ____ 9. Mr. Band. Mr. Kinbert, a family person, more than 25 \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
